{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6VO-fNxrWh5"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, setting up device and seeds\n"
      ],
      "metadata": {
        "id": "bWqIz6BsrIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "-RiHHnHEi7Vc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_all_seeds(42)"
      ],
      "metadata": {
        "id": "dF7Jzby3i-I6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.set_device(1)\n",
        "device = torch.device(\"cuda\")\n",
        "# device = torch.device('mps')\n",
        "# device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "-BCkcrW5i9kE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive"
      ],
      "metadata": {
        "id": "A2P1P9ATUoun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakEYCURjAtn",
        "outputId": "0b924c7e-b2d1-4922-e8a1-bf5e8d2e0dd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/SSNElab9\")"
      ],
      "metadata": {
        "id": "fGzhDkfDjCGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "zDc0baBsXVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_PERCENTAGE = 0.10\n",
        "batch_size = 8\n",
        "TRAIN_PATH = 'train.pkl'\n",
        "TEST_PATH = \"test_no_target.pkl\""
      ],
      "metadata": {
        "id": "sg6Nh9CXXT4U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training dataset"
      ],
      "metadata": {
        "id": "8b6UrS1rrOIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lhaFNeLhusm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(TRAIN_PATH, 'rb') as f:\n",
        "    train = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lengths = [len(train_song[0]) for train_song in train]"
      ],
      "metadata": {
        "id": "7eNmQAg1i7Yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjH5ziWn_4Po",
        "outputId": "0933d817-5b5a-4a3b-81c8-f0a2a0d17716"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGswPGVIFE",
        "outputId": "b56c6d07-dcf2-479c-87b3-684aa698f5ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for training values"
      ],
      "metadata": {
        "id": "g6VO-fNxrWh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of lengths of training sequences\n",
        "plt.hist(train_lengths, bins='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUP8rCvCo716",
        "outputId": "094fa81f-522f-4d07-c96b-485b2cdadf91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([152., 383., 229., 301., 297., 245., 212., 162., 103., 111.,  76.,\n",
              "         67.,  87.,  49.,  42.,  37.,  23.,  27.,  22.,  25.,  17.,  16.,\n",
              "         14.,  13.,  13.,  10.,  19.,  15.,  11.,  16.,   4.,   6.,   8.,\n",
              "          8.,   2.,   5.,   3.,   5.,   5.,   5.,   6.,   4.,   4.,  11.,\n",
              "          5.,   2.,   6.,   4.,   8.,   1.,   0.,   1.,   3.,   1.,   1.,\n",
              "          2.,   1.,   2.,   0.,   2.,   1.,   2.,   3.,   0.,   0.,   0.,\n",
              "          0.,   1.,   1.,   3.,   0.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,\n",
              "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,\n",
              "          1.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
              " array([4.00000000e+00, 5.17575758e+01, 9.95151515e+01, 1.47272727e+02,\n",
              "        1.95030303e+02, 2.42787879e+02, 2.90545455e+02, 3.38303030e+02,\n",
              "        3.86060606e+02, 4.33818182e+02, 4.81575758e+02, 5.29333333e+02,\n",
              "        5.77090909e+02, 6.24848485e+02, 6.72606061e+02, 7.20363636e+02,\n",
              "        7.68121212e+02, 8.15878788e+02, 8.63636364e+02, 9.11393939e+02,\n",
              "        9.59151515e+02, 1.00690909e+03, 1.05466667e+03, 1.10242424e+03,\n",
              "        1.15018182e+03, 1.19793939e+03, 1.24569697e+03, 1.29345455e+03,\n",
              "        1.34121212e+03, 1.38896970e+03, 1.43672727e+03, 1.48448485e+03,\n",
              "        1.53224242e+03, 1.58000000e+03, 1.62775758e+03, 1.67551515e+03,\n",
              "        1.72327273e+03, 1.77103030e+03, 1.81878788e+03, 1.86654545e+03,\n",
              "        1.91430303e+03, 1.96206061e+03, 2.00981818e+03, 2.05757576e+03,\n",
              "        2.10533333e+03, 2.15309091e+03, 2.20084848e+03, 2.24860606e+03,\n",
              "        2.29636364e+03, 2.34412121e+03, 2.39187879e+03, 2.43963636e+03,\n",
              "        2.48739394e+03, 2.53515152e+03, 2.58290909e+03, 2.63066667e+03,\n",
              "        2.67842424e+03, 2.72618182e+03, 2.77393939e+03, 2.82169697e+03,\n",
              "        2.86945455e+03, 2.91721212e+03, 2.96496970e+03, 3.01272727e+03,\n",
              "        3.06048485e+03, 3.10824242e+03, 3.15600000e+03, 3.20375758e+03,\n",
              "        3.25151515e+03, 3.29927273e+03, 3.34703030e+03, 3.39478788e+03,\n",
              "        3.44254545e+03, 3.49030303e+03, 3.53806061e+03, 3.58581818e+03,\n",
              "        3.63357576e+03, 3.68133333e+03, 3.72909091e+03, 3.77684848e+03,\n",
              "        3.82460606e+03, 3.87236364e+03, 3.92012121e+03, 3.96787879e+03,\n",
              "        4.01563636e+03, 4.06339394e+03, 4.11115152e+03, 4.15890909e+03,\n",
              "        4.20666667e+03, 4.25442424e+03, 4.30218182e+03, 4.34993939e+03,\n",
              "        4.39769697e+03, 4.44545455e+03, 4.49321212e+03, 4.54096970e+03,\n",
              "        4.58872727e+03, 4.63648485e+03, 4.68424242e+03, 4.73200000e+03,\n",
              "        4.77975758e+03, 4.82751515e+03, 4.87527273e+03, 4.92303030e+03,\n",
              "        4.97078788e+03, 5.01854545e+03, 5.06630303e+03, 5.11406061e+03,\n",
              "        5.16181818e+03, 5.20957576e+03, 5.25733333e+03, 5.30509091e+03,\n",
              "        5.35284848e+03, 5.40060606e+03, 5.44836364e+03, 5.49612121e+03,\n",
              "        5.54387879e+03, 5.59163636e+03, 5.63939394e+03, 5.68715152e+03,\n",
              "        5.73490909e+03, 5.78266667e+03, 5.83042424e+03, 5.87818182e+03,\n",
              "        5.92593939e+03, 5.97369697e+03, 6.02145455e+03, 6.06921212e+03,\n",
              "        6.11696970e+03, 6.16472727e+03, 6.21248485e+03, 6.26024242e+03,\n",
              "        6.30800000e+03]),\n",
              " <a list of 132 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train_lengths), max(train_lengths)"
      ],
      "metadata": {
        "id": "fkSg5eaga6cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932ef489-f9ef-4802-e148-967a4ec6afef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6308)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQvCZEwhCsTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "0a24j9vdPTrr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "SItHYahBR0BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from math import floor\n",
        "\n",
        "# converting train to tensors\n",
        "# train = [[torch.from_numpy(t[0].astype(int)).float(), torch.from_numpy(np.ndarray([int(t[1])]))] for t in train]\n",
        "train_data = [[torch.from_numpy(t[0].astype(int)).float(), int(t[1])] for t in train]\n",
        "\n",
        "dataset_length = len(train_data)\n",
        "val_size = floor(dataset_length * VALIDATION_PERCENTAGE)\n",
        "train_size = dataset_length - val_size\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
        "\n",
        "train_subset_data = [item[0] for item in train_subset]\n",
        "train_subset_targets = [item[1] for item in train_subset]\n",
        "\n",
        "val_subset_data = [item[0] for item in val_subset]\n",
        "val_subset_targets = [item[1] for item in val_subset]\n",
        "\n",
        "train_set = VariableLenDataset(train_subset_data, train_subset_targets)\n",
        "val_set = VariableLenDataset(val_subset_data, val_subset_targets)"
      ],
      "metadata": {
        "id": "sEm_rXS2TX4r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy"
      ],
      "metadata": {
        "id": "BvgU5pn2PTua"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "p8ShbxngPTxK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2H1pWKZyMu",
        "outputId": "62439f45-d00e-439d-b7c4-68306c93300c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[145., 145.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ -1., 112.,  34.,  ...,   0.,   0.,   0.],\n",
              "         [ -1.,  -1.,  -1.,  ...,   0.,   0.,  -1.],\n",
              "         ...,\n",
              "         [110., 185.,  88.,  ...,   0.,   0.,   0.],\n",
              "         [ 12.,  12.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ 21., 116.,  21.,  ...,   0.,   0.,   0.]]),\n",
              " (0, 4, 1, 4, 3, 0, 0, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CmMtriGMPSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        # pass the input through the LSTM layer\n",
        "        # print(x.shape)\n",
        "        # print(hidden[0].size(0))\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "\n",
        "        # print(\"OUT\", out.shape)\n",
        "        \n",
        "        # get the last output of the LSTM layer\n",
        "        out = out[-1, :, :]\n",
        "\n",
        "        # print(\"OUT2\", out.shape)\n",
        "        \n",
        "        # pass the last output through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # print(\"OUT3\", out.shape)\n",
        "        \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "W2TSYGhAa6i-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "model = LSTMRegressor(1,20,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kLQzbaPTow",
        "outputId": "b42f4ffe-ac30-4ae0-fc45-98a2f5646d5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 20, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy_per_class(model, loader, classes):\n",
        "\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "    acurracy_sum = 0\n",
        "\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for x, targets in loader:\n",
        "        \n",
        "            targets = torch.from_numpy(np.asarray(targets))\n",
        "            # print(\"SHAPE X\", x.shape)\n",
        "            # print(\"SHAPE TARGETS\", targets.shape)\n",
        "            x = x.to(device).unsqueeze(2)\n",
        "            targets = targets.to(device)\n",
        "            hidden, state = model.init_hidden(x.size(0))\n",
        "            hidden, state = hidden.to(device), state.to(device) \n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            preds = model(x, (hidden, state))\n",
        "            _, predictions = torch.max(preds, 1)\n",
        "\n",
        "            for label, prediction in zip(targets, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        # print(\"Accuracy for class {:5s} is: {:.2f} %\".format(classname, \n",
        "        #                                                accuracy))\n",
        "        acurracy_sum += accuracy\n",
        "        \n",
        "    # print(\"Average accuracy for a class is: {:.2f} %\".format(acurracy_sum/len(classes)))\n",
        "    \n",
        "    # division by 100\n",
        "    return acurracy_sum/(len(classes) * 100)\n"
      ],
      "metadata": {
        "id": "dd1xinfuEMZv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtpRHsY2EMcw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4xsMjjQEMfL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL2OKKBkEMh8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Sn-tXvwIG83R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "best_model = None\n",
        "best_model_acc = None\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    for x, targets in train_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # print(\"A\")\n",
        "        preds = model(x, (hidden, state))\n",
        "        # print(\"B\")\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "        # preds = preds.squeeze(2)\n",
        "        # print(\"PREDS\", preds.shape)\n",
        "        # preds = preds[:,-1,:]\n",
        "        \n",
        "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "        \n",
        "        # preds = preds.squeeze(2)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    epochs.append(epoch)\n",
        "\n",
        "    # evaluate the model on the validation set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, targets in val_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        preds = model(x, (hidden, state))\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(x, (hidden, state))\n",
        "\n",
        "        # get the predicted labels\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "        # compute the accuracy\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    val_acc.append(100 * correct / total)\n",
        "\n",
        "    if best_model is None or (correct / total) > best_model_acc:\n",
        "        best_model = model\n",
        "        best_model_acc = correct / total\n",
        "\n",
        "    # print the accuracy\n",
        "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")\n",
        "    print(f\"Accuracy on the validation set: {100 * correct / total}\")\n",
        "    print(f\"Accuracy per class {get_accuracy_per_class(model, val_loader, range(0, 5)):.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAWo9YRg3BLo",
        "outputId": "54172be9-b7bc-47ff-aa1f-63c9fd3c8001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.868\n",
            "Accuracy on the validation set: 53.24232081911263\n",
            "Accuracy per class 0.244\n",
            "Epoch: 1, loss: 0.874\n",
            "Accuracy on the validation set: 57.33788395904437\n",
            "Accuracy per class 0.244\n",
            "Epoch: 2, loss: 0.792\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.24\n",
            "Epoch: 3, loss: 1.7\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.252\n",
            "Epoch: 4, loss: 1.1\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.247\n",
            "Epoch: 5, loss: 1.14\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.248\n",
            "Epoch: 6, loss: 1.99\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.241\n",
            "Epoch: 7, loss: 1.12\n",
            "Accuracy on the validation set: 57.33788395904437\n",
            "Accuracy per class 0.248\n",
            "Epoch: 8, loss: 1.63\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.253\n",
            "Epoch: 9, loss: 0.958\n",
            "Accuracy on the validation set: 58.70307167235495\n",
            "Accuracy per class 0.256\n",
            "Epoch: 10, loss: 1.88\n",
            "Accuracy on the validation set: 55.63139931740614\n",
            "Accuracy per class 0.252\n",
            "Epoch: 11, loss: 1.26\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.244\n",
            "Epoch: 12, loss: 1.62\n",
            "Accuracy on the validation set: 56.65529010238908\n",
            "Accuracy per class 0.261\n",
            "Epoch: 13, loss: 1.9\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.257\n",
            "Epoch: 14, loss: 1.22\n",
            "Accuracy on the validation set: 59.044368600682596\n",
            "Accuracy per class 0.253\n",
            "Epoch: 15, loss: 0.563\n",
            "Accuracy on the validation set: 58.70307167235495\n",
            "Accuracy per class 0.257\n",
            "Epoch: 16, loss: 0.852\n",
            "Accuracy on the validation set: 57.33788395904437\n",
            "Accuracy per class 0.255\n",
            "Epoch: 17, loss: 1.66\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.253\n",
            "Epoch: 18, loss: 1.21\n",
            "Accuracy on the validation set: 57.33788395904437\n",
            "Accuracy per class 0.263\n",
            "Epoch: 19, loss: 2.1\n",
            "Accuracy on the validation set: 59.044368600682596\n",
            "Accuracy per class 0.255\n",
            "Epoch: 20, loss: 1.67\n",
            "Accuracy on the validation set: 59.044368600682596\n",
            "Accuracy per class 0.264\n",
            "Epoch: 21, loss: 0.509\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.256\n",
            "Epoch: 22, loss: 0.914\n",
            "Accuracy on the validation set: 58.70307167235495\n",
            "Accuracy per class 0.248\n",
            "Epoch: 23, loss: 1.2\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.266\n",
            "Epoch: 24, loss: 1.18\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.25\n",
            "Epoch: 25, loss: 0.512\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.26\n",
            "Epoch: 26, loss: 1.27\n",
            "Accuracy on the validation set: 56.65529010238908\n",
            "Accuracy per class 0.244\n",
            "Epoch: 27, loss: 1.25\n",
            "Accuracy on the validation set: 58.70307167235495\n",
            "Accuracy per class 0.248\n",
            "Epoch: 28, loss: 1.1\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.268\n",
            "Epoch: 29, loss: 1.17\n",
            "Accuracy on the validation set: 57.67918088737201\n",
            "Accuracy per class 0.271\n",
            "Epoch: 30, loss: 1.35\n",
            "Accuracy on the validation set: 57.33788395904437\n",
            "Accuracy per class 0.244\n",
            "Epoch: 31, loss: 0.505\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.26\n",
            "Epoch: 32, loss: 1.25\n",
            "Accuracy on the validation set: 58.02047781569966\n",
            "Accuracy per class 0.256\n",
            "Epoch: 33, loss: 1.01\n",
            "Accuracy on the validation set: 59.38566552901024\n",
            "Accuracy per class 0.272\n",
            "Epoch: 34, loss: 1.12\n",
            "Accuracy on the validation set: 59.72696245733788\n",
            "Accuracy per class 0.266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(epochs, losses, val_acc):\n",
        "    # plotting\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(\"Validation acc\")\n",
        "    plt.plot(epochs, val_acc, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "id": "K-s5mTUxSjOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(epochs, losses, val_acc)"
      ],
      "metadata": {
        "id": "iCwAflsXSjQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model to file\n",
        "state_dict = model.state_dict()\n",
        "torch.save(state_dict, \"neural_net.tar\")"
      ],
      "metadata": {
        "id": "7wsHi_yyLtge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving bes model to file\n",
        "state_dict = best_model.state_dict()\n",
        "torch.save(state_dict, \"best_neural_net.tar\")"
      ],
      "metadata": {
        "id": "fLPBbG134ncv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on the validation set: \", best_model_acc)"
      ],
      "metadata": {
        "id": "_i4Ta2PD439d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on test set"
      ],
      "metadata": {
        "id": "ajFynd6s9Ldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TEST_PATH, 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "wc1Q0Gne9KaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)"
      ],
      "metadata": {
        "id": "T6RUWhCm9M8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "id": "XCUegF_H9M-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [torch.from_numpy(t.astype(int)).float() for t in test_data]"
      ],
      "metadata": {
        "id": "5P2d0O2df28D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = VariableLenDataset(test_data, [0 for t in test_data])"
      ],
      "metadata": {
        "id": "FD-YF1cgYLBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "MOFb5U4TYLEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for x, label in test_loader:\n",
        "  print(x)\n",
        "  hidden, state = model.init_hidden(x.shape[0])\n",
        "  hidden, state = hidden.to(device), state.to(device)\n",
        "  x = x.to(device).unsqueeze(2)\n",
        "  x = torch.transpose(x, 0, 1)\n",
        "  new_preds = model(x, (hidden, state))\n",
        "  for new_pred in new_preds:\n",
        "    preds.append(new_pred.max(0, keepdim=True)[1].item())"
      ],
      "metadata": {
        "id": "LsEGLP2TYLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_filename = \"preds.csv\"\n",
        "pd.DataFrame({'A': preds}).to_csv(preds_filename, index=False, header=False)"
      ],
      "metadata": {
        "id": "jHYTyOE8ehGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(preds_filename, header=None)\n"
      ],
      "metadata": {
        "id": "PCdB4mfVehJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhRheNLg19CZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}