{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6VO-fNxrWh5"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, setting up device and seeds\n"
      ],
      "metadata": {
        "id": "bWqIz6BsrIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "-RiHHnHEi7Vc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_all_seeds(42)"
      ],
      "metadata": {
        "id": "dF7Jzby3i-I6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.set_device(1)\n",
        "device = torch.device(\"cuda\")\n",
        "# device = torch.device('mps')\n",
        "# device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "-BCkcrW5i9kE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive"
      ],
      "metadata": {
        "id": "A2P1P9ATUoun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakEYCURjAtn",
        "outputId": "85a4951d-d46c-4aa4-c0c7-bdfcf38a50cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/SSNElab9\")"
      ],
      "metadata": {
        "id": "fGzhDkfDjCGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "zDc0baBsXVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_PERCENTAGE = 0.10\n",
        "batch_size = 8\n",
        "TRAIN_PATH = 'train.pkl'\n",
        "TEST_PATH = \"test_no_target.pkl\""
      ],
      "metadata": {
        "id": "sg6Nh9CXXT4U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training dataset"
      ],
      "metadata": {
        "id": "8b6UrS1rrOIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lhaFNeLhusm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(TRAIN_PATH, 'rb') as f:\n",
        "    train = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lengths = [len(train_song[0]) for train_song in train]"
      ],
      "metadata": {
        "id": "7eNmQAg1i7Yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjH5ziWn_4Po",
        "outputId": "eb0bb6f5-5ca3-4b59-c4b3-0b637486430a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGswPGVIFE",
        "outputId": "07974603-4612-4a6f-9139-039938f01053"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for training values"
      ],
      "metadata": {
        "id": "g6VO-fNxrWh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of lengths of training sequences\n",
        "plt.hist(train_lengths, bins='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUP8rCvCo716",
        "outputId": "6bc071df-43fd-4a16-80d6-e24cb2972d57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([152., 383., 229., 301., 297., 245., 212., 162., 103., 111.,  76.,\n",
              "         67.,  87.,  49.,  42.,  37.,  23.,  27.,  22.,  25.,  17.,  16.,\n",
              "         14.,  13.,  13.,  10.,  19.,  15.,  11.,  16.,   4.,   6.,   8.,\n",
              "          8.,   2.,   5.,   3.,   5.,   5.,   5.,   6.,   4.,   4.,  11.,\n",
              "          5.,   2.,   6.,   4.,   8.,   1.,   0.,   1.,   3.,   1.,   1.,\n",
              "          2.,   1.,   2.,   0.,   2.,   1.,   2.,   3.,   0.,   0.,   0.,\n",
              "          0.,   1.,   1.,   3.,   0.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,\n",
              "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,\n",
              "          1.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
              " array([4.00000000e+00, 5.17575758e+01, 9.95151515e+01, 1.47272727e+02,\n",
              "        1.95030303e+02, 2.42787879e+02, 2.90545455e+02, 3.38303030e+02,\n",
              "        3.86060606e+02, 4.33818182e+02, 4.81575758e+02, 5.29333333e+02,\n",
              "        5.77090909e+02, 6.24848485e+02, 6.72606061e+02, 7.20363636e+02,\n",
              "        7.68121212e+02, 8.15878788e+02, 8.63636364e+02, 9.11393939e+02,\n",
              "        9.59151515e+02, 1.00690909e+03, 1.05466667e+03, 1.10242424e+03,\n",
              "        1.15018182e+03, 1.19793939e+03, 1.24569697e+03, 1.29345455e+03,\n",
              "        1.34121212e+03, 1.38896970e+03, 1.43672727e+03, 1.48448485e+03,\n",
              "        1.53224242e+03, 1.58000000e+03, 1.62775758e+03, 1.67551515e+03,\n",
              "        1.72327273e+03, 1.77103030e+03, 1.81878788e+03, 1.86654545e+03,\n",
              "        1.91430303e+03, 1.96206061e+03, 2.00981818e+03, 2.05757576e+03,\n",
              "        2.10533333e+03, 2.15309091e+03, 2.20084848e+03, 2.24860606e+03,\n",
              "        2.29636364e+03, 2.34412121e+03, 2.39187879e+03, 2.43963636e+03,\n",
              "        2.48739394e+03, 2.53515152e+03, 2.58290909e+03, 2.63066667e+03,\n",
              "        2.67842424e+03, 2.72618182e+03, 2.77393939e+03, 2.82169697e+03,\n",
              "        2.86945455e+03, 2.91721212e+03, 2.96496970e+03, 3.01272727e+03,\n",
              "        3.06048485e+03, 3.10824242e+03, 3.15600000e+03, 3.20375758e+03,\n",
              "        3.25151515e+03, 3.29927273e+03, 3.34703030e+03, 3.39478788e+03,\n",
              "        3.44254545e+03, 3.49030303e+03, 3.53806061e+03, 3.58581818e+03,\n",
              "        3.63357576e+03, 3.68133333e+03, 3.72909091e+03, 3.77684848e+03,\n",
              "        3.82460606e+03, 3.87236364e+03, 3.92012121e+03, 3.96787879e+03,\n",
              "        4.01563636e+03, 4.06339394e+03, 4.11115152e+03, 4.15890909e+03,\n",
              "        4.20666667e+03, 4.25442424e+03, 4.30218182e+03, 4.34993939e+03,\n",
              "        4.39769697e+03, 4.44545455e+03, 4.49321212e+03, 4.54096970e+03,\n",
              "        4.58872727e+03, 4.63648485e+03, 4.68424242e+03, 4.73200000e+03,\n",
              "        4.77975758e+03, 4.82751515e+03, 4.87527273e+03, 4.92303030e+03,\n",
              "        4.97078788e+03, 5.01854545e+03, 5.06630303e+03, 5.11406061e+03,\n",
              "        5.16181818e+03, 5.20957576e+03, 5.25733333e+03, 5.30509091e+03,\n",
              "        5.35284848e+03, 5.40060606e+03, 5.44836364e+03, 5.49612121e+03,\n",
              "        5.54387879e+03, 5.59163636e+03, 5.63939394e+03, 5.68715152e+03,\n",
              "        5.73490909e+03, 5.78266667e+03, 5.83042424e+03, 5.87818182e+03,\n",
              "        5.92593939e+03, 5.97369697e+03, 6.02145455e+03, 6.06921212e+03,\n",
              "        6.11696970e+03, 6.16472727e+03, 6.21248485e+03, 6.26024242e+03,\n",
              "        6.30800000e+03]),\n",
              " <a list of 132 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT8ElEQVR4nO3dfYxd9X3n8fenPCWboJiHWa/XdnacxtuIrrYGzRJQoioLSgKkW6cSjYyqYGWp3N0lUqJE25hW2ibSIpHVNrSRurTuQuOs0gCbh8XCdFMKRFWkDWScGMJDKJPEEbYMHlIgyUZFa/LdP+7P5GLGnjtz587MPbxf0tX8zu88fQ++fObM75xzb6oKSVK3/MJKFyBJWnqGuyR1kOEuSR1kuEtSBxnuktRBhrskddDA4Z7klCTfSnJnm96U5P4kM0luS3J66z+jTc+0+ZOjKV2SdCILOXP/EPBY3/QngRur6s3As8A1rf8a4NnWf2NbTpK0jDLIQ0xJNgC7geuBjwD/BpgF/klVHU1yMfDxqnp3kq+09v9JcirwFDBRJ9nRueeeW5OTk8MfjSS9iuzbt++ZqpqYa96pA27jj4DfBc5s0+cAz1XV0TZ9EFjf2uuBJwFa8D/fln/mRBufnJxkenp6wFIkSQBJfnCiefMOyyT5NeBIVe1b4qJ2JJlOMj07O7uUm5akV71BxtzfBvx6kgPArcAlwB8Da9qwC8AG4FBrHwI2ArT5bwB+ePxGq2pXVU1V1dTExJx/VUiSFmnecK+q66pqQ1VNAtuAe6vqt4D7gCvbYtuBO1p7T5umzb/3ZOPtkqSlN8x97h8DPpJkht6Y+s2t/2bgnNb/EWDncCVKkhZq0AuqAFTVV4Gvtvb3gAvnWOYfgN9cgtokSYvkE6qS1EGGuyR1kOEuSR1kuEtSB3Uq3Cd37mVy596VLkOSVlynwl2S1GO4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHTRvuCd5TZIHkjyY5JEkn2j9n0ny/ST722tL60+STyeZSfJQkgtGfRCSpJcb5DtUXwAuqaqfJDkN+FqSv2rz/mNVfeG45S8HNrfXW4Gb2k9J0jKZ98y9en7SJk9rrzrJKluBz7b1vg6sSbJu+FIlSYMaaMw9ySlJ9gNHgLur6v426/o29HJjkjNa33rgyb7VD7Y+SdIyGSjcq+rFqtoCbAAuTPIvgOuAtwD/Cjgb+NhCdpxkR5LpJNOzs7MLLFuSdDILulumqp4D7gMuq6rDbejlBeAvgAvbYoeAjX2rbWh9x29rV1VNVdXUxMTE4qqXJM1pkLtlJpKsae3XAu8EvnNsHD1JgPcCD7dV9gBXt7tmLgKer6rDI6lekjSnQe6WWQfsTnIKvV8Gt1fVnUnuTTIBBNgP/Lu2/F3AFcAM8FPgA0tftiTpZOYN96p6CDh/jv5LTrB8AdcOX5okabF8QlWSOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDhrkC7Jfk+SBJA8meSTJJ1r/piT3J5lJcluS01v/GW16ps2fHO0hSJKON8iZ+wvAJVX1K8AW4LIkFwGfBG6sqjcDzwLXtOWvAZ5t/Te25SRJy2jecK+en7TJ09qrgEuAL7T+3cB7W3trm6bNvzRJlqxiSdK8Th1koSSnAPuANwN/AnwXeK6qjrZFDgLrW3s98CRAVR1N8jxwDvDMEtY9kMmde19qH7jhPcu9e0laMQNdUK2qF6tqC7ABuBB4y7A7TrIjyXSS6dnZ2WE3J0nqs6C7ZarqOeA+4GJgTZJjZ/4bgEOtfQjYCNDmvwH44Rzb2lVVU1U1NTExscjyBze5c+/LzuQlqcsGuVtmIsma1n4t8E7gMXohf2VbbDtwR2vvadO0+fdWVS1l0ZKkkxtkzH0dsLuNu/8CcHtV3ZnkUeDWJP8Z+BZwc1v+ZuB/JJkB/h7YNoK6JUknMW+4V9VDwPlz9H+P3vj78f3/APzmklQnSVoUn1CVpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMG+YLsjUnuS/JokkeSfKj1fzzJoST72+uKvnWuSzKT5PEk7x7lAUiSXmmQL8g+Cny0qr6Z5ExgX5K727wbq+q/9i+c5Dx6X4r9y8A/Bf4myT+vqheXsnBJ0onNe+ZeVYer6put/WPgMWD9SVbZCtxaVS9U1feBGeb4Im1J0ugsaMw9ySRwPnB/6/pgkoeS3JLkrNa3Hniyb7WDnPyXgSRpiQ0c7kleD3wR+HBV/Qi4CfhFYAtwGPjDhew4yY4k00mmZ2dnF7KqJGkeA4V7ktPoBfvnqupLAFX1dFW9WFU/A/6cnw+9HAI29q2+ofW9TFXtqqqpqpqamJgY5hgkSccZ5G6ZADcDj1XVp/r61/Ut9hvAw629B9iW5Iwkm4DNwANLV/JwJnfuZXLn3pUuQ5JGapC7Zd4GvB/4dpL9re/3gKuSbAEKOAD8DkBVPZLkduBRenfaXOudMpK0vOYN96r6GpA5Zt11knWuB64foi5J0hB8QlWSOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDhrkPvex40NKkl7tPHOXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjqokw8xDaL/QacDN7xnBSuRpKXnmbskdZDhLkkdNMgXZG9Mcl+SR5M8kuRDrf/sJHcneaL9PKv1J8mnk8wkeSjJBaM+CEnSyw1y5n4U+GhVnQdcBFyb5DxgJ3BPVW0G7mnTAJcDm9trB3DTklctSTqpecO9qg5X1Tdb+8fAY8B6YCuwuy22G3hva28FPls9XwfWJFm35JVLkk5oQWPuSSaB84H7gbVVdbjNegpY29rrgSf7VjvY+iRJy2TgcE/yeuCLwIer6kf986qqgFrIjpPsSDKdZHp2dnYhq0qS5jFQuCc5jV6wf66qvtS6nz423NJ+Hmn9h4CNfatvaH0vU1W7qmqqqqYmJiYWW78kaQ6D3C0T4Gbgsar6VN+sPcD21t4O3NHXf3W7a+Yi4Pm+4RtJ0jIY5AnVtwHvB76dZH/r+z3gBuD2JNcAPwDe1+bdBVwBzAA/BT6wpBVLkuY1b7hX1deAnGD2pXMsX8C1Q9YlSRqCT6hKUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4Q5M7tzL5M69K12GJC0Zw12SOshwl6QOGuQLsm9JciTJw319H09yKMn+9rqib951SWaSPJ7k3aMqXJJ0YoOcuX8GuGyO/hurakt73QWQ5DxgG/DLbZ3/luSUpSpWkjSYecO9qv4W+PsBt7cVuLWqXqiq7wMzwIVD1CdJWoRTh1j3g0muBqaBj1bVs8B64Ot9yxxsfSPjXS6S9EqLvaB6E/CLwBbgMPCHC91Akh1JppNMz87OLrIMSdJcFhXuVfV0Vb1YVT8D/pyfD70cAjb2Lbqh9c21jV1VNVVVUxMTE4spQ5J0AosK9yTr+iZ/Azh2J80eYFuSM5JsAjYDDwxXoiRpoeYdc0/yeeAdwLlJDgJ/ALwjyRaggAPA7wBU1SNJbgceBY4C11bVi6MpXZJ0IvOGe1VdNUf3zSdZ/nrg+mGKkiQNxydUJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3OcwuXMvkzv3rnQZkrRohrskddC84Z7kliRHkjzc13d2kruTPNF+ntX6k+TTSWaSPJTkglEWL0ma2yBn7p8BLjuubydwT1VtBu5p0wCXA5vbawdw09KUKUlaiEG+IPtvk0we170VeEdr7wa+Cnys9X+2qgr4epI1SdZV1eGlKniUHGeX1BWLHXNf2xfYTwFrW3s98GTfcgdbnyRpGQ19QbWdpddC10uyI8l0kunZ2dlhy5Ak9VlsuD+dZB1A+3mk9R8CNvYtt6H1vUJV7aqqqaqampiYWGQZkqS5LDbc9wDbW3s7cEdf/9XtrpmLgOfHZbxdkrpk3guqST5P7+LpuUkOAn8A3ADcnuQa4AfA+9ridwFXADPAT4EPjKBmSdI8Brlb5qoTzLp0jmULuHbYoiRJw/EJVUnqIMNdkjrIcF8gP1RM0jgw3CWpgwx3Seogw12SOshwl6QOMtwlqYPmfYjp1az/rpgDN7xnBSuRpIXxzF2SOshwl6QOMtwlqYMMd0nqIC+oDsiPHJA0Tjxzl6QOMtwlqYMMd0nqIMNdkjpoqAuqSQ4APwZeBI5W1VSSs4HbgEngAPC+qnp2uDIlSQuxFGfu/7qqtlTVVJveCdxTVZuBe9q0JGkZjWJYZiuwu7V3A+8dwT4kSScxbLgX8NdJ9iXZ0frWVtXh1n4KWDvkPiRJCzTsQ0xvr6pDSf4xcHeS7/TPrKpKUnOt2H4Z7AB44xvfOGQZy89PjJS0mg115l5Vh9rPI8CXgQuBp5OsA2g/j5xg3V1VNVVVUxMTE8OUIUk6zqLDPcnrkpx5rA28C3gY2ANsb4ttB+4YtkhJ0sIMMyyzFvhykmPb+cuq+t9JvgHcnuQa4AfA+4YvU5K0EIsO96r6HvArc/T/ELh0mKLGzbHxd8feJa0WPqEqSR1kuEtSBxnuS2hy514/913SqmC4S1IHGe6S1EGGuyR1kOEuSR1kuI+YF1klrYRhPzhMC+QHjklaDob7CHimLmmlGe7LxMCXtJwcc5ekDvLMfcw4Zi9pEIb7Cjp+qGbYsDb4JR3jsMwqstDbJr3NUtKJeOa+Cs0V2J6JS1oIw31MnOwMfTWdvfvFJdLqYLi/SqzGvwb8RSCNzsjG3JNcluTxJDNJdo5qP5KkVxrJmXuSU4A/Ad4JHAS+kWRPVT06iv3pxAYZspnrDHqQ9U52xn38Nr2TR1peoxqWuRCYaV+iTZJbga2A4b5MFjMOv9B1FjvWv9A7go5Z6l8KS7Fth5a0Wo0q3NcDT/ZNHwTeOqJ9aZGW40LsQv5ygLnP9BeyrUG2s1gLPZbja5lrmYX89bPY/Z5sO0u1j4Vuc9hfiqvpGtJijmU5/pJNVS39RpMrgcuq6rfb9PuBt1bVB/uW2QHsaJO/BDy+yN2dCzwzRLmrwbgfg/WvrHGvH8b/GFaq/n9WVRNzzRjVmfshYGPf9IbW95Kq2gXsGnZHSaaramrY7aykcT8G619Z414/jP8xrMb6R3W3zDeAzUk2JTkd2AbsGdG+JEnHGcmZe1UdTfJB4CvAKcAtVfXIKPYlSXqlkT3EVFV3AXeNavt9hh7aWQXG/Risf2WNe/0w/sew6uofyQVVSdLK8lMhJamDxjrcV+tHHCS5JcmRJA/39Z2d5O4kT7SfZ7X+JPl0O4aHklzQt872tvwTSbYvY/0bk9yX5NEkjyT50DgdQ5LXJHkgyYOt/k+0/k1J7m913tYu9pPkjDY90+ZP9m3rutb/eJJ3L0f9ffs+Jcm3ktw5pvUfSPLtJPuTTLe+sXgPtf2uSfKFJN9J8liSi8epfqpqLF/0LtR+F3gTcDrwIHDeStfVavtV4ALg4b6+/wLsbO2dwCdb+wrgr4AAFwH3t/6zge+1n2e19lnLVP864ILWPhP4O+C8cTmGVsfrW/s04P5W1+3Attb/p8C/b+3/APxpa28Dbmvt89r76gxgU3u/nbKM76OPAH8J3Nmmx63+A8C5x/WNxXuo7Xs38NutfTqwZqzqX65/6BH8h78Y+Erf9HXAdStdV189k7w83B8H1rX2OuDx1v4z4KrjlwOuAv6sr/9lyy3zsdxB73OCxu4YgH8EfJPeE9LPAKce//6hd1fXxa19alsux7+n+pdbhro3APcAlwB3tnrGpv62vwO8MtzH4j0EvAH4Pu265LjVX1VjPSwz10ccrF+hWgaxtqoOt/ZTwNrWPtFxrIrja3/in0/v7HdsjqENaewHjgB30ztrfa6qjs5Ry0t1tvnPA+ewsv8GfwT8LvCzNn0O41U/QAF/nWRfek+kw/i8hzYBs8BftKGx/57kdYxP/WMd7mOrer/CV/1tSkleD3wR+HBV/ah/3mo/hqp6saq20DsDvhB4ywqXNLAkvwYcqap9K13LkN5eVRcAlwPXJvnV/pmr/D10Kr2h1Zuq6nzg/9IbhnnJKq9/rMN93o84WGWeTrIOoP080vpPdBwrenxJTqMX7J+rqi+17rE6BoCqeg64j94wxpokx57t6K/lpTrb/DcAP2Tl6n8b8OtJDgC30hua+WPGp34AqupQ+3kE+DK9X7Lj8h46CBysqvvb9Bfohf241D/W4T5uH3GwBzh2pXw7vXHsY/1Xt6vtFwHPtz/7vgK8K8lZ7Yr8u1rfyCUJcDPwWFV9atyOIclEkjWt/Vp61wseoxfyV56g/mPHdSVwbzsr2wNsa3ejbAI2Aw+Muv6quq6qNlTVJL339b1V9VvjUj9AktclOfNYm96//cOMyXuoqp4CnkzyS63rUnofWT4W9R87iLF90btC/Xf0xlN/f6Xr6avr88Bh4P/ROwO4ht4Y6D3AE8DfAGe3ZUPvi02+C3wbmOrbzr8FZtrrA8tY/9vp/bn5ELC/va4Yl2MA/iXwrVb/w8B/av1vohduM8D/BM5o/a9p0zNt/pv6tvX77bgeBy5fgffSO/j53TJjU3+r9cH2euTY/5/j8h5q+90CTLf30f+id7fL2NTvE6qS1EHjPCwjSToBw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamD/j9xHck4s7Zy2gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train_lengths), max(train_lengths)"
      ],
      "metadata": {
        "id": "fkSg5eaga6cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b13265-b3d4-4f6b-cc64-2ff5a5b05c6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6308)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQvCZEwhCsTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "0a24j9vdPTrr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "SItHYahBR0BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from math import floor\n",
        "\n",
        "# converting train to tensors\n",
        "# train = [[torch.from_numpy(t[0].astype(int)).float(), torch.from_numpy(np.ndarray([int(t[1])]))] for t in train]\n",
        "train_data = [[torch.from_numpy(t[0].astype(int)).float(), int(t[1])] for t in train]\n",
        "\n",
        "dataset_length = len(train_data)\n",
        "val_size = floor(dataset_length * VALIDATION_PERCENTAGE)\n",
        "train_size = dataset_length - val_size\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
        "\n",
        "train_subset_data = [item[0] for item in train_subset]\n",
        "train_subset_targets = [item[1] for item in train_subset]\n",
        "\n",
        "val_subset_data = [item[0] for item in val_subset]\n",
        "val_subset_targets = [item[1] for item in val_subset]\n",
        "\n",
        "train_set = VariableLenDataset(train_subset_data, train_subset_targets)\n",
        "val_set = VariableLenDataset(val_subset_data, val_subset_targets)"
      ],
      "metadata": {
        "id": "sEm_rXS2TX4r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy"
      ],
      "metadata": {
        "id": "BvgU5pn2PTua"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "p8ShbxngPTxK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2H1pWKZyMu",
        "outputId": "16583723-0c8e-4831-f2b9-e08a721594f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[145., 145.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ -1., 112.,  34.,  ...,   0.,   0.,   0.],\n",
              "         [ -1.,  -1.,  -1.,  ...,   0.,   0.,  -1.],\n",
              "         ...,\n",
              "         [110., 185.,  88.,  ...,   0.,   0.,   0.],\n",
              "         [ 12.,  12.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ 21., 116.,  21.,  ...,   0.,   0.,   0.]]),\n",
              " (0, 4, 1, 4, 3, 0, 0, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CmMtriGMPSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        # pass the input through the LSTM layer\n",
        "        # print(x.shape)\n",
        "        # print(hidden[0].size(0))\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "\n",
        "        # print(\"OUT\", out.shape)\n",
        "        \n",
        "        # get the last output of the LSTM layer\n",
        "        out = out[-1, :, :]\n",
        "\n",
        "        # print(\"OUT2\", out.shape)\n",
        "        \n",
        "        # pass the last output through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # print(\"OUT3\", out.shape)\n",
        "        \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "W2TSYGhAa6i-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "model = LSTMRegressor(1,20,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kLQzbaPTow",
        "outputId": "ea449374-f520-4c5d-b64b-5af09a9f0924"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 20, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Sn-tXvwIG83R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "best_model = None\n",
        "best_model_acc = None\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1500):\n",
        "    for x, targets in train_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # print(\"A\")\n",
        "        preds = model(x, (hidden, state))\n",
        "        # print(\"B\")\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "        # preds = preds.squeeze(2)\n",
        "        # print(\"PREDS\", preds.shape)\n",
        "        # preds = preds[:,-1,:]\n",
        "        \n",
        "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "        \n",
        "        # preds = preds.squeeze(2)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    epochs.append(epoch)\n",
        "\n",
        "    # evaluate the model on the validation set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, targets in val_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        preds = model(x, (hidden, state))\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(x, (hidden, state))\n",
        "\n",
        "        # get the predicted labels\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "        # compute the accuracy\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    \n",
        "\n",
        "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")\n",
        "\n",
        "    val_acc.append(100 * correct / total)\n",
        "\n",
        "    if best_model is None or (correct / total) > best_model_acc:\n",
        "        best_model = model\n",
        "        best_model_acc = correct / total\n",
        "\n",
        "    # print the accuracy\n",
        "    print(f\"Accuracy on the validation set: {100 * correct / total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAWo9YRg3BLo",
        "outputId": "0839574d-e614-43f1-ba79-13a9219e6f82"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.169\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 1, loss: 0.0135\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 2, loss: 0.114\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 3, loss: 0.283\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 4, loss: 0.903\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 5, loss: 0.109\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 6, loss: 0.588\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 7, loss: 0.295\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 8, loss: 0.564\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 9, loss: 0.217\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 10, loss: 0.66\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 11, loss: 0.107\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 12, loss: 0.905\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 13, loss: 0.318\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 14, loss: 0.0761\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 15, loss: 0.358\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 16, loss: 0.282\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 17, loss: 0.205\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 18, loss: 0.19\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 19, loss: 0.162\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 20, loss: 0.0502\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 21, loss: 0.243\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 22, loss: 0.243\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 23, loss: 0.569\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 24, loss: 0.436\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 25, loss: 0.0675\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 26, loss: 0.139\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 27, loss: 1.1\n",
            "Accuracy on the validation set: 70.30716723549489\n",
            "Epoch: 28, loss: 0.0206\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 29, loss: 0.0845\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 30, loss: 1.1\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 31, loss: 0.232\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 32, loss: 0.0156\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 33, loss: 0.439\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 34, loss: 0.46\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 35, loss: 0.785\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 36, loss: 0.0379\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 37, loss: 0.12\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 38, loss: 0.916\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 39, loss: 0.167\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 40, loss: 0.146\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 41, loss: 0.78\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 42, loss: 0.136\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 43, loss: 1.93\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 44, loss: 0.0214\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 45, loss: 0.382\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 46, loss: 0.0786\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 47, loss: 0.0388\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 48, loss: 0.524\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 49, loss: 0.228\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 50, loss: 0.1\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 51, loss: 0.787\n",
            "Accuracy on the validation set: 70.30716723549489\n",
            "Epoch: 52, loss: 0.609\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 53, loss: 0.467\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 54, loss: 0.464\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 55, loss: 0.145\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 56, loss: 0.155\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 57, loss: 0.586\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 58, loss: 0.0224\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 59, loss: 0.214\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 60, loss: 0.16\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 61, loss: 2.3\n",
            "Accuracy on the validation set: 65.52901023890784\n",
            "Epoch: 62, loss: 0.264\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 63, loss: 0.187\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 64, loss: 0.174\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 65, loss: 0.147\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 66, loss: 0.828\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 67, loss: 0.506\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 68, loss: 0.235\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 69, loss: 0.0428\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 70, loss: 0.182\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 71, loss: 0.101\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 72, loss: 0.127\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 73, loss: 0.784\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 74, loss: 0.494\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 75, loss: 1.28\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 76, loss: 0.166\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 77, loss: 0.95\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 78, loss: 0.55\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 79, loss: 0.0279\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 80, loss: 0.203\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 81, loss: 0.317\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 82, loss: 0.674\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 83, loss: 0.0136\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 84, loss: 0.149\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 85, loss: 0.139\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 86, loss: 0.0208\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 87, loss: 0.427\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 88, loss: 0.91\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 89, loss: 0.152\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 90, loss: 0.189\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 91, loss: 0.178\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 92, loss: 0.0771\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 93, loss: 0.58\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 94, loss: 0.16\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 95, loss: 0.367\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 96, loss: 0.151\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 97, loss: 0.301\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 98, loss: 0.129\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 99, loss: 0.278\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 100, loss: 0.458\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 101, loss: 1.33\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 102, loss: 0.113\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 103, loss: 0.526\n",
            "Accuracy on the validation set: 76.79180887372014\n",
            "Epoch: 104, loss: 0.0534\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 105, loss: 0.425\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 106, loss: 0.073\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 107, loss: 0.0151\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 108, loss: 0.135\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 109, loss: 0.0146\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 110, loss: 0.639\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 111, loss: 0.196\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 112, loss: 0.0524\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 113, loss: 1.64\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 114, loss: 0.154\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 115, loss: 0.0739\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 116, loss: 0.144\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 117, loss: 0.999\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 118, loss: 0.578\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 119, loss: 0.372\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 120, loss: 0.0109\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 121, loss: 0.424\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 122, loss: 0.499\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 123, loss: 0.168\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 124, loss: 0.686\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 125, loss: 0.0919\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 126, loss: 0.31\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 127, loss: 0.046\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 128, loss: 0.616\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 129, loss: 0.541\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 130, loss: 0.504\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 131, loss: 0.0934\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 132, loss: 0.0991\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 133, loss: 0.33\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 134, loss: 0.137\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 135, loss: 0.288\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 136, loss: 1.83\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 137, loss: 0.059\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 138, loss: 0.583\n",
            "Accuracy on the validation set: 70.64846416382252\n",
            "Epoch: 139, loss: 0.0537\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 140, loss: 0.101\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 141, loss: 0.191\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 142, loss: 0.0729\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 143, loss: 0.667\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 144, loss: 0.0805\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 145, loss: 0.403\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 146, loss: 0.323\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 147, loss: 0.0109\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 148, loss: 0.164\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 149, loss: 1.32\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 150, loss: 0.166\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 151, loss: 0.081\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 152, loss: 0.144\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 153, loss: 0.166\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 154, loss: 0.812\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 155, loss: 0.469\n",
            "Accuracy on the validation set: 70.30716723549489\n",
            "Epoch: 156, loss: 0.584\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 157, loss: 0.254\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 158, loss: 0.457\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 159, loss: 0.211\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 160, loss: 0.156\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 161, loss: 0.0124\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 162, loss: 0.732\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 163, loss: 0.279\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 164, loss: 0.123\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 165, loss: 0.387\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 166, loss: 0.668\n",
            "Accuracy on the validation set: 76.79180887372014\n",
            "Epoch: 167, loss: 1.24\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 168, loss: 0.177\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 169, loss: 0.397\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 170, loss: 0.128\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 171, loss: 0.371\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 172, loss: 0.273\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 173, loss: 0.235\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 174, loss: 0.0561\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 175, loss: 0.0735\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 176, loss: 0.0503\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 177, loss: 0.786\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 178, loss: 0.0923\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 179, loss: 0.705\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 180, loss: 0.481\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 181, loss: 0.0959\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 182, loss: 0.909\n",
            "Accuracy on the validation set: 68.9419795221843\n",
            "Epoch: 183, loss: 0.0959\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 184, loss: 0.142\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 185, loss: 0.0312\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 186, loss: 0.0523\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 187, loss: 0.0435\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 188, loss: 0.0917\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 189, loss: 0.461\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 190, loss: 0.0417\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 191, loss: 0.471\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 192, loss: 0.743\n",
            "Accuracy on the validation set: 67.91808873720136\n",
            "Epoch: 193, loss: 0.36\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 194, loss: 0.0664\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 195, loss: 0.333\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 196, loss: 0.445\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 197, loss: 0.272\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 198, loss: 0.113\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 199, loss: 0.0461\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 200, loss: 0.0554\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 201, loss: 0.0298\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 202, loss: 0.0652\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 203, loss: 0.0276\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 204, loss: 0.0644\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 205, loss: 1.02\n",
            "Accuracy on the validation set: 76.79180887372014\n",
            "Epoch: 206, loss: 0.179\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 207, loss: 0.216\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 208, loss: 0.0777\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 209, loss: 0.477\n",
            "Accuracy on the validation set: 77.13310580204778\n",
            "Epoch: 210, loss: 0.838\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 211, loss: 0.338\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 212, loss: 0.0255\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 213, loss: 0.625\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 214, loss: 0.192\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 215, loss: 0.093\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 216, loss: 0.0827\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 217, loss: 0.223\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 218, loss: 0.375\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 219, loss: 0.332\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 220, loss: 0.0743\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 221, loss: 1.1\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 222, loss: 0.393\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 223, loss: 0.988\n",
            "Accuracy on the validation set: 69.28327645051195\n",
            "Epoch: 224, loss: 0.0399\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 225, loss: 0.0332\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 226, loss: 0.718\n",
            "Accuracy on the validation set: 70.64846416382252\n",
            "Epoch: 227, loss: 1.01\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 228, loss: 0.306\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 229, loss: 0.19\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 230, loss: 0.029\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 231, loss: 0.0932\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 232, loss: 0.0368\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 233, loss: 0.268\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 234, loss: 0.249\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 235, loss: 0.112\n",
            "Accuracy on the validation set: 77.47440273037543\n",
            "Epoch: 236, loss: 0.106\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 237, loss: 0.0317\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 238, loss: 0.286\n",
            "Accuracy on the validation set: 70.64846416382252\n",
            "Epoch: 239, loss: 0.771\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 240, loss: 0.282\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 241, loss: 0.318\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 242, loss: 0.274\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 243, loss: 0.119\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 244, loss: 0.151\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 245, loss: 0.0676\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 246, loss: 0.0215\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 247, loss: 0.885\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 248, loss: 0.121\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 249, loss: 0.21\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 250, loss: 0.152\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 251, loss: 0.117\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 252, loss: 0.0213\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 253, loss: 0.814\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 254, loss: 0.39\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 255, loss: 0.356\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 256, loss: 0.25\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 257, loss: 0.0194\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 258, loss: 0.213\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 259, loss: 0.456\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 260, loss: 0.21\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 261, loss: 0.134\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 262, loss: 0.0648\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 263, loss: 0.561\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 264, loss: 0.248\n",
            "Accuracy on the validation set: 68.9419795221843\n",
            "Epoch: 265, loss: 0.225\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 266, loss: 0.138\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 267, loss: 0.0173\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 268, loss: 0.224\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 269, loss: 0.355\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 270, loss: 0.175\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 271, loss: 0.0312\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 272, loss: 0.44\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 273, loss: 0.205\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 274, loss: 0.281\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 275, loss: 0.138\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 276, loss: 0.163\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 277, loss: 0.0645\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 278, loss: 0.716\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 279, loss: 0.211\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 280, loss: 0.087\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 281, loss: 0.401\n",
            "Accuracy on the validation set: 70.30716723549489\n",
            "Epoch: 282, loss: 0.348\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 283, loss: 1.11\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 284, loss: 0.132\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 285, loss: 0.159\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 286, loss: 0.116\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 287, loss: 0.277\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 288, loss: 0.167\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 289, loss: 0.477\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 290, loss: 0.0628\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 291, loss: 0.1\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 292, loss: 0.362\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 293, loss: 0.0795\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 294, loss: 0.142\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 295, loss: 0.0316\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 296, loss: 0.194\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 297, loss: 0.0116\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 298, loss: 0.44\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 299, loss: 0.32\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 300, loss: 0.162\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 301, loss: 0.291\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 302, loss: 0.223\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 303, loss: 0.124\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 304, loss: 0.396\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 305, loss: 0.609\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 306, loss: 0.548\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 307, loss: 0.0187\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 308, loss: 0.271\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 309, loss: 0.0554\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 310, loss: 0.118\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 311, loss: 0.151\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 312, loss: 0.149\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 313, loss: 0.482\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 314, loss: 0.903\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 315, loss: 0.114\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 316, loss: 0.0716\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 317, loss: 0.153\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 318, loss: 0.299\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 319, loss: 0.0205\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 320, loss: 0.638\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 321, loss: 0.0562\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 322, loss: 0.0414\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 323, loss: 0.151\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 324, loss: 0.213\n",
            "Accuracy on the validation set: 78.49829351535836\n",
            "Epoch: 325, loss: 0.3\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 326, loss: 0.205\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 327, loss: 0.417\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 328, loss: 0.0293\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 329, loss: 0.125\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 330, loss: 0.00939\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 331, loss: 0.911\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 332, loss: 0.0676\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 333, loss: 0.277\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 334, loss: 0.712\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 335, loss: 0.351\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 336, loss: 0.0406\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 337, loss: 0.0127\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 338, loss: 0.0194\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 339, loss: 0.189\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 340, loss: 0.294\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 341, loss: 0.411\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 342, loss: 0.503\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 343, loss: 0.707\n",
            "Accuracy on the validation set: 70.64846416382252\n",
            "Epoch: 344, loss: 0.0183\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 345, loss: 0.154\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 346, loss: 0.0626\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 347, loss: 0.0589\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 348, loss: 0.54\n",
            "Accuracy on the validation set: 77.81569965870307\n",
            "Epoch: 349, loss: 0.0659\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 350, loss: 0.799\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 351, loss: 0.277\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 352, loss: 0.00903\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 353, loss: 0.0792\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 354, loss: 0.0327\n",
            "Accuracy on the validation set: 69.62457337883959\n",
            "Epoch: 355, loss: 0.77\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 356, loss: 0.088\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 357, loss: 0.0209\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 358, loss: 0.0366\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 359, loss: 0.0793\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 360, loss: 0.41\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 361, loss: 0.178\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 362, loss: 0.0418\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 363, loss: 0.0166\n",
            "Accuracy on the validation set: 76.79180887372014\n",
            "Epoch: 364, loss: 0.269\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 365, loss: 0.612\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 366, loss: 0.784\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 367, loss: 0.804\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 368, loss: 0.0664\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 369, loss: 0.0594\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 370, loss: 0.032\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 371, loss: 0.0507\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 372, loss: 0.141\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 373, loss: 0.2\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 374, loss: 0.159\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 375, loss: 0.45\n",
            "Accuracy on the validation set: 78.15699658703072\n",
            "Epoch: 376, loss: 0.583\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 377, loss: 0.0755\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 378, loss: 0.0901\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 379, loss: 0.934\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 380, loss: 0.11\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 381, loss: 0.0741\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 382, loss: 0.0842\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 383, loss: 0.0585\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 384, loss: 0.601\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 385, loss: 0.0183\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 386, loss: 0.052\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 387, loss: 0.177\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 388, loss: 0.018\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 389, loss: 0.107\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 390, loss: 0.136\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 391, loss: 0.966\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 392, loss: 0.424\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 393, loss: 0.0703\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 394, loss: 0.0419\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 395, loss: 1.3\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 396, loss: 0.0385\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 397, loss: 0.141\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 398, loss: 0.258\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 399, loss: 0.147\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 400, loss: 0.15\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 401, loss: 0.219\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 402, loss: 0.0158\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 403, loss: 0.0938\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 404, loss: 0.259\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 405, loss: 0.237\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 406, loss: 0.0884\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 407, loss: 0.105\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 408, loss: 0.0514\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 409, loss: 0.0106\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 410, loss: 0.105\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 411, loss: 0.036\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 412, loss: 0.0659\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 413, loss: 0.033\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 414, loss: 0.0797\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 415, loss: 0.0129\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 416, loss: 0.0554\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 417, loss: 0.106\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 418, loss: 0.106\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 419, loss: 0.0276\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 420, loss: 0.347\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 421, loss: 0.129\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 422, loss: 0.0484\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 423, loss: 0.0556\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 424, loss: 0.752\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 425, loss: 0.0163\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 426, loss: 0.749\n",
            "Accuracy on the validation set: 76.45051194539249\n",
            "Epoch: 427, loss: 0.194\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 428, loss: 0.0694\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 429, loss: 0.121\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 430, loss: 0.0235\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 431, loss: 0.161\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 432, loss: 0.103\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 433, loss: 0.0446\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 434, loss: 0.33\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 435, loss: 0.28\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 436, loss: 0.208\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 437, loss: 0.587\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 438, loss: 0.0321\n",
            "Accuracy on the validation set: 77.47440273037543\n",
            "Epoch: 439, loss: 0.574\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 440, loss: 0.788\n",
            "Accuracy on the validation set: 72.0136518771331\n",
            "Epoch: 441, loss: 0.42\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 442, loss: 0.0611\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 443, loss: 0.0835\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 444, loss: 0.427\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 445, loss: 0.231\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 446, loss: 0.803\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 447, loss: 0.277\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 448, loss: 0.0895\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 449, loss: 0.0833\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 450, loss: 0.0619\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 451, loss: 0.138\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 452, loss: 0.144\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 453, loss: 2.3\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 454, loss: 0.054\n",
            "Accuracy on the validation set: 71.67235494880546\n",
            "Epoch: 455, loss: 0.0289\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 456, loss: 0.0596\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 457, loss: 0.0467\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 458, loss: 0.074\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 459, loss: 0.0303\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 460, loss: 2.26\n",
            "Accuracy on the validation set: 70.30716723549489\n",
            "Epoch: 461, loss: 0.655\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 462, loss: 0.161\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 463, loss: 0.588\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 464, loss: 0.0119\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 465, loss: 0.0196\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 466, loss: 0.0352\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 467, loss: 0.038\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 468, loss: 0.208\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 469, loss: 0.0126\n",
            "Accuracy on the validation set: 70.64846416382252\n",
            "Epoch: 470, loss: 0.0124\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 471, loss: 0.45\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 472, loss: 0.0434\n",
            "Accuracy on the validation set: 73.03754266211604\n",
            "Epoch: 473, loss: 0.0157\n",
            "Accuracy on the validation set: 76.10921501706484\n",
            "Epoch: 474, loss: 0.0753\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 475, loss: 0.0255\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 476, loss: 0.131\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 477, loss: 0.0557\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 478, loss: 0.02\n",
            "Accuracy on the validation set: 74.40273037542661\n",
            "Epoch: 479, loss: 1.78\n",
            "Accuracy on the validation set: 69.96587030716724\n",
            "Epoch: 480, loss: 0.025\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 481, loss: 0.0139\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 482, loss: 0.0979\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 483, loss: 0.279\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 484, loss: 1.6\n",
            "Accuracy on the validation set: 75.42662116040955\n",
            "Epoch: 485, loss: 0.121\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 486, loss: 0.387\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 487, loss: 0.0329\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 488, loss: 0.078\n",
            "Accuracy on the validation set: 75.08532423208192\n",
            "Epoch: 489, loss: 0.0214\n",
            "Accuracy on the validation set: 73.37883959044369\n",
            "Epoch: 490, loss: 0.28\n",
            "Accuracy on the validation set: 72.35494880546075\n",
            "Epoch: 491, loss: 0.198\n",
            "Accuracy on the validation set: 70.98976109215018\n",
            "Epoch: 492, loss: 0.168\n",
            "Accuracy on the validation set: 75.7679180887372\n",
            "Epoch: 493, loss: 0.115\n",
            "Accuracy on the validation set: 73.72013651877133\n",
            "Epoch: 494, loss: 0.0626\n",
            "Accuracy on the validation set: 74.74402730375427\n",
            "Epoch: 495, loss: 0.0959\n",
            "Accuracy on the validation set: 74.06143344709898\n",
            "Epoch: 496, loss: 0.0895\n",
            "Accuracy on the validation set: 67.91808873720136\n",
            "Epoch: 497, loss: 0.557\n",
            "Accuracy on the validation set: 72.6962457337884\n",
            "Epoch: 498, loss: 0.132\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "Epoch: 499, loss: 0.074\n",
            "Accuracy on the validation set: 71.33105802047781\n",
            "CPU times: user 22min 11s, sys: 29.5 s, total: 22min 41s\n",
            "Wall time: 21min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(epochs, losses, val_acc):\n",
        "    # plotting\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(\"Validation acc\")\n",
        "    plt.plot(epochs, val_acc, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "id": "K-s5mTUxSjOJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(epochs, losses, val_acc)"
      ],
      "metadata": {
        "id": "iCwAflsXSjQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b0de7586-0d89-4fd8-9c9d-42a1550de10e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model to file\n",
        "state_dict = model.state_dict()\n",
        "torch.save(state_dict, \"neural_net.tar\")"
      ],
      "metadata": {
        "id": "7wsHi_yyLtge"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving bes model to file\n",
        "state_dict = best_model.state_dict()\n",
        "torch.save(state_dict, \"best_neural_net.tar\")"
      ],
      "metadata": {
        "id": "fLPBbG134ncv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on the validation set: \", best_model_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i4Ta2PD439d",
        "outputId": "1ef27bf2-774f-4a2c-f0ed-0b891d764b1d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the validation set:  0.7849829351535836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on test set"
      ],
      "metadata": {
        "id": "ajFynd6s9Ldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TEST_PATH, 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "wc1Q0Gne9KaU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6RUWhCm9M8E",
        "outputId": "ed0f686e-c120-4065-94c3-2d6fd6ba07b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCUegF_H9M-f",
        "outputId": "b732b4b8-d21c-40a7-99bc-2e9ba8e39095"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd889797250>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [torch.from_numpy(t.astype(int)).float() for t in test_data]"
      ],
      "metadata": {
        "id": "5P2d0O2df28D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = VariableLenDataset(test_data, [0 for t in test_data])"
      ],
      "metadata": {
        "id": "FD-YF1cgYLBt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "MOFb5U4TYLEM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for x, label in test_loader:\n",
        "  print(x)\n",
        "  hidden, state = model.init_hidden(x.shape[0])\n",
        "  hidden, state = hidden.to(device), state.to(device)\n",
        "  x = x.to(device).unsqueeze(2)\n",
        "  x = torch.transpose(x, 0, 1)\n",
        "  new_preds = model(x, (hidden, state))\n",
        "  for new_pred in new_preds:\n",
        "    preds.append(new_pred.max(0, keepdim=True)[1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsEGLP2TYLHE",
        "outputId": "891e2ea1-1402-4b00-ac3a-c765b8c44331"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0.,   2.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  64.,  64.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [144.,  69., 100.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ 12.,  47.,  28.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ 12.,  47.,  47.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  7., 158.,  92.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ 67.,  47.,  47.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1.,  0.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0., 12., 12.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.]])\n",
            "tensor([[ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  32., 114.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,  13., 125.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,  92.,  13.,  ...,   0.,   0.,   0.],\n",
            "        [  1.,  20.,  47.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 34., 121.,  76.,  ...,   0.,   0.,   0.],\n",
            "        [ 12.,  13.,  28.,  ...,   0.,   0.,   0.],\n",
            "        [ 64., 180., 180.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ 67.,   0., 159.,  ...,   0.,   0.,   0.],\n",
            "        [ 41.,  47.,  30.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0.,   3.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1., 112.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  64.,  65.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  13.,   5.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ -1.,  -1., 145.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ -1., 144.,  50.,  ...,   0.,   0.,   0.],\n",
            "        [ -1., 144., 180.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,   3.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  47.,  47.,  ...,   0.,   0.,   0.],\n",
            "        [144., 144., 144.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  0.,  12.,  47.,  ...,   0.,   0.,   0.],\n",
            "        [145.,  92.,  88.,  ...,   0.,   0.,   0.],\n",
            "        [144., 144., 100.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[144.,   6.,  47.,  ...,   0.,   0.,   0.],\n",
            "        [ 34.,  34., 100.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,  67., 180.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ 84., 191., 191.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  34.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[100., 124.,  37.,  ...,   0.,   0.,   0.],\n",
            "        [ 82.,  92.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [ 67.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  0.,  67.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [  8.,  12., 146.,  ...,   0.,   0.,   0.],\n",
            "        [153.,  47., 132.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ 73.,  88.,  92.,  ...,   0.,   0.,   0.],\n",
            "        [112.,  68.,  88.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  0.,   0.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [ 32., 146.,  65.,  ...,   0.,   0.,   0.],\n",
            "        [145., 145.,  47.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,   0.,  67.,  ...,   0.,   0.,   0.],\n",
            "        [112.,   0.,   1.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,  82.,  82.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1.,  0.,  ...,  0.,  0.,  0.],\n",
            "        [-1., 67.,  0.,  ...,  0.,  0.,  0.]])\n",
            "tensor([[ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 64., 145., 145.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0., 159.,  ...,   0.,   0.,   0.],\n",
            "        [ 64.,   0., 179.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,   0.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [145.,  92., 156.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,   0.,   0.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1., 145.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  80.,  ...,   0.,   0.,   0.],\n",
            "        [ -1., 112.,   0.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  0.,  13.,  79.,  ...,   0.,   0.,   0.],\n",
            "        [  0., 159.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [100., 159., 117.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,   0.],\n",
            "        [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
            "        [ 32.,  32.,  32.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[145.,  12., 156.,  ...,   0.,   0.,   0.],\n",
            "        [145.,  12.,  42.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0., 112.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ -1.,  -1.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1., 144.,  ...,   0.,   0.,   0.],\n",
            "        [128., 128., 128.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
            "        [  1.,  53.,  53.,  ...,   0.,   0.,   0.],\n",
            "        [114.,   4.,  89.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 68., 124.,  12.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1., 112.,  ...,   0.,   0.,   0.],\n",
            "        [ 80.,  80.,  92.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ -1.,  -1.,   2.,  ...,   0.,   0.,   0.],\n",
            "        [ 64.,  64.,  66.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  66.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 33.,  50., 121.,  ...,   0.,   0.,   0.],\n",
            "        [ 80.,  80.,  80.,  ...,   0.,   0.,   0.],\n",
            "        [ 34.,  68., 120.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ -1.,  -1., 112.,  ...,   0.,   0.,   0.],\n",
            "        [ 32.,  32.,  20.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,  -1.,  80.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 80.,  80.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ -1.,   0., 114.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0., 114.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[ 64.,  64.,  64.,  ...,   0.,   0.,   0.],\n",
            "        [144., 144., 145.,  ...,   0.,   0.,   0.],\n",
            "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [  1.,   9.,  60.,  ...,   0.,   0.,   0.],\n",
            "        [112., 112.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [112., 112., 112.,  ...,   0.,   0.,   0.]])\n",
            "tensor([[176., 176.,  66., 146., 124., 190.,  77., 185., 157., 119., 124.,  68.,\n",
            "          68., 149.,  44.,  45., 124.,  45.,  79., 149., 149.,  60.,  45.,  47.,\n",
            "          45.,  73.,  12., 120.,  13.,  13.,  45., 121.,  60.,  92.,   5.,  33.,\n",
            "          33., 180., 180.,  20.,  44.,  44.,  45.,  79., 149., 149.,  44.,  20.,\n",
            "          74.,  47.,  92.,  60.,  44.,  44.,  60.,  60., 157.,  76.,  78.,  44.,\n",
            "          44., 149.,  44.,  79.,  78.,  12.,  12.,  73.,  71.,  72.,  45.,  73.,\n",
            "          73., 112., 124., 191., 156.,  41.,  13., 124., 124.,  79., 109., 185.,\n",
            "         185., 112., 124., 191., 156.,  41.,  13., 124., 124.,  79., 109., 185.,\n",
            "         185.,  74.,  74.,  45., 159.,   8., 159.,  45.,  74.,  45., 159.,   8.,\n",
            "         159.,  45., 127., 127.,  13.,  45.,  36., 119.,   8.,   8., 159.,  92.,\n",
            "         159., 159.,  45.,  38.,  93., 124., 190., 156., 143., 190., 190.,  45.,\n",
            "          45.,  92.,  47.,  71.,  72.,  45.,  73.,  73.,  73.,  12.,   0.,   0.,\n",
            "           0.,  12.,  73.,  73.,  73.],\n",
            "        [ 32.,  32.,  32.,  32.,  33.,  78.,  92.,  33.,  33.,  33.,  13., 185.,\n",
            "         132., 132.,  71.,  74., 146., 146.,  77.,  77., 124., 100., 120.,  45.,\n",
            "          92., 125., 125., 157.,  44., 125.,   5., 125.,  12.,  28.,  60.,  33.,\n",
            "          60.,  92.,  47., 180., 180.,  78.,  78., 172.,  38.,  44.,  78.,  30.,\n",
            "          44.,  37.,  37.,  37.,  45.,  66.,  68., 100., 132.,  98.,  40., 152.,\n",
            "          34.,  34., 159.,  13., 158.,  40.,  44., 180.,  41., 108.,  62., 146.,\n",
            "          58.,  45.,  37., 177.,  30.,  60., 168., 146.,  58.,  33.,  33.,  78.,\n",
            "         125.,  41.,  28.,  13.,  60.,  40.,  97.,  97.,  97.,  97.,  97.,  97.,\n",
            "         185., 176.,  35., 164.,  56., 146.,  44.,  45.,  79., 157.,  92., 172.,\n",
            "         125.,  92., 157.,  44.,  44.,  39., 190., 132.,  30.,  25.,  44., 190.,\n",
            "          15.,   5., 109.,  25.,  12., 125.,  92., 117.,  44., 149., 124.,  12.,\n",
            "          92.,  28.,  30.,  44., 124.,  42.,  47., 117.,  28.,  78.,  30.,  25.,\n",
            "          44.,  37.,  -1.,  -1.,   0.],\n",
            "        [144., 144., 144.,  34.,  34.,  32.,  33.,  80.,  88., 152., 156., 144.,\n",
            "          40., 121.,  60.,  41.,   8.,  37., 156., 144.,  44.,  32., 124., 112.,\n",
            "         112.,   8.,   8., 112., 117.,  12., 124.,  32., 124., 190.,   8., 190.,\n",
            "          13.,  88.,  92.,  88.,  92.,   8.,  12.,  92., 172.,  37., 127., 144.,\n",
            "          44.,  33.,  47.,  92.,  78.,  41.,  44.,  92.,  44.,  32.,  45.,  12.,\n",
            "          77.,  44.,  30.,  37., 127.,  40.,  44.,  33.,  33.,  33.,  77., 119.,\n",
            "          12.,  20.,  44.,  33.,  33.,  47., 125., 112.,  44., 144.,  44.,  32.,\n",
            "         124.,  12.,  12., 119., 125.,  40.,  44.,  39., 172., 113., 127.,  33.,\n",
            "          60.,  73.,  44., 124., 172., 121., 127.,  40.,  44.,  39., 172., 113.,\n",
            "          37., 120., 149.,  33.,  33.,  33., 127.,  37.,  37., 120.,  96.,  96.,\n",
            "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "           0.,   0.,   0.,   0.,   0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_filename = \"preds.csv\"\n",
        "pd.DataFrame({'A': preds}).to_csv(preds_filename, index=False, header=False)"
      ],
      "metadata": {
        "id": "jHYTyOE8ehGP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(preds_filename, header=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PCdB4mfVehJB",
        "outputId": "6aeb7dba-94ed-4142-d919-4f177394dd9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0\n",
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "...  ..\n",
              "1098  1\n",
              "1099  4\n",
              "1100  1\n",
              "1101  2\n",
              "1102  3\n",
              "\n",
              "[1103 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52dde0c8-78b6-44be-a4d8-9d0be55924d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1098</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1103 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52dde0c8-78b6-44be-a4d8-9d0be55924d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52dde0c8-78b6-44be-a4d8-9d0be55924d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52dde0c8-78b6-44be-a4d8-9d0be55924d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhRheNLg19CZ"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}