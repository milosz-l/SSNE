{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, setting up device and seeds\n"
      ],
      "metadata": {
        "id": "bWqIz6BsrIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "-RiHHnHEi7Vc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_all_seeds(42)"
      ],
      "metadata": {
        "id": "dF7Jzby3i-I6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.set_device(1)\n",
        "device = torch.device(\"cuda\")\n",
        "# device = torch.device('mps')\n",
        "# device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "-BCkcrW5i9kE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive"
      ],
      "metadata": {
        "id": "A2P1P9ATUoun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakEYCURjAtn",
        "outputId": "2afbe01a-1445-4f3d-b911-906bf7e70881"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/SSNElab9\")"
      ],
      "metadata": {
        "id": "fGzhDkfDjCGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "zDc0baBsXVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_PERCENTAGE = 0.10\n",
        "TRAIN_PATH = 'train.pkl'\n",
        "TEST_PATH = \"\""
      ],
      "metadata": {
        "id": "sg6Nh9CXXT4U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training dataset"
      ],
      "metadata": {
        "id": "8b6UrS1rrOIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lhaFNeLhusm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(TRAIN_PATH, 'rb') as f:\n",
        "    train = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lengths = [len(train_song[0]) for train_song in train]"
      ],
      "metadata": {
        "id": "7eNmQAg1i7Yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGswPGVIFE",
        "outputId": "f3591c80-3933-4cc6-81d3-e9b4c707e6f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for training values"
      ],
      "metadata": {
        "id": "g6VO-fNxrWh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of lengths of training sequences\n",
        "plt.hist(train_lengths, bins='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZUP8rCvCo716",
        "outputId": "e4b39335-8d36-4fa7-cbd6-30bd5a0276c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([152., 383., 229., 301., 297., 245., 212., 162., 103., 111.,  76.,\n",
              "         67.,  87.,  49.,  42.,  37.,  23.,  27.,  22.,  25.,  17.,  16.,\n",
              "         14.,  13.,  13.,  10.,  19.,  15.,  11.,  16.,   4.,   6.,   8.,\n",
              "          8.,   2.,   5.,   3.,   5.,   5.,   5.,   6.,   4.,   4.,  11.,\n",
              "          5.,   2.,   6.,   4.,   8.,   1.,   0.,   1.,   3.,   1.,   1.,\n",
              "          2.,   1.,   2.,   0.,   2.,   1.,   2.,   3.,   0.,   0.,   0.,\n",
              "          0.,   1.,   1.,   3.,   0.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,\n",
              "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,\n",
              "          1.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
              " array([4.00000000e+00, 5.17575758e+01, 9.95151515e+01, 1.47272727e+02,\n",
              "        1.95030303e+02, 2.42787879e+02, 2.90545455e+02, 3.38303030e+02,\n",
              "        3.86060606e+02, 4.33818182e+02, 4.81575758e+02, 5.29333333e+02,\n",
              "        5.77090909e+02, 6.24848485e+02, 6.72606061e+02, 7.20363636e+02,\n",
              "        7.68121212e+02, 8.15878788e+02, 8.63636364e+02, 9.11393939e+02,\n",
              "        9.59151515e+02, 1.00690909e+03, 1.05466667e+03, 1.10242424e+03,\n",
              "        1.15018182e+03, 1.19793939e+03, 1.24569697e+03, 1.29345455e+03,\n",
              "        1.34121212e+03, 1.38896970e+03, 1.43672727e+03, 1.48448485e+03,\n",
              "        1.53224242e+03, 1.58000000e+03, 1.62775758e+03, 1.67551515e+03,\n",
              "        1.72327273e+03, 1.77103030e+03, 1.81878788e+03, 1.86654545e+03,\n",
              "        1.91430303e+03, 1.96206061e+03, 2.00981818e+03, 2.05757576e+03,\n",
              "        2.10533333e+03, 2.15309091e+03, 2.20084848e+03, 2.24860606e+03,\n",
              "        2.29636364e+03, 2.34412121e+03, 2.39187879e+03, 2.43963636e+03,\n",
              "        2.48739394e+03, 2.53515152e+03, 2.58290909e+03, 2.63066667e+03,\n",
              "        2.67842424e+03, 2.72618182e+03, 2.77393939e+03, 2.82169697e+03,\n",
              "        2.86945455e+03, 2.91721212e+03, 2.96496970e+03, 3.01272727e+03,\n",
              "        3.06048485e+03, 3.10824242e+03, 3.15600000e+03, 3.20375758e+03,\n",
              "        3.25151515e+03, 3.29927273e+03, 3.34703030e+03, 3.39478788e+03,\n",
              "        3.44254545e+03, 3.49030303e+03, 3.53806061e+03, 3.58581818e+03,\n",
              "        3.63357576e+03, 3.68133333e+03, 3.72909091e+03, 3.77684848e+03,\n",
              "        3.82460606e+03, 3.87236364e+03, 3.92012121e+03, 3.96787879e+03,\n",
              "        4.01563636e+03, 4.06339394e+03, 4.11115152e+03, 4.15890909e+03,\n",
              "        4.20666667e+03, 4.25442424e+03, 4.30218182e+03, 4.34993939e+03,\n",
              "        4.39769697e+03, 4.44545455e+03, 4.49321212e+03, 4.54096970e+03,\n",
              "        4.58872727e+03, 4.63648485e+03, 4.68424242e+03, 4.73200000e+03,\n",
              "        4.77975758e+03, 4.82751515e+03, 4.87527273e+03, 4.92303030e+03,\n",
              "        4.97078788e+03, 5.01854545e+03, 5.06630303e+03, 5.11406061e+03,\n",
              "        5.16181818e+03, 5.20957576e+03, 5.25733333e+03, 5.30509091e+03,\n",
              "        5.35284848e+03, 5.40060606e+03, 5.44836364e+03, 5.49612121e+03,\n",
              "        5.54387879e+03, 5.59163636e+03, 5.63939394e+03, 5.68715152e+03,\n",
              "        5.73490909e+03, 5.78266667e+03, 5.83042424e+03, 5.87818182e+03,\n",
              "        5.92593939e+03, 5.97369697e+03, 6.02145455e+03, 6.06921212e+03,\n",
              "        6.11696970e+03, 6.16472727e+03, 6.21248485e+03, 6.26024242e+03,\n",
              "        6.30800000e+03]),\n",
              " <a list of 132 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train_lengths), max(train_lengths)"
      ],
      "metadata": {
        "id": "fkSg5eaga6cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46603db7-e820-4bff-a3b9-2f8786c3b053"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6308)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CmMtriGMPSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Seq_Regressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.proj_size = out_size\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, proj_size = out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.proj_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        # x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        # all_outputs = torch.transpose(all_outputs, 0, 1)\n",
        "        return all_outputs, hidden\n",
        "    "
      ],
      "metadata": {
        "id": "W2TSYGhAa6i-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "model = LSTM_Seq_Regressor(1, 200, 1, 5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kLQzbaPTow",
        "outputId": "1cdcd649-8053-4de5-cb63-44f45b1c2221"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_Seq_Regressor(\n",
              "  (lstm): LSTM(1, 200, proj_size=5)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "0a24j9vdPTrr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "SItHYahBR0BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from math import floor\n",
        "\n",
        "# converting train to tensors\n",
        "# train = [[torch.from_numpy(t[0].astype(int)).float(), torch.from_numpy(np.ndarray([int(t[1])]))] for t in train]\n",
        "train_data = [[torch.from_numpy(t[0].astype(int)).float(), int(t[1])] for t in train]\n",
        "\n",
        "dataset_length = len(train_data)\n",
        "val_size = floor(dataset_length * VALIDATION_PERCENTAGE)\n",
        "train_size = dataset_length - val_size\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
        "\n",
        "train_subset_data = [item[0] for item in train_subset]\n",
        "train_subset_targets = [item[1] for item in train_subset]\n",
        "\n",
        "val_subset_data = [item[0] for item in val_subset]\n",
        "val_subset_targets = [item[1] for item in val_subset]\n",
        "\n",
        "train_set = VariableLenDataset(train_subset_data, train_subset_targets)\n",
        "val_set = VariableLenDataset(val_subset_data, val_subset_targets)"
      ],
      "metadata": {
        "id": "sEm_rXS2TX4r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train[0][0].astype(int))"
      ],
      "metadata": {
        "id": "13fTQ1QafOXp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.ndarray(train[0][0].astype(int))"
      ],
      "metadata": {
        "id": "y-puBqRVe3Ev"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[torch.from_numpy(t[0].astype(int)), int(t[1])] for t in train]"
      ],
      "metadata": {
        "id": "nAZiFy9heEC6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy\n",
        "\n",
        "# def pad_collate(batch, pad_value=0):\n",
        "#     xx, yy = zip(*batch)\n",
        "#     x_lens = [len(x) for x in xx]\n",
        "#     y_lens = [1 for y in yy]\n",
        "\n",
        "#     xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "#     # yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "#     return xx_pad, yy, x_lens, y_lens"
      ],
      "metadata": {
        "id": "BvgU5pn2PTua"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=8, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "p8ShbxngPTxK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2H1pWKZyMu",
        "outputId": "b6dbf082-8916-45ec-d27d-b48dfa06eb32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ -1.,  -1.,  -1.,  ...,  12.,  -1.,  -1.],\n",
              "         [ -1.,  -1.,  -1.,  ...,   0.,   0.,   0.],\n",
              "         [  2.,  95.,  29.,  ...,   0.,   0.,   0.],\n",
              "         ...,\n",
              "         [132.,  92.,  28.,  ...,   0.,   0.,   0.],\n",
              "         [  0.,  88., 159.,  ...,   0.,   0.,   0.],\n",
              "         [ 32.,  79.,  79.,  ...,   0.,   0.,   0.]]),\n",
              " (1, 0, 3, 3, 0, 0, 0, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# loss_fun = nn.MSELoss()\n",
        "\n",
        "# # Training loop\n",
        "# for epoch in range(101):\n",
        "#     for x, targets in train_loader:\n",
        "#         x = x.to(device).unsqueeze(2)\n",
        "#         # targets = targets.to(device)\n",
        "#         hidden, state = model.init_hidden(x.size(0))\n",
        "#         hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "#         targets = torch.from_numpy(np.asarray(targets))\n",
        "        \n",
        "#         x = torch.transpose(x, 0, 1)\n",
        "#         preds, _ = model(x, (hidden, state))\n",
        "#         preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "#         # print(x)\n",
        "        \n",
        "#         # x_lens = [len(xx) for xx in x]\n",
        "#         # x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "#         # print(\"XPACKED\", x_packed.data)\n",
        "#         # preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         # preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "        \n",
        "#         preds = preds.squeeze(2)\n",
        "#         print(preds.shape)\n",
        "#         print(targets)\n",
        "#         optimizer.zero_grad()\n",
        "#         mask = targets != pad\n",
        "#         print(\"A\", preds)\n",
        "#         print(\"V\", targets)\n",
        "#         loss = loss_fun(preds[mask], targets[mask])\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#     if epoch % 10 == 0:\n",
        "#         print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "id": "HS7G0eLnSg_v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    for x, targets in train_loader:\n",
        "        # print(\"X\", x.shape)\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "#         x = x.unsqueeze(2)\n",
        "        # print(\"X\", x.shape)\n",
        "        targets = targets.to(device)\n",
        "        # print(x.size(0))\n",
        "        hidden, state = model.init_hidden(x.size(1))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "        # print('X SHAPE', x.shape)\n",
        "        # print('PREDS SHAPE', x.shape)\n",
        "        # print(\"HIDDEN SHAPE\", hidden.shape)\n",
        "        preds, _ = model(x, (hidden,state))\n",
        "        preds = preds.squeeze(2)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        \n",
        "        # print(preds.shape)\n",
        "        # print(targets.shape)\n",
        "        preds = preds[:,:,4]\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "vAWo9YRg3BLo",
        "outputId": "f43a468b-c000-41ae-d853-96eb2dbd9f8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1788])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b5c417378453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print(targets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3277\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3280\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1788) must match the size of tensor b (8) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-s5mTUxSjOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCwAflsXSjQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}