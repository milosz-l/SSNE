{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, setting up device and seeds\n"
      ],
      "metadata": {
        "id": "bWqIz6BsrIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "-RiHHnHEi7Vc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_all_seeds(42)"
      ],
      "metadata": {
        "id": "dF7Jzby3i-I6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.set_device(1)\n",
        "# device = torch.device(\"cuda\")\n",
        "# device = torch.device('mps')\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "-BCkcrW5i9kE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive"
      ],
      "metadata": {
        "id": "A2P1P9ATUoun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakEYCURjAtn",
        "outputId": "caf3f8dc-bb60-4ae8-c11e-60ac3b40cf70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/SSNElab9\")"
      ],
      "metadata": {
        "id": "fGzhDkfDjCGE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "zDc0baBsXVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_PERCENTAGE = 0.10\n",
        "TRAIN_PATH = 'train.pkl'\n",
        "TEST_PATH = \"\""
      ],
      "metadata": {
        "id": "sg6Nh9CXXT4U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training dataset"
      ],
      "metadata": {
        "id": "8b6UrS1rrOIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lhaFNeLhusm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(TRAIN_PATH, 'rb') as f:\n",
        "    train = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lengths = [len(train_song[0]) for train_song in train]"
      ],
      "metadata": {
        "id": "7eNmQAg1i7Yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGswPGVIFE",
        "outputId": "f4b89800-002d-4afa-90b7-b8694b170bbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for training values"
      ],
      "metadata": {
        "id": "g6VO-fNxrWh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of lengths of training sequences\n",
        "plt.hist(train_lengths, bins='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZUP8rCvCo716",
        "outputId": "67a8e09e-f101-4fdb-ec72-d29147511598"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([152., 383., 229., 301., 297., 245., 212., 162., 103., 111.,  76.,\n",
              "         67.,  87.,  49.,  42.,  37.,  23.,  27.,  22.,  25.,  17.,  16.,\n",
              "         14.,  13.,  13.,  10.,  19.,  15.,  11.,  16.,   4.,   6.,   8.,\n",
              "          8.,   2.,   5.,   3.,   5.,   5.,   5.,   6.,   4.,   4.,  11.,\n",
              "          5.,   2.,   6.,   4.,   8.,   1.,   0.,   1.,   3.,   1.,   1.,\n",
              "          2.,   1.,   2.,   0.,   2.,   1.,   2.,   3.,   0.,   0.,   0.,\n",
              "          0.,   1.,   1.,   3.,   0.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,\n",
              "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,\n",
              "          1.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
              " array([4.00000000e+00, 5.17575758e+01, 9.95151515e+01, 1.47272727e+02,\n",
              "        1.95030303e+02, 2.42787879e+02, 2.90545455e+02, 3.38303030e+02,\n",
              "        3.86060606e+02, 4.33818182e+02, 4.81575758e+02, 5.29333333e+02,\n",
              "        5.77090909e+02, 6.24848485e+02, 6.72606061e+02, 7.20363636e+02,\n",
              "        7.68121212e+02, 8.15878788e+02, 8.63636364e+02, 9.11393939e+02,\n",
              "        9.59151515e+02, 1.00690909e+03, 1.05466667e+03, 1.10242424e+03,\n",
              "        1.15018182e+03, 1.19793939e+03, 1.24569697e+03, 1.29345455e+03,\n",
              "        1.34121212e+03, 1.38896970e+03, 1.43672727e+03, 1.48448485e+03,\n",
              "        1.53224242e+03, 1.58000000e+03, 1.62775758e+03, 1.67551515e+03,\n",
              "        1.72327273e+03, 1.77103030e+03, 1.81878788e+03, 1.86654545e+03,\n",
              "        1.91430303e+03, 1.96206061e+03, 2.00981818e+03, 2.05757576e+03,\n",
              "        2.10533333e+03, 2.15309091e+03, 2.20084848e+03, 2.24860606e+03,\n",
              "        2.29636364e+03, 2.34412121e+03, 2.39187879e+03, 2.43963636e+03,\n",
              "        2.48739394e+03, 2.53515152e+03, 2.58290909e+03, 2.63066667e+03,\n",
              "        2.67842424e+03, 2.72618182e+03, 2.77393939e+03, 2.82169697e+03,\n",
              "        2.86945455e+03, 2.91721212e+03, 2.96496970e+03, 3.01272727e+03,\n",
              "        3.06048485e+03, 3.10824242e+03, 3.15600000e+03, 3.20375758e+03,\n",
              "        3.25151515e+03, 3.29927273e+03, 3.34703030e+03, 3.39478788e+03,\n",
              "        3.44254545e+03, 3.49030303e+03, 3.53806061e+03, 3.58581818e+03,\n",
              "        3.63357576e+03, 3.68133333e+03, 3.72909091e+03, 3.77684848e+03,\n",
              "        3.82460606e+03, 3.87236364e+03, 3.92012121e+03, 3.96787879e+03,\n",
              "        4.01563636e+03, 4.06339394e+03, 4.11115152e+03, 4.15890909e+03,\n",
              "        4.20666667e+03, 4.25442424e+03, 4.30218182e+03, 4.34993939e+03,\n",
              "        4.39769697e+03, 4.44545455e+03, 4.49321212e+03, 4.54096970e+03,\n",
              "        4.58872727e+03, 4.63648485e+03, 4.68424242e+03, 4.73200000e+03,\n",
              "        4.77975758e+03, 4.82751515e+03, 4.87527273e+03, 4.92303030e+03,\n",
              "        4.97078788e+03, 5.01854545e+03, 5.06630303e+03, 5.11406061e+03,\n",
              "        5.16181818e+03, 5.20957576e+03, 5.25733333e+03, 5.30509091e+03,\n",
              "        5.35284848e+03, 5.40060606e+03, 5.44836364e+03, 5.49612121e+03,\n",
              "        5.54387879e+03, 5.59163636e+03, 5.63939394e+03, 5.68715152e+03,\n",
              "        5.73490909e+03, 5.78266667e+03, 5.83042424e+03, 5.87818182e+03,\n",
              "        5.92593939e+03, 5.97369697e+03, 6.02145455e+03, 6.06921212e+03,\n",
              "        6.11696970e+03, 6.16472727e+03, 6.21248485e+03, 6.26024242e+03,\n",
              "        6.30800000e+03]),\n",
              " <a list of 132 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train_lengths), max(train_lengths)"
      ],
      "metadata": {
        "id": "fkSg5eaga6cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613e05ce-0b20-4104-b18a-34f2794e2366"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6308)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CmMtriGMPSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size*90*self.bidirectional, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x,0,1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        all_outputs = torch.transpose(all_outputs,0,1)\n",
        "        out = torch.flatten(all_outputs,1)\n",
        "        x = self.fc(out)\n",
        "        return x, hidden\n",
        "    \n",
        "model = LSTMRegressor(1,5,2,16).to(device)\n",
        "model\n",
        "    "
      ],
      "metadata": {
        "id": "W2TSYGhAa6i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d9487a-b167-4f35-e02f-641712415699"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=450, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1,5,2,16).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kLQzbaPTow",
        "outputId": "0bc03d5d-b402-4419-bac2-bfb4fceff42c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=450, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "0a24j9vdPTrr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "SItHYahBR0BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from math import floor\n",
        "\n",
        "# converting train to tensors\n",
        "train = [[torch.from_numpy(t[0].astype(int)), int(t[1])] for t in train]\n",
        "\n",
        "dataset_length = len(train)\n",
        "val_size = floor(dataset_length * VALIDATION_PERCENTAGE)\n",
        "train_size = dataset_length - val_size\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(train, [train_size, val_size])\n",
        "\n",
        "train_subset_data = [item[0] for item in train_subset]\n",
        "train_subset_targets = [item[1] for item in train_subset]\n",
        "\n",
        "val_subset_data = [item[0] for item in val_subset]\n",
        "val_subset_targets = [item[1] for item in val_subset]\n",
        "\n",
        "train_set = VariableLenDataset(train_subset_data, train_subset_targets)\n",
        "val_set = VariableLenDataset(val_subset_data, val_subset_targets)"
      ],
      "metadata": {
        "id": "sEm_rXS2TX4r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train[0][0].astype(int))"
      ],
      "metadata": {
        "id": "13fTQ1QafOXp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.ndarray(train[0][0].astype(int))"
      ],
      "metadata": {
        "id": "y-puBqRVe3Ev"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[torch.from_numpy(t[0].astype(int)), int(t[1])] for t in train]"
      ],
      "metadata": {
        "id": "nAZiFy9heEC6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy"
      ],
      "metadata": {
        "id": "BvgU5pn2PTua"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnjhkqH9iNcm",
        "outputId": "f342ea5b-0066-40f8-b18a-014aeb16dbae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 33,  33, 146,  33,  33,  33,  44,  12,  44,  44,  12,  44,  44,  12,\n",
              "          44,  44,  12,  44,  76, 108, 127,  92, 127, 127,  44,  78,  60, 157,\n",
              "          78, 127, 158,  44,  44, 127, 175,  28, 156, 141, 141, 156,  45,  45,\n",
              "          77, 190, 190,  41,  12,  47, 156, 156, 156, 156,  47,  47,  12,  12,\n",
              "         156, 190,  92,  92,  77, 141, 141, 141, 141, 141, 141, 141, 141, 141,\n",
              "         141, 141, 141,  77, 156,  30,  77, 190, 141, 141,  28,  28,  47, 156,\n",
              "          78, 125,  78,  78,  78,  78,  78,  78,  78,  78,  47, 156,  92,  47,\n",
              "          78,  92,  47,  78,  92, 125,  28, 159,   5, 127,  12,  30,  44,  92,\n",
              "         127, 158,  12,  44,  44,  44,  40,  33,  33,  92,  92,  68,  92, 175,\n",
              "         140, 175, 175, 175,  47,  47,  28,  92,  92, 109,  13,  13,  44, 125,\n",
              "         127, 158,  79,  44,  44, 127, 158, 157,  44,  44,  44,  44,  44,  44,\n",
              "          44,  44,  44,  44,  44,  44,  78,  44,  79, 157,  12,  44, 125,  93,\n",
              "          93, 175,  44,  44,  44,  44,  44,  44,  44,  78, 127, 127,  60,  44,\n",
              "          44,  44,  44,  44,  78, 172, 140, 127,  92,  44, 158,  13,  44, 158,\n",
              "         127, 158, 158, 127,  44, 158, 127,  44,  44, 127, 158,  44, 127, 158,\n",
              "          44, 175, 175, 175, 175,  44,  44, 114,  32,  32,  32,  -1]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=50, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=50, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "p8ShbxngPTxK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2H1pWKZyMu",
        "outputId": "8f95b763-7bf9-4eba-a58b-34489248f0b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[144, 144, 145,  ...,   0,   0,   0],\n",
              "         [ -1,  -1,  -1,  ...,   0,   0,   0],\n",
              "         [ -1,  -1,  -1,  ...,   0,   0,   0],\n",
              "         ...,\n",
              "         [ 46,  46,  46,  ...,   0,   0,   0],\n",
              "         [ 47,   0,  92,  ...,   0,   0,   0],\n",
              "         [ -1,   0, 114,  ...,   0,   0,   0]]),\n",
              " (0,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  4))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(101):\n",
        "    for x, targets in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        # targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        preds, _ = model(x, (hidden, state))\n",
        "        preds = torch.transpose(preds, 0, 1)\n",
        "        \n",
        "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "        \n",
        "        preds = preds.squeeze(2)\n",
        "        optimizer.zero_grad()\n",
        "        mask = targets != pad\n",
        "        loss = loss_fun(preds[mask], targets[mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "HS7G0eLnSg_v",
        "outputId": "33fb6962-eeda-416b-aad0-118875de05c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d29eabed0f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-098ceb323b83>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mall_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    691\u001b[0m                            ):\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0m\u001b[1;32m    694\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[1;32m    695\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    224\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 4924, 5), got [2, 50, 5]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-s5mTUxSjOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCwAflsXSjQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}