{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6VO-fNxrWh5"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, setting up device and seeds\n"
      ],
      "metadata": {
        "id": "bWqIz6BsrIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "-RiHHnHEi7Vc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_all_seeds(42)"
      ],
      "metadata": {
        "id": "dF7Jzby3i-I6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.set_device(1)\n",
        "device = torch.device(\"cuda\")\n",
        "# device = torch.device('mps')\n",
        "# device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "-BCkcrW5i9kE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive"
      ],
      "metadata": {
        "id": "O6kRoxN_Mq60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1a790c-fe15-4640-994a-6cd57358a8d1",
        "id": "s3TMSAqEMq62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/SSNE_colab/C9(M4)\")"
      ],
      "metadata": {
        "id": "y10hmgNKMq62"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "zDc0baBsXVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_PERCENTAGE = 0.10\n",
        "batch_size = 8\n",
        "TRAIN_PATH = 'train.pkl'\n",
        "TEST_PATH = \"test_no_target.pkl\""
      ],
      "metadata": {
        "id": "sg6Nh9CXXT4U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training dataset"
      ],
      "metadata": {
        "id": "8b6UrS1rrOIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lhaFNeLhusm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(TRAIN_PATH, 'rb') as f:\n",
        "    train = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lengths = [len(train_song[0]) for train_song in train]"
      ],
      "metadata": {
        "id": "7eNmQAg1i7Yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjH5ziWn_4Po",
        "outputId": "ad4ea189-9ae0-478e-9c61-50754de33baf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2939"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fGswPGVIFE",
        "outputId": "a85a13eb-e7bc-4076-88d9-f9f29b7dda12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for training values"
      ],
      "metadata": {
        "id": "g6VO-fNxrWh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of lengths of training sequences\n",
        "plt.hist(train_lengths, bins='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZUP8rCvCo716",
        "outputId": "2c4f5dff-a9c4-42db-e080-566db2703fc0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([152., 383., 229., 301., 297., 245., 212., 162., 103., 111.,  76.,\n",
              "         67.,  87.,  49.,  42.,  37.,  23.,  27.,  22.,  25.,  17.,  16.,\n",
              "         14.,  13.,  13.,  10.,  19.,  15.,  11.,  16.,   4.,   6.,   8.,\n",
              "          8.,   2.,   5.,   3.,   5.,   5.,   5.,   6.,   4.,   4.,  11.,\n",
              "          5.,   2.,   6.,   4.,   8.,   1.,   0.,   1.,   3.,   1.,   1.,\n",
              "          2.,   1.,   2.,   0.,   2.,   1.,   2.,   3.,   0.,   0.,   0.,\n",
              "          0.,   1.,   1.,   3.,   0.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,\n",
              "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,\n",
              "          1.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
              " array([4.00000000e+00, 5.17575758e+01, 9.95151515e+01, 1.47272727e+02,\n",
              "        1.95030303e+02, 2.42787879e+02, 2.90545455e+02, 3.38303030e+02,\n",
              "        3.86060606e+02, 4.33818182e+02, 4.81575758e+02, 5.29333333e+02,\n",
              "        5.77090909e+02, 6.24848485e+02, 6.72606061e+02, 7.20363636e+02,\n",
              "        7.68121212e+02, 8.15878788e+02, 8.63636364e+02, 9.11393939e+02,\n",
              "        9.59151515e+02, 1.00690909e+03, 1.05466667e+03, 1.10242424e+03,\n",
              "        1.15018182e+03, 1.19793939e+03, 1.24569697e+03, 1.29345455e+03,\n",
              "        1.34121212e+03, 1.38896970e+03, 1.43672727e+03, 1.48448485e+03,\n",
              "        1.53224242e+03, 1.58000000e+03, 1.62775758e+03, 1.67551515e+03,\n",
              "        1.72327273e+03, 1.77103030e+03, 1.81878788e+03, 1.86654545e+03,\n",
              "        1.91430303e+03, 1.96206061e+03, 2.00981818e+03, 2.05757576e+03,\n",
              "        2.10533333e+03, 2.15309091e+03, 2.20084848e+03, 2.24860606e+03,\n",
              "        2.29636364e+03, 2.34412121e+03, 2.39187879e+03, 2.43963636e+03,\n",
              "        2.48739394e+03, 2.53515152e+03, 2.58290909e+03, 2.63066667e+03,\n",
              "        2.67842424e+03, 2.72618182e+03, 2.77393939e+03, 2.82169697e+03,\n",
              "        2.86945455e+03, 2.91721212e+03, 2.96496970e+03, 3.01272727e+03,\n",
              "        3.06048485e+03, 3.10824242e+03, 3.15600000e+03, 3.20375758e+03,\n",
              "        3.25151515e+03, 3.29927273e+03, 3.34703030e+03, 3.39478788e+03,\n",
              "        3.44254545e+03, 3.49030303e+03, 3.53806061e+03, 3.58581818e+03,\n",
              "        3.63357576e+03, 3.68133333e+03, 3.72909091e+03, 3.77684848e+03,\n",
              "        3.82460606e+03, 3.87236364e+03, 3.92012121e+03, 3.96787879e+03,\n",
              "        4.01563636e+03, 4.06339394e+03, 4.11115152e+03, 4.15890909e+03,\n",
              "        4.20666667e+03, 4.25442424e+03, 4.30218182e+03, 4.34993939e+03,\n",
              "        4.39769697e+03, 4.44545455e+03, 4.49321212e+03, 4.54096970e+03,\n",
              "        4.58872727e+03, 4.63648485e+03, 4.68424242e+03, 4.73200000e+03,\n",
              "        4.77975758e+03, 4.82751515e+03, 4.87527273e+03, 4.92303030e+03,\n",
              "        4.97078788e+03, 5.01854545e+03, 5.06630303e+03, 5.11406061e+03,\n",
              "        5.16181818e+03, 5.20957576e+03, 5.25733333e+03, 5.30509091e+03,\n",
              "        5.35284848e+03, 5.40060606e+03, 5.44836364e+03, 5.49612121e+03,\n",
              "        5.54387879e+03, 5.59163636e+03, 5.63939394e+03, 5.68715152e+03,\n",
              "        5.73490909e+03, 5.78266667e+03, 5.83042424e+03, 5.87818182e+03,\n",
              "        5.92593939e+03, 5.97369697e+03, 6.02145455e+03, 6.06921212e+03,\n",
              "        6.11696970e+03, 6.16472727e+03, 6.21248485e+03, 6.26024242e+03,\n",
              "        6.30800000e+03]),\n",
              " <a list of 132 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(train_lengths), max(train_lengths)"
      ],
      "metadata": {
        "id": "fkSg5eaga6cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe1db57-d17f-4030-f111-cb809609b666"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6308)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQvCZEwhCsTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "0a24j9vdPTrr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "SItHYahBR0BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from math import floor\n",
        "\n",
        "# converting train to tensors\n",
        "# train = [[torch.from_numpy(t[0].astype(int)).float(), torch.from_numpy(np.ndarray([int(t[1])]))] for t in train]\n",
        "train_data = [[torch.from_numpy(t[0].astype(int)).float(), int(t[1])] for t in train]\n",
        "\n",
        "dataset_length = len(train_data)\n",
        "val_size = floor(dataset_length * VALIDATION_PERCENTAGE)\n",
        "train_size = dataset_length - val_size\n",
        "\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
        "\n",
        "train_subset_data = [item[0] for item in train_subset]\n",
        "train_subset_targets = [item[1] for item in train_subset]\n",
        "\n",
        "val_subset_data = [item[0] for item in val_subset]\n",
        "val_subset_targets = [item[1] for item in val_subset]\n",
        "\n",
        "train_set = VariableLenDataset(train_subset_data, train_subset_targets)\n",
        "val_set = VariableLenDataset(val_subset_data, val_subset_targets)"
      ],
      "metadata": {
        "id": "sEm_rXS2TX4r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy"
      ],
      "metadata": {
        "id": "BvgU5pn2PTua"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "p8ShbxngPTxK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2H1pWKZyMu",
        "outputId": "831284ad-c626-4fed-aeaf-37d5e8fccf3e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[145., 145.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ -1., 112.,  34.,  ...,   0.,   0.,   0.],\n",
              "         [ -1.,  -1.,  -1.,  ...,   0.,   0.,  -1.],\n",
              "         ...,\n",
              "         [110., 185.,  88.,  ...,   0.,   0.,   0.],\n",
              "         [ 12.,  12.,  12.,  ...,   0.,   0.,   0.],\n",
              "         [ 21., 116.,  21.,  ...,   0.,   0.,   0.]]),\n",
              " (0, 4, 1, 4, 3, 0, 0, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## weight classes"
      ],
      "metadata": {
        "id": "3UTKEgVJNDoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [train_song[1] for train_song in train]\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "anmnEw6KNKrt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6dYzb2rQ3Iu",
        "outputId": "29baf575-6256-4561-aa22-9b88c006d1f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "9JJ6nau7Nr-V",
        "outputId": "34be9c49-0e57-4939-9194-b682a93fa9b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1630.,    0.,  478.,    0.,    0.,  154.,    0.,  441.,    0.,\n",
              "         236.]),\n",
              " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "CLASS_WEIGHT= compute_class_weight(class_weight='balanced', classes=np.unique(labels).tolist(), y=labels.tolist())\n",
        "classes_weights = torch.tensor(np.array(CLASS_WEIGHT).astype('float32')).to(device)"
      ],
      "metadata": {
        "id": "PUQQOO4yO0KX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for class_idx, class_weight in zip(np.unique(labels), CLASS_WEIGHT):\n",
        "    print(class_idx, class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpuAaoBuR6L0",
        "outputId": "30115d79-7733-47a2-d606-315dd379ad6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.3606134969325153\n",
            "1 1.2297071129707113\n",
            "2 3.8168831168831168\n",
            "3 1.3328798185941042\n",
            "4 2.490677966101695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CmMtriGMPSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        # pass the input through the LSTM layer\n",
        "        # print(x.shape)\n",
        "        # print(hidden[0].size(0))\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "\n",
        "        # print(\"OUT\", out.shape)\n",
        "        \n",
        "        # get the last output of the LSTM layer\n",
        "        out = out[-1, :, :]\n",
        "\n",
        "        # print(\"OUT2\", out.shape)\n",
        "        \n",
        "        # pass the last output through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # print(\"OUT3\", out.shape)\n",
        "        \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "W2TSYGhAa6i-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "model = LSTMRegressor(1,20,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kLQzbaPTow",
        "outputId": "47e7ff1d-d5ea-4948-9dc6-9268d81abb53"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 20, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy_per_class(model, loader, classes):\n",
        "\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "    acurracy_sum = 0\n",
        "\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for x, targets in loader:\n",
        "        \n",
        "            targets = torch.from_numpy(np.asarray(targets))\n",
        "            # print(\"SHAPE X\", x.shape)\n",
        "            # print(\"SHAPE TARGETS\", targets.shape)\n",
        "            x = x.to(device).unsqueeze(2)\n",
        "            targets = targets.to(device)\n",
        "            hidden, state = model.init_hidden(x.size(0))\n",
        "            hidden, state = hidden.to(device), state.to(device) \n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            preds = model(x, (hidden, state))\n",
        "            _, predictions = torch.max(preds, 1)\n",
        "\n",
        "            for label, prediction in zip(targets, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        # print(\"Accuracy for class {:5s} is: {:.2f} %\".format(classname, \n",
        "        #                                                accuracy))\n",
        "        acurracy_sum += accuracy\n",
        "        \n",
        "    # print(\"Average accuracy for a class is: {:.2f} %\".format(acurracy_sum/len(classes)))\n",
        "    \n",
        "    # division by 100\n",
        "    return acurracy_sum/(len(classes) * 100)\n"
      ],
      "metadata": {
        "id": "dd1xinfuEMZv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtpRHsY2EMcw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4xsMjjQEMfL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL2OKKBkEMh8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Sn-tXvwIG83R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fun = nn.CrossEntropyLoss(weight=classes_weights)\n",
        "\n",
        "epochs, losses, train_acc, val_acc, train_acc_per_class, val_acc_per_class  = [], [], [], [], [], []\n",
        "\n",
        "best_model = None\n",
        "best_model_acc = None\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(300):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for x, targets in train_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # print(\"A\")\n",
        "        preds = model(x, (hidden, state))\n",
        "        # print(\"B\")\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "        # preds = preds.squeeze(2)\n",
        "        # print(\"PREDS\", preds.shape)\n",
        "        # preds = preds[:,-1,:]\n",
        "        \n",
        "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "        \n",
        "        # preds = preds.squeeze(2)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # get the predicted labels\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "\n",
        "\n",
        "        # compute the accuracy\n",
        "        total_train += targets.size(0)\n",
        "        correct_train += (predicted == targets).sum().item()\n",
        "\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    epochs.append(epoch)\n",
        "\n",
        "    # evaluate the model on the validation set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, targets in val_loader:\n",
        "        targets = torch.from_numpy(np.asarray(targets))\n",
        "        # print(\"SHAPE X\", x.shape)\n",
        "        # print(\"SHAPE TARGETS\", targets.shape)\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "\n",
        "        # print(hidden.shape, state.shape)\n",
        "        \n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        preds = model(x, (hidden, state))\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(x, (hidden, state))\n",
        "\n",
        "        # get the predicted labels\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "        # compute the accuracy\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    # appending\n",
        "    train_acc.append(100 * correct_train / total_train)\n",
        "    val_acc.append(100 * correct / total)\n",
        "    train_acc_per_class_for_epoch = get_accuracy_per_class(model, train_loader, range(0, 5))\n",
        "    train_acc_per_class.append(train_acc_per_class_for_epoch)\n",
        "    val_acc_per_class_for_epoch = get_accuracy_per_class(model, val_loader, range(0, 5))\n",
        "    val_acc_per_class.append(val_acc_per_class_for_epoch)\n",
        "\n",
        "    if best_model is None or val_acc_per_class_for_epoch > best_model_acc:\n",
        "        # taking accuracy per class\n",
        "        best_model = model\n",
        "        best_model_acc = val_acc_per_class_for_epoch\n",
        "\n",
        "    # print the accuracy\n",
        "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")\n",
        "    print(f\"Accuracy on the validation set: {100 * correct / total}\")\n",
        "    print(f\"Accuracy per class on train: {train_acc_per_class_for_epoch:.3}\")\n",
        "    print(f\"Accuracy per class on val: {val_acc_per_class_for_epoch:.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAWo9YRg3BLo",
        "outputId": "5e495388-2db9-41e4-f82d-3eaaf0dd00c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.569\n",
            "Accuracy on the validation set: 69.62457337883959\n",
            "Accuracy per class on train: 0.754\n",
            "Accuracy per class on val: 0.595\n",
            "Epoch: 1, loss: 0.373\n",
            "Accuracy on the validation set: 67.57679180887372\n",
            "Accuracy per class on train: 0.752\n",
            "Accuracy per class on val: 0.576\n",
            "Epoch: 2, loss: 1.09\n",
            "Accuracy on the validation set: 65.8703071672355\n",
            "Accuracy per class on train: 0.755\n",
            "Accuracy per class on val: 0.626\n",
            "Epoch: 3, loss: 0.492\n",
            "Accuracy on the validation set: 64.16382252559727\n",
            "Accuracy per class on train: 0.73\n",
            "Accuracy per class on val: 0.669\n",
            "Epoch: 4, loss: 0.757\n",
            "Accuracy on the validation set: 63.13993174061434\n",
            "Accuracy per class on train: 0.759\n",
            "Accuracy per class on val: 0.598\n",
            "Epoch: 5, loss: 1.1\n",
            "Accuracy on the validation set: 62.79863481228669\n",
            "Accuracy per class on train: 0.769\n",
            "Accuracy per class on val: 0.611\n",
            "Epoch: 6, loss: 0.108\n",
            "Accuracy on the validation set: 68.25938566552901\n",
            "Accuracy per class on train: 0.766\n",
            "Accuracy per class on val: 0.623\n",
            "Epoch: 7, loss: 0.562\n",
            "Accuracy on the validation set: 63.822525597269625\n",
            "Accuracy per class on train: 0.762\n",
            "Accuracy per class on val: 0.655\n",
            "Epoch: 8, loss: 0.475\n",
            "Accuracy on the validation set: 63.48122866894198\n",
            "Accuracy per class on train: 0.775\n",
            "Accuracy per class on val: 0.63\n",
            "Epoch: 9, loss: 0.291\n",
            "Accuracy on the validation set: 64.16382252559727\n",
            "Accuracy per class on train: 0.784\n",
            "Accuracy per class on val: 0.599\n",
            "Epoch: 10, loss: 0.412\n",
            "Accuracy on the validation set: 67.57679180887372\n",
            "Accuracy per class on train: 0.737\n",
            "Accuracy per class on val: 0.614\n",
            "Epoch: 11, loss: 0.793\n",
            "Accuracy on the validation set: 65.52901023890784\n",
            "Accuracy per class on train: 0.768\n",
            "Accuracy per class on val: 0.62\n",
            "Epoch: 12, loss: 0.805\n",
            "Accuracy on the validation set: 65.52901023890784\n",
            "Accuracy per class on train: 0.767\n",
            "Accuracy per class on val: 0.597\n",
            "Epoch: 13, loss: 0.222\n",
            "Accuracy on the validation set: 62.45733788395904\n",
            "Accuracy per class on train: 0.768\n",
            "Accuracy per class on val: 0.637\n",
            "Epoch: 14, loss: 0.25\n",
            "Accuracy on the validation set: 66.89419795221843\n",
            "Accuracy per class on train: 0.769\n",
            "Accuracy per class on val: 0.668\n",
            "Epoch: 15, loss: 1.31\n",
            "Accuracy on the validation set: 65.18771331058021\n",
            "Accuracy per class on train: 0.765\n",
            "Accuracy per class on val: 0.605\n",
            "Epoch: 16, loss: 0.594\n",
            "Accuracy on the validation set: 66.21160409556315\n",
            "Accuracy per class on train: 0.782\n",
            "Accuracy per class on val: 0.7\n",
            "Epoch: 17, loss: 0.797\n",
            "Accuracy on the validation set: 64.16382252559727\n",
            "Accuracy per class on train: 0.784\n",
            "Accuracy per class on val: 0.627\n",
            "Epoch: 18, loss: 0.988\n",
            "Accuracy on the validation set: 65.18771331058021\n",
            "Accuracy per class on train: 0.778\n",
            "Accuracy per class on val: 0.649\n",
            "Epoch: 19, loss: 0.611\n",
            "Accuracy on the validation set: 68.60068259385666\n",
            "Accuracy per class on train: 0.756\n",
            "Accuracy per class on val: 0.649\n",
            "Epoch: 20, loss: 0.584\n",
            "Accuracy on the validation set: 67.23549488054607\n",
            "Accuracy per class on train: 0.792\n",
            "Accuracy per class on val: 0.632\n",
            "Epoch: 21, loss: 0.566\n",
            "Accuracy on the validation set: 65.52901023890784\n",
            "Accuracy per class on train: 0.77\n",
            "Accuracy per class on val: 0.645\n",
            "Epoch: 22, loss: 0.322\n",
            "Accuracy on the validation set: 66.55290102389078\n",
            "Accuracy per class on train: 0.782\n",
            "Accuracy per class on val: 0.589\n",
            "Epoch: 23, loss: 0.499\n",
            "Accuracy on the validation set: 67.91808873720136\n",
            "Accuracy per class on train: 0.767\n",
            "Accuracy per class on val: 0.638\n",
            "Epoch: 24, loss: 0.969\n",
            "Accuracy on the validation set: 66.89419795221843\n",
            "Accuracy per class on train: 0.757\n",
            "Accuracy per class on val: 0.608\n",
            "Epoch: 25, loss: 0.369\n",
            "Accuracy on the validation set: 68.9419795221843\n",
            "Accuracy per class on train: 0.786\n",
            "Accuracy per class on val: 0.663\n",
            "Epoch: 26, loss: 0.352\n",
            "Accuracy on the validation set: 68.9419795221843\n",
            "Accuracy per class on train: 0.75\n",
            "Accuracy per class on val: 0.617\n",
            "Epoch: 27, loss: 0.163\n",
            "Accuracy on the validation set: 65.8703071672355\n",
            "Accuracy per class on train: 0.794\n",
            "Accuracy per class on val: 0.625\n",
            "Epoch: 28, loss: 0.613\n",
            "Accuracy on the validation set: 65.8703071672355\n",
            "Accuracy per class on train: 0.766\n",
            "Accuracy per class on val: 0.654\n",
            "Epoch: 29, loss: 0.777\n",
            "Accuracy on the validation set: 64.84641638225256\n",
            "Accuracy per class on train: 0.774\n",
            "Accuracy per class on val: 0.642\n",
            "Epoch: 30, loss: 0.84\n",
            "Accuracy on the validation set: 65.18771331058021\n",
            "Accuracy per class on train: 0.797\n",
            "Accuracy per class on val: 0.629\n",
            "Epoch: 31, loss: 0.437\n",
            "Accuracy on the validation set: 68.25938566552901\n",
            "Accuracy per class on train: 0.789\n",
            "Accuracy per class on val: 0.623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(epochs, losses, train_acc, val_acc, train_acc_per_class, val_acc_per_class):\n",
        "    # plotting\n",
        "    plt.figure(figsize=(20,70), dpi=30,)\n",
        "    # fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, val_acc, label=\"Valid\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title(\"Accuracy per class\")\n",
        "    plt.plot(epochs, train_acc_per_class, label=\"Train\")\n",
        "    plt.plot(epochs, val_acc_per_class, label=\"Valid\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy per class\")\n",
        "\n",
        "    fig.tight_layout()"
      ],
      "metadata": {
        "id": "K-s5mTUxSjOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(epochs, losses, train_acc, val_acc, train_acc_per_class, val_acc_per_class)"
      ],
      "metadata": {
        "id": "iCwAflsXSjQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model to file\n",
        "state_dict = model.state_dict()\n",
        "torch.save(state_dict, \"neural_net.tar\")"
      ],
      "metadata": {
        "id": "7wsHi_yyLtge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving bes model to file\n",
        "state_dict = best_model.state_dict()\n",
        "torch.save(state_dict, \"best_neural_net.tar\")"
      ],
      "metadata": {
        "id": "fLPBbG134ncv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on the validation set: \", best_model_acc)"
      ],
      "metadata": {
        "id": "_i4Ta2PD439d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on test set"
      ],
      "metadata": {
        "id": "ajFynd6s9Ldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TEST_PATH, 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "wc1Q0Gne9KaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)"
      ],
      "metadata": {
        "id": "T6RUWhCm9M8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "id": "XCUegF_H9M-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [torch.from_numpy(t.astype(int)).float() for t in test_data]"
      ],
      "metadata": {
        "id": "5P2d0O2df28D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = VariableLenDataset(test_data, [0 for t in test_data])"
      ],
      "metadata": {
        "id": "FD-YF1cgYLBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "MOFb5U4TYLEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for x, label in test_loader:\n",
        "  print(x)\n",
        "  hidden, state = model.init_hidden(x.shape[0])\n",
        "  hidden, state = hidden.to(device), state.to(device)\n",
        "  x = x.to(device).unsqueeze(2)\n",
        "  x = torch.transpose(x, 0, 1)\n",
        "  new_preds = model(x, (hidden, state))\n",
        "  for new_pred in new_preds:\n",
        "    preds.append(new_pred.max(0, keepdim=True)[1].item())"
      ],
      "metadata": {
        "id": "LsEGLP2TYLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds_filename = \"preds.csv\"\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "current_datetime_formatted = f'{datetime.now()}'.replace('-', '_').replace(' ', '_').replace(':', '_')[:-4]\n",
        "preds_filename = f\"preds{current_datetime_formatted}.csv\"\n",
        "pd.DataFrame({'A': preds}).to_csv(preds_filename, index=False, header=False)"
      ],
      "metadata": {
        "id": "jHYTyOE8ehGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(preds_filename, header=None)\n"
      ],
      "metadata": {
        "id": "PCdB4mfVehJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhRheNLg19CZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}