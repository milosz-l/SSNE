{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n \nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:11.426732Z","iopub.execute_input":"2022-11-25T19:31:11.427163Z","iopub.status.idle":"2022-11-25T19:31:13.370361Z","shell.execute_reply.started":"2022-11-25T19:31:11.427131Z","shell.execute_reply":"2022-11-25T19:31:13.369439Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.set_device(1)\ndevice = torch.device(\"cuda\")\n# device = torch.device('mps')\n# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:13.372587Z","iopub.execute_input":"2022-11-25T19:31:13.372988Z","iopub.status.idle":"2022-11-25T19:31:13.377759Z","shell.execute_reply.started":"2022-11-25T19:31:13.372962Z","shell.execute_reply":"2022-11-25T19:31:13.376632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:13.379182Z","iopub.execute_input":"2022-11-25T19:31:13.379786Z","iopub.status.idle":"2022-11-25T19:31:13.394842Z","shell.execute_reply.started":"2022-11-25T19:31:13.379749Z","shell.execute_reply":"2022-11-25T19:31:13.393965Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport random\n\ndef set_all_seeds(seed):\n    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_all_seeds(42)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:13.397792Z","iopub.execute_input":"2022-11-25T19:31:13.398049Z","iopub.status.idle":"2022-11-25T19:31:13.408563Z","shell.execute_reply.started":"2022-11-25T19:31:13.398025Z","shell.execute_reply":"2022-11-25T19:31:13.407547Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"VALIDATION_PERCENTAGE = 0.10\nTRAIN_PATH = \"/kaggle/input/trainset\"","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:13.412751Z","iopub.execute_input":"2022-11-25T19:31:13.413862Z","iopub.status.idle":"2022-11-25T19:31:13.418265Z","shell.execute_reply.started":"2022-11-25T19:31:13.413826Z","shell.execute_reply":"2022-11-25T19:31:13.417288Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 32\n\ntrainFolder = torchvision.datasets.ImageFolder(root=TRAIN_PATH,\n                                               transform=transform)\n\ntrain_set, val_set = torch.utils.data.random_split(trainFolder, [79210, 8801])\n\ntrainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\nvalidloader = torch.utils.data.DataLoader(val_set, batch_size=1,\n                                          shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:31:13.419594Z","iopub.execute_input":"2022-11-25T19:31:13.420163Z","iopub.status.idle":"2022-11-25T19:32:42.210231Z","shell.execute_reply.started":"2022-11-25T19:31:13.420125Z","shell.execute_reply":"2022-11-25T19:32:42.209117Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## Warstwa konwolucyjna\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=2, padding=0)\n        ## Warstwa max pooling \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(1, 3, 5)\n        self.pool2 = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(75, 120)\n        self.fc2 = nn.Linear(120, 60)\n        self.fc3 = nn.Linear(60, 50)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:42.211646Z","iopub.execute_input":"2022-11-25T19:32:42.212028Z","iopub.status.idle":"2022-11-25T19:32:42.224829Z","shell.execute_reply.started":"2022-11-25T19:32:42.211986Z","shell.execute_reply":"2022-11-25T19:32:42.223754Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"net = Net()\nnet = net.to(device)\nnet","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:42.226423Z","iopub.execute_input":"2022-11-25T19:32:42.226899Z","iopub.status.idle":"2022-11-25T19:32:45.415252Z","shell.execute_reply.started":"2022-11-25T19:32:42.226859Z","shell.execute_reply":"2022-11-25T19:32:45.414094Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Net(\n  (conv1): Conv2d(3, 1, kernel_size=(5, 5), stride=(2, 2))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=75, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (fc3): Linear(in_features=60, out_features=50, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:45.417069Z","iopub.execute_input":"2022-11-25T19:32:45.417484Z","iopub.status.idle":"2022-11-25T19:32:45.423641Z","shell.execute_reply.started":"2022-11-25T19:32:45.417446Z","shell.execute_reply":"2022-11-25T19:32:45.422722Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy and accuracy per class","metadata":{"execution":{"iopub.status.busy":"2022-11-25T20:35:36.287774Z","iopub.execute_input":"2022-11-25T20:35:36.288186Z","iopub.status.idle":"2022-11-25T20:35:36.293298Z","shell.execute_reply.started":"2022-11-25T20:35:36.288150Z","shell.execute_reply":"2022-11-25T20:35:36.291813Z"}}},{"cell_type":"code","source":"def get_accuracy(model, dataset):\n    correct = 0\n    total = 0\n    model.eval() #*********#\n    for x, labels in dataset:\n        # moving to device\n        x, labels = x.to(device), labels.to(device)\n\n        output = model(x)\n        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n        correct += pred.eq(labels.view_as(pred)).sum().item()\n        total += x.shape[0]\n    return correct / total","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:45.425026Z","iopub.execute_input":"2022-11-25T19:32:45.425931Z","iopub.status.idle":"2022-11-25T19:32:45.435099Z","shell.execute_reply.started":"2022-11-25T19:32:45.425885Z","shell.execute_reply":"2022-11-25T19:32:45.433952Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_acccuracy_per_class(model, loader, classes):\n\n    # prepare to count predictions for each class\n    correct_pred = {classname: 0 for classname in classes}\n    total_pred = {classname: 0 for classname in classes}\n    acurracy_sum = 0\n\n    # again no gradients needed\n    with torch.no_grad():\n        for data in loader:\n            images, labels = data    \n            images = images.to(device)\n            outputs = net(images).cpu()   \n            _, predictions = torch.max(outputs, 1)\n            # collect the correct predictions for each class\n            for label, prediction in zip(labels, predictions):\n                if label == prediction:\n                    correct_pred[classes[label]] += 1\n                total_pred[classes[label]] += 1\n\n\n    # print accuracy for each class\n    for classname, correct_count in correct_pred.items():\n        accuracy = 100 * float(correct_count) / total_pred[classname]\n        print(\"Accuracy for class {:5s} is: {:.2f} %\".format(classname, \n                                                       accuracy))\n        acurracy_sum += accuracy\n        \n    print(\"Average accuracy for a class is: {:.2f} %\".format(acurracy_sum/len(classes)))\n    \n    # division by 100\n    return acurracy_sum/(len(classes) * 100)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:45.436475Z","iopub.execute_input":"2022-11-25T19:32:45.436881Z","iopub.status.idle":"2022-11-25T19:32:45.448980Z","shell.execute_reply.started":"2022-11-25T19:32:45.436846Z","shell.execute_reply":"2022-11-25T19:32:45.447894Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"%%time\nNUM_EPOCHS = 1\nfor epoch in range(NUM_EPOCHS): \n    epoch_loss = 0\n    train_accuracy = 0\n    val_accuracy = 0\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n#         print(i)\n        net.train()\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n\n    print(f'[{epoch+1}/{NUM_EPOCHS}] loss: {running_loss * 1000}')\n    running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:32:45.450817Z","iopub.execute_input":"2022-11-25T19:32:45.451103Z","iopub.status.idle":"2022-11-25T19:36:04.582106Z","shell.execute_reply.started":"2022-11-25T19:32:45.451071Z","shell.execute_reply":"2022-11-25T19:36:04.580809Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[1/1] loss: 8811964.530706406\nFinished Training\nCPU times: user 13.7 s, sys: 3.48 s, total: 17.2 s\nWall time: 3min 19s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Calculating accuracy","metadata":{}},{"cell_type":"code","source":"classes = os.listdir(TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:36:04.583937Z","iopub.execute_input":"2022-11-25T19:36:04.584695Z","iopub.status.idle":"2022-11-25T19:36:04.590569Z","shell.execute_reply.started":"2022-11-25T19:36:04.584650Z","shell.execute_reply":"2022-11-25T19:36:04.589467Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"%%time\navg_acc = get_acccuracy_per_class(net, validloader, classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:36:04.595890Z","iopub.execute_input":"2022-11-25T19:36:04.596212Z","iopub.status.idle":"2022-11-25T19:36:38.278198Z","shell.execute_reply.started":"2022-11-25T19:36:04.596185Z","shell.execute_reply":"2022-11-25T19:36:38.276807Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Accuracy for class beetle is: 7.19 %\nAccuracy for class spider is: 12.70 %\nAccuracy for class turtle is: 9.20 %\nAccuracy for class snake is: 8.82 %\nAccuracy for class memorial is: 0.00 %\nAccuracy for class tomato is: 0.00 %\nAccuracy for class saw   is: 2.29 %\nAccuracy for class swine is: 5.03 %\nAccuracy for class fungus is: 0.60 %\nAccuracy for class flower is: 7.22 %\nAccuracy for class truck is: 0.00 %\nAccuracy for class bread is: 41.49 %\nAccuracy for class bomb  is: 11.36 %\nAccuracy for class spoon is: 0.00 %\nAccuracy for class carbon is: 11.63 %\nAccuracy for class bird  is: 0.52 %\nAccuracy for class antenna is: 0.00 %\nAccuracy for class spice is: 0.55 %\nAccuracy for class battery is: 0.00 %\nAccuracy for class acoustic is: 0.00 %\nAccuracy for class bacteria is: 9.89 %\nAccuracy for class motor is: 6.25 %\nAccuracy for class kangaroo is: 6.32 %\nAccuracy for class towel is: 7.32 %\nAccuracy for class worm  is: 28.82 %\nAccuracy for class gauge is: 3.72 %\nAccuracy for class tea   is: 30.59 %\nAccuracy for class frog  is: 9.41 %\nAccuracy for class elephant is: 10.00 %\nAccuracy for class bridge is: 15.17 %\nAccuracy for class nest  is: 17.58 %\nAccuracy for class fish  is: 6.04 %\nAccuracy for class bean  is: 0.00 %\nAccuracy for class bicycle is: 0.00 %\nAccuracy for class echinoderm is: 58.60 %\nAccuracy for class crab  is: 0.00 %\nAccuracy for class monkey is: 19.55 %\nAccuracy for class palm  is: 34.39 %\nAccuracy for class crocodilian is: 0.00 %\nAccuracy for class hammer is: 11.98 %\nAccuracy for class squash is: 2.67 %\nAccuracy for class pizza is: 36.26 %\nAccuracy for class icecream is: 0.00 %\nAccuracy for class cat   is: 12.96 %\nAccuracy for class pot   is: 1.12 %\nAccuracy for class corn  is: 0.00 %\nAccuracy for class camera is: 23.81 %\nAccuracy for class egg   is: 30.00 %\nAccuracy for class printer is: 24.73 %\nAccuracy for class birch is: 0.00 %\nAverage accuracy for a class is: 10.52 %\nCPU times: user 15.9 s, sys: 3.99 s, total: 19.8 s\nWall time: 33.7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"avg_acc","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:36:38.280201Z","iopub.execute_input":"2022-11-25T19:36:38.280635Z","iopub.status.idle":"2022-11-25T19:36:38.289508Z","shell.execute_reply.started":"2022-11-25T19:36:38.280592Z","shell.execute_reply":"2022-11-25T19:36:38.288469Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.10515634143815264"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving model to file","metadata":{}},{"cell_type":"code","source":"# saving model to file\nstate_dict = net.state_dict()\ntorch.save(state_dict, \"neural_net.tar\")","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:36:38.292195Z","iopub.execute_input":"2022-11-25T19:36:38.292517Z","iopub.status.idle":"2022-11-25T19:36:38.303972Z","shell.execute_reply.started":"2022-11-25T19:36:38.292490Z","shell.execute_reply":"2022-11-25T19:36:38.303017Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Reading test images","metadata":{}},{"cell_type":"code","source":"# custom test path\nTEST_PATH = \"/kaggle/input/d/franeksakowski/testset\"","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:36:38.305494Z","iopub.execute_input":"2022-11-25T19:36:38.306035Z","iopub.status.idle":"2022-11-25T19:36:38.311428Z","shell.execute_reply.started":"2022-11-25T19:36:38.305994Z","shell.execute_reply":"2022-11-25T19:36:38.310375Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# reading file names (adjust path)\ntest_files_names = os.listdir(TEST_PATH + \"/test_all\")","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:43:04.464010Z","iopub.execute_input":"2022-11-25T19:43:04.464720Z","iopub.status.idle":"2022-11-25T19:43:04.472650Z","shell.execute_reply.started":"2022-11-25T19:43:04.464683Z","shell.execute_reply":"2022-11-25T19:43:04.471733Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"testFolder = torchvision.datasets.ImageFolder(root=TEST_PATH,\n                                               transform=transforms.ToTensor())\n\ntestloader = torch.utils.data.DataLoader(testFolder, batch_size=1,\n                                         shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:45:53.772510Z","iopub.execute_input":"2022-11-25T19:45:53.772963Z","iopub.status.idle":"2022-11-25T19:45:54.688422Z","shell.execute_reply.started":"2022-11-25T19:45:53.772915Z","shell.execute_reply":"2022-11-25T19:45:54.687307Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Predictions on testset","metadata":{}},{"cell_type":"code","source":"preds = []","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:46:03.300559Z","iopub.execute_input":"2022-11-25T19:46:03.300967Z","iopub.status.idle":"2022-11-25T19:46:03.306342Z","shell.execute_reply.started":"2022-11-25T19:46:03.300931Z","shell.execute_reply":"2022-11-25T19:46:03.305024Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"%%time\nfor i, data in enumerate(testloader, 0):\n    x, labels = data\n    true_values.append(labels)\n    x, labels = x.to(device), labels.to(device)\n    preds.append(net(x).max(1, keepdim=True)[1].item())","metadata":{"execution":{"iopub.status.busy":"2022-11-25T19:46:03.622977Z","iopub.execute_input":"2022-11-25T19:46:03.624170Z","iopub.status.idle":"2022-11-25T19:46:38.497327Z","shell.execute_reply.started":"2022-11-25T19:46:03.624120Z","shell.execute_reply":"2022-11-25T19:46:38.495867Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"CPU times: user 19.7 s, sys: 4.48 s, total: 24.2 s\nWall time: 34.9 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# saving to file\npd.DataFrame({'A': test_files_names, 'B': preds}).to_csv(\"preds.csv\", index=False, header=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T20:10:46.861953Z","iopub.execute_input":"2022-11-25T20:10:46.863001Z","iopub.status.idle":"2022-11-25T20:10:46.886987Z","shell.execute_reply.started":"2022-11-25T20:10:46.862959Z","shell.execute_reply":"2022-11-25T20:10:46.886081Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"preds.csv\", header=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T20:35:03.100576Z","iopub.execute_input":"2022-11-25T20:35:03.100970Z","iopub.status.idle":"2022-11-25T20:35:03.122156Z","shell.execute_reply.started":"2022-11-25T20:35:03.100939Z","shell.execute_reply":"2022-11-25T20:35:03.121110Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"                            0   1\n0       7386844264429369.JPEG   2\n1      24419493975293927.JPEG  36\n2       7742907835373426.JPEG  46\n3      38209545241358567.JPEG  36\n4       3569300609925149.JPEG   5\n...                       ...  ..\n9995    5239559584274834.JPEG  37\n9996    1312880239038562.JPEG  37\n9997  014146161727582651.JPEG  37\n9998    7728901188836401.JPEG  41\n9999   25321388824424007.JPEG  36\n\n[10000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7386844264429369.JPEG</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24419493975293927.JPEG</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7742907835373426.JPEG</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38209545241358567.JPEG</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3569300609925149.JPEG</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>5239559584274834.JPEG</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>1312880239038562.JPEG</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>014146161727582651.JPEG</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>7728901188836401.JPEG</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>25321388824424007.JPEG</td>\n      <td>36</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training loop + saving best model","metadata":{}},{"cell_type":"code","source":"%%time\n\nepochs, losses, train_acc, val_acc = [], [], [], []\n\nbest_model = None\nbest_valid_acc = None\n\nNUM_EPOCHS = 5\nfor epoch in range(NUM_EPOCHS): \n    train_correct_count = 0\n    train_data_len = 0\n    running_loss = 0.0\n    for i, data in enumerate(train_dataloader, 0):\n        # print(i)\n        net.train()\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n\n        # print statistics\n        outputs_for_train_correct_count = outputs.max(1, keepdim=True)[1].squeeze()\n        train_correct_count += (outputs_for_train_correct_count == labels).sum()\n        train_data_len += len(labels)\n\n        # # clear memory\n        # del inputs, labels, outputs\n        # torch.mps.empty_cache()\n\n        running_loss_single_iter = loss.item()\n        running_loss += running_loss_single_iter\n        \n    \n\n    new_train_acc = train_correct_count / train_data_len\n    train_acc.append(new_train_acc)\n    \n    running_loss /= 1000\n    losses.append(running_loss)\n    new_val_acc = get_accuracy()\n    val_acc.append(new_val_acc)\n    epochs.append(epoch+1)\n    \n    # replacing best model if necessary\n    if best_model == None or best_valid_acc < new_val_acc:\n        best_model = net\n        best_valid_acc = new_val_acc\n        \n        # saving model to file\n        state_dict = best_model.state_dict()\n        torch.save(state_dict, \"neural_net.tar\")\n\n    print(f'epoch {epoch+1} train running accuracy = {new_train_acc}, val_accuracy = {new_val_acc}')\n    print(f'[{epoch+1}/{NUM_EPOCHS}] running loss: {round(running_loss, 4)}, macro avg accuracy: {round(get_accuracy_per_class(), 4)}\\n')\n    running_loss = 0.0\n\nprint('Finished Training')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}