{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, setting up device and seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(1)\n",
    "# device = torch.device(\"cuda\")\n",
    "# device = torch.device('mps')\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa94b7",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d478aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_COLAB_VERSION = False\n",
    "VALIDATION_PERCENTAGE = 0.10\n",
    "TRAIN_PATH = \"./train\"\n",
    "TEST_PATH = \"./test_all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainFolder = torchvision.datasets.ImageFolder(root=TRAIN_PATH,\n",
    "                                               transform=transform)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainFolder, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root=TEST_PATH, train=False,\n",
    "#                                        download=False, transform=transform)\n",
    "\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation\n",
    "train_size = int((1 - VALIDATION_PERCENTAGE) * len(trainFolder))\n",
    "val_size = len(trainFolder) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(trainFolder, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79209"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_subset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_subset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=256) # TODO: change to max, który się szybko liczy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Mobdule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, 2)\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv3 = nn.Conv2d(128, 256, 2)\n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv4 = nn.Conv2d(256, 512, 2)\n",
    "#         self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv5 = nn.Conv2d(64, 128, 2)\n",
    "#         self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv6 = nn.Conv2d(128, 128, 2)\n",
    "#         self.pool6 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "#         self.conv7 = nn.Conv2d(128, 128, 2)\n",
    "#         self.pool7 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "#         self.conv8 = nn.Conv2d(128, 128, 2)\n",
    "#         self.pool8 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "#         self.fc1 = nn.Linear(4608, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 50)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool1(F.relu(self.conv1(x)))\n",
    "#         x = self.pool2(F.relu(self.conv2(x)))\n",
    "#         x = self.pool3(F.relu(self.conv3(x)))\n",
    "#         x = self.pool4(F.relu(self.conv4(x)))\n",
    "\n",
    "#         # x = self.pool5(F.relu(self.conv5(x)))\n",
    "#         # x = self.pool6(F.relu(self.conv6(x)))\n",
    "#         # x = self.pool7(F.relu(self.conv7(x)))\n",
    "#         # x = self.pool8(F.relu(self.conv8(x)))\n",
    "\n",
    "#         # print(x.shape, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LongNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         ## Warstwa konwolucyjna\n",
    "#         self.n_convs =  4\n",
    "#         n_channels = 32\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=n_channels, kernel_size=5, stride=1, padding=0)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=5, stride=1, padding=0)\n",
    "#         self.convs = [nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2) for _ in range(self.n_convs)]\n",
    "#         self.bns = [nn.BatchNorm2d(n_channels) for _ in range(self.n_convs)]\n",
    "     \n",
    "#         ## Warstwa max pooling \n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(n_channels * 28 * 28, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 50)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x_2 = F.relu(self.conv2(x))\n",
    "#         x = x_2\n",
    "#         for i in range(self.n_convs):    # tutaj w pętli jest chyba skip connection, skipujemy wyjścia drugiej warstwy do kazdej kolejnej\n",
    "#             x = torch.cat([x,x_2],dim=1)\n",
    "#             x = F.relu(self.convs[i](x))\n",
    "#             x = self.bns[i](x)\n",
    "#         x = self.pool1(x)\n",
    "# #         print(x.size())\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# net = LongNet().to(device)\n",
    "# for conv in net.convs:\n",
    "#     conv.to(device)\n",
    "# for bn in net.bns:\n",
    "#     bn.to(device)\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         ## Warstwa konwolucyjna\n",
    "#         self.n_convs =  8\n",
    "#         n_channels = 10\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=n_channels, kernel_size=5, stride=1, padding=0)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn3 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn4 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv5 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn5 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv6 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn6 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv7 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn7 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv8 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn8 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv9 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn9 = nn.BatchNorm2d(n_channels)\n",
    "#         self.conv10 = nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn10 = nn.BatchNorm2d(n_channels)\n",
    "\n",
    "#         self.convs = [self.conv3, self.conv4, self.conv5, self.conv6, self.conv7, self.conv8, self.conv9, self.conv10]\n",
    "#         self.bns = [self.bn3, self.bn4, self.bn5, self.bn6, self.bn7, self.bn8, self.bn9, self.bn10]\n",
    "#         # self.convs = [nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2) for _ in range(self.n_convs)]\n",
    "#         # self.bns = [nn.BatchNorm2d(n_channels) for _ in range(self.n_convs)]\n",
    "\n",
    "#         ## Warstwa max pooling \n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(n_channels * 28 * 28, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 50)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x_2 = F.relu(self.conv2(x))\n",
    "#         x = x_2\n",
    "#         for i in range(self.n_convs):    # tutaj w pętli jest chyba skip connection, skipujemy wyjścia drugiej warstwy do kazdej kolejnej\n",
    "#             x = torch.cat([x,x_2],dim=1)\n",
    "#             x = F.relu(self.convs[i](x))\n",
    "#             x = self.bns[i](x)\n",
    "#         x = self.pool1(x)\n",
    "# #         print(x.size())\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels=64):\n",
    "#         super().__init__()\n",
    "#         ## Warstwa konwolucyjna\n",
    "#         out_channels = in_channels\n",
    "#         self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=in_channels*2, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x_1 = self.bn1(F.relu(self.conv1(x)))\n",
    "#         # x = x_1\n",
    "\n",
    "#         x_2 = self.bn2(F.relu(self.conv2(x_1)))\n",
    "#         # x = x_2\n",
    "\n",
    "#         x_3 = self.bn3(F.relu(self.conv3(x_2)))\n",
    "#         x_3 = torch.cat([x_3, x],dim=1)\n",
    "#         # x = torch.cat([x_3, x],dim=1)\n",
    "\n",
    "#         x_4 = self.bn3(F.relu(self.conv4(x_3)))\n",
    "\n",
    "#         x_5 = torch.cat([x_4, x_2],dim=1)\n",
    "#         # x = x_2\n",
    "#         # for i in range(self.n_convs):    # tutaj w pętli jest chyba skip connection, skipujemy wyjścia drugiej warstwy do kazdej kolejnej\n",
    "#         #     x = torch.cat([x,x_2],dim=1)\n",
    "#         #     x = F.relu(self.convs[i](x))\n",
    "#         #     x = self.bns[i](x)\n",
    "#         # x = self.pool1(x)\n",
    "# #         print(x.size())\n",
    "#         # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         # x = F.relu(self.fc1(x))\n",
    "#         # x = F.relu(self.fc2(x))\n",
    "#         # x = self.fc3(x)\n",
    "#         return x_5\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         ## Warstwa konwolucyjna\n",
    "#         n_channels = 64\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=n_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "#         self.conv_block1 = ConvBlock(in_channels=n_channels)\n",
    "\n",
    "#         # self.convs = [self.conv3, self.conv4, self.conv5, self.conv6, self.conv7, self.conv8, self.conv9, self.conv10]\n",
    "#         # self.bns = [self.bn3, self.bn4, self.bn5, self.bn6, self.bn7, self.bn8, self.bn9, self.bn10]\n",
    "#         # self.convs = [nn.Conv2d(in_channels=n_channels*2, out_channels=n_channels, kernel_size=5, stride=1, padding=2) for _ in range(self.n_convs)]\n",
    "#         # self.bns = [nn.BatchNorm2d(n_channels) for _ in range(self.n_convs)]\n",
    "\n",
    "#         ## Warstwa max pooling \n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(n_channels * 16 * 16 * 2, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 50)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = F.relu(self.conv_block1(x))\n",
    "#         x = self.pool2(x)\n",
    "# #         print(x.size())\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 50):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(2, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# n_channels_test = 64\n",
    "# input_test = torch.rand(32, 3, 32, 32)\n",
    "\n",
    "# conv1_test = torch.nn.Conv2d(in_channels=3, out_channels=n_channels_test, kernel_size=3, stride=1, padding=1)\n",
    "# x_test = conv1_test(input_test)\n",
    "# print(x_test.shape)\n",
    "\n",
    "# conv2_test = nn.Conv2d(in_channels=n_channels_test, out_channels=n_channels_test, kernel_size=3, stride=1, padding=1)\n",
    "# x_test = conv2_test(x_test)\n",
    "# print(x_test.shape)\n",
    "\n",
    "# conv3_test = ConvBlock(in_channels=n_channels_test)\n",
    "# x_test = conv3_test(x_test)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# net = Net().to(device)\n",
    "# net = models.resnet18().to(device)\n",
    "# net = models.densenet161().to(device)\n",
    "# net = Net().to(device)\n",
    "net = ResNet(ResidualBlock, [2, 2, 2, 2]).to(device) # TODO: change to 4, 4, 4, 4\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.2078, -0.2392, -0.3020,  ..., -0.1765, -0.1373, -0.1686],\n",
      "          [-0.1765, -0.2000, -0.2706,  ..., -0.2706, -0.1843, -0.1765],\n",
      "          [-0.1373, -0.1608, -0.2235,  ..., -0.2549, -0.1608, -0.1451],\n",
      "          ...,\n",
      "          [-0.3961, -0.3725, -0.3647,  ..., -0.4588, -0.4510, -0.4824],\n",
      "          [-0.4431, -0.4039, -0.3961,  ..., -0.5137, -0.5451, -0.4980],\n",
      "          [-0.5059, -0.4667, -0.4510,  ..., -0.5373, -0.6157, -0.4824]],\n",
      "\n",
      "         [[-0.4118, -0.4196, -0.4353,  ...,  0.0118,  0.0431,  0.0118],\n",
      "          [-0.3882, -0.4039, -0.4118,  ..., -0.0824, -0.0039,  0.0039],\n",
      "          [-0.3804, -0.3882, -0.3961,  ..., -0.0667,  0.0275,  0.0353],\n",
      "          ...,\n",
      "          [-0.1608, -0.1373, -0.1294,  ..., -0.4196, -0.4196, -0.4588],\n",
      "          [-0.2235, -0.1843, -0.1608,  ..., -0.4510, -0.5137, -0.4667],\n",
      "          [-0.2863, -0.2471, -0.2314,  ..., -0.4745, -0.5843, -0.4510]],\n",
      "\n",
      "         [[-0.5451, -0.5608, -0.5922,  ..., -0.2549, -0.1843, -0.2078],\n",
      "          [-0.5216, -0.5373, -0.5843,  ..., -0.3490, -0.2314, -0.2157],\n",
      "          [-0.5216, -0.5294, -0.5765,  ..., -0.3333, -0.2235, -0.1922],\n",
      "          ...,\n",
      "          [-0.5529, -0.5451, -0.5373,  ..., -0.5765, -0.5529, -0.5922],\n",
      "          [-0.6235, -0.5843, -0.5686,  ..., -0.6157, -0.6471, -0.6000],\n",
      "          [-0.6863, -0.6471, -0.6314,  ..., -0.6392, -0.7176, -0.5843]]],\n",
      "\n",
      "\n",
      "        [[[-0.3490, -0.4196, -0.5137,  ..., -0.0510, -0.3412, -0.7725],\n",
      "          [-0.3490, -0.4275, -0.5137,  ..., -0.2157, -0.4510, -0.6941],\n",
      "          [-0.3725, -0.4353, -0.5059,  ..., -0.5294, -0.6863, -0.7176],\n",
      "          ...,\n",
      "          [ 0.5686,  0.5922,  0.6235,  ...,  0.3490,  0.3490,  0.3412],\n",
      "          [ 0.4588,  0.4667,  0.4980,  ...,  0.3569,  0.3412,  0.3412],\n",
      "          [ 0.5529,  0.4980,  0.4510,  ...,  0.3333,  0.3098,  0.3098]],\n",
      "\n",
      "         [[-0.6471, -0.6314, -0.6157,  ...,  0.1216, -0.2235, -0.7176],\n",
      "          [-0.6471, -0.6314, -0.6157,  ..., -0.0431, -0.3333, -0.6392],\n",
      "          [-0.6627, -0.6392, -0.6078,  ..., -0.3725, -0.5765, -0.6784],\n",
      "          ...,\n",
      "          [ 0.4824,  0.5137,  0.5529,  ...,  0.2549,  0.2549,  0.2471],\n",
      "          [ 0.3804,  0.3961,  0.4353,  ...,  0.2627,  0.2471,  0.2471],\n",
      "          [ 0.4824,  0.4353,  0.3961,  ...,  0.2392,  0.2157,  0.2157]],\n",
      "\n",
      "         [[-0.7961, -0.8431, -0.8824,  ..., -0.1843, -0.5608, -1.0000],\n",
      "          [-0.7961, -0.8431, -0.8824,  ..., -0.3255, -0.6392, -0.9608],\n",
      "          [-0.8039, -0.8353, -0.8588,  ..., -0.5922, -0.8353, -0.9294],\n",
      "          ...,\n",
      "          [ 0.4353,  0.4353,  0.4196,  ...,  0.1294,  0.1294,  0.1216],\n",
      "          [ 0.2863,  0.2627,  0.2549,  ...,  0.1529,  0.1373,  0.1373],\n",
      "          [ 0.3490,  0.2863,  0.1922,  ...,  0.1294,  0.1059,  0.1059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8196,  0.9216,  0.8745,  ...,  0.5686,  0.6784,  1.0000],\n",
      "          [ 0.9216,  0.8431,  0.9216,  ...,  0.5294,  0.6078,  0.9529],\n",
      "          [ 0.9059,  0.8824,  0.9451,  ...,  0.4275,  0.4667,  0.8039],\n",
      "          ...,\n",
      "          [ 0.9922,  0.9922,  0.9529,  ...,  0.0745,  0.2235,  0.3725],\n",
      "          [ 1.0000,  0.9686,  0.9608,  ...,  0.1137,  0.2314,  0.3176],\n",
      "          [ 1.0000,  0.9451,  0.9843,  ...,  0.1686,  0.2392,  0.2157]],\n",
      "\n",
      "         [[ 0.6392,  0.7333,  0.6706,  ..., -0.1373,  0.2784,  0.9216],\n",
      "          [ 0.7412,  0.6549,  0.7176,  ..., -0.1765,  0.1686,  0.8196],\n",
      "          [ 0.7490,  0.6941,  0.7333,  ..., -0.2706, -0.0118,  0.5765],\n",
      "          ...,\n",
      "          [ 0.7020,  0.7176,  0.7098,  ..., -0.5451, -0.3255, -0.1294],\n",
      "          [ 0.7333,  0.6784,  0.7176,  ..., -0.4588, -0.2549, -0.1529],\n",
      "          [ 0.7882,  0.6392,  0.7412,  ..., -0.3725, -0.2314, -0.2471]],\n",
      "\n",
      "         [[ 0.3961,  0.5451,  0.5373,  ..., -0.0431,  0.3333,  0.9059],\n",
      "          [ 0.4980,  0.4510,  0.5843,  ..., -0.0980,  0.1922,  0.7569],\n",
      "          [ 0.4902,  0.4745,  0.5686,  ..., -0.2235, -0.0510,  0.4353],\n",
      "          ...,\n",
      "          [ 0.5608,  0.5686,  0.5529,  ..., -0.8824, -0.8118, -0.7098],\n",
      "          [ 0.6235,  0.5373,  0.5608,  ..., -0.7333, -0.7020, -0.7020],\n",
      "          [ 0.6863,  0.5059,  0.5765,  ..., -0.6157, -0.6392, -0.7647]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4745, -0.2863, -0.4667,  ..., -0.9765, -0.9765, -0.9686],\n",
      "          [-0.3725, -0.2863, -0.4510,  ..., -0.9922, -0.9765, -0.9529],\n",
      "          [-0.4275, -0.3804, -0.4275,  ..., -0.8667, -0.8431, -0.8196],\n",
      "          ...,\n",
      "          [-0.3255, -0.5137, -0.6471,  ..., -0.4980, -0.1373, -0.1294],\n",
      "          [-0.6157, -0.6706, -0.6627,  ..., -0.4824, -0.4980, -0.6157],\n",
      "          [-0.3490, -0.3098, -0.2784,  ..., -0.5059, -0.8275, -0.8353]],\n",
      "\n",
      "         [[-0.4275, -0.2549, -0.4353,  ..., -0.9608, -0.9608, -0.9529],\n",
      "          [-0.3255, -0.2392, -0.4039,  ..., -0.9843, -0.9529, -0.9294],\n",
      "          [-0.3647, -0.3176, -0.3647,  ..., -0.8588, -0.8353, -0.8118],\n",
      "          ...,\n",
      "          [-0.2863, -0.4745, -0.6078,  ..., -0.4431, -0.0824, -0.0745],\n",
      "          [-0.5686, -0.6235, -0.6157,  ..., -0.4275, -0.4431, -0.5608],\n",
      "          [-0.3020, -0.2627, -0.2314,  ..., -0.4510, -0.7725, -0.7804]],\n",
      "\n",
      "         [[-0.2235, -0.0431, -0.2235,  ..., -0.9843, -0.9843, -0.9765],\n",
      "          [-0.1373, -0.0510, -0.2314,  ..., -0.9451, -0.9137, -0.8902],\n",
      "          [-0.1843, -0.1529, -0.2000,  ..., -0.7176, -0.6784, -0.6549],\n",
      "          ...,\n",
      "          [-0.1294, -0.3176, -0.4510,  ..., -0.3176,  0.0431,  0.0510],\n",
      "          [-0.4431, -0.4980, -0.4902,  ..., -0.2863, -0.3176, -0.4353],\n",
      "          [-0.1922, -0.1529, -0.1216,  ..., -0.3098, -0.6314, -0.6549]]],\n",
      "\n",
      "\n",
      "        [[[-0.9216, -0.8588, -0.9373,  ...,  0.0745,  0.0980,  0.1137],\n",
      "          [-0.9294, -0.9137, -0.9451,  ...,  0.0824,  0.0980,  0.1059],\n",
      "          [-0.9059, -0.9529, -0.9059,  ...,  0.0980,  0.0902,  0.0980],\n",
      "          ...,\n",
      "          [ 0.3333,  0.3412,  0.3804,  ...,  0.2078,  0.2078,  0.1843],\n",
      "          [ 0.4275,  0.4980,  0.4510,  ...,  0.2314,  0.2784,  0.2471],\n",
      "          [ 0.2549,  0.3647,  0.2784,  ...,  0.2000,  0.2784,  0.2392]],\n",
      "\n",
      "         [[-0.9451, -0.8824, -0.9686,  ..., -0.0824, -0.0980, -0.1059],\n",
      "          [-0.9529, -0.9373, -0.9529,  ..., -0.0745, -0.0980, -0.1137],\n",
      "          [-0.9294, -0.9765, -0.9137,  ..., -0.0588, -0.0980, -0.1216],\n",
      "          ...,\n",
      "          [ 0.3490,  0.3569,  0.3804,  ...,  0.2549,  0.2706,  0.2627],\n",
      "          [ 0.4431,  0.5137,  0.4510,  ...,  0.2784,  0.3412,  0.3255],\n",
      "          [ 0.2706,  0.3804,  0.2784,  ...,  0.2471,  0.3412,  0.3098]],\n",
      "\n",
      "         [[-0.9843, -0.9216, -0.9922,  ..., -0.5451, -0.6000, -0.6157],\n",
      "          [-0.9922, -0.9765, -0.9843,  ..., -0.5529, -0.6000, -0.6235],\n",
      "          [-0.9686, -1.0000, -0.9451,  ..., -0.5373, -0.6000, -0.6314],\n",
      "          ...,\n",
      "          [ 0.4431,  0.4510,  0.4588,  ...,  0.3490,  0.3725,  0.3569],\n",
      "          [ 0.5373,  0.6078,  0.5294,  ...,  0.3725,  0.4431,  0.4196],\n",
      "          [ 0.3647,  0.4745,  0.3569,  ...,  0.3412,  0.4431,  0.4275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9529,  0.9686,  0.9686,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.9686,  0.9765,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9765,  0.9765,  0.9765,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9765,  0.9765,  0.9765,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.9686,  0.9686,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  1.0000,  0.9922],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.9922],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  0.9922,  0.9922],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  0.9922,  0.9922]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  0.9451,  0.9294,  0.9137],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9686,  0.9608,  0.9608],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9843,  0.9843,  0.9686],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9843,  0.9686,  0.9686],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9686,  0.9686,  0.9686]]]]), tensor([ 5, 44, 34, 17, 21, 20,  6, 41, 32, 43, 12, 47,  7,  5, 11, 10, 47,  5,\n",
      "        12,  8,  1, 49, 22,  9, 34,  5, 46,  3, 35, 25, 12, 10])]\n",
      "<class 'list'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(test_batch)\n",
    "print(type(test_batch))\n",
    "print(len(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# from datetime import datetime\n",
    "\n",
    "# # uncomment this cell to visualize a net (do it on the cpu - change device from 'mps' to 'cpu')\n",
    "# yhat = net(test_batch[0])\n",
    "# current_datetime_formatted = f'{datetime.now()}'.replace('-', '_').replace(' ', '_').replace(':', '_')[:-4]\n",
    "# make_dot(yhat, params=dict(list(net.named_parameters()))).render(f\"net_visualizations/net_visualization{current_datetime_formatted}\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_parameters(net=models.resnet18()):\n",
    "    params_sum = 0\n",
    "    for params in net.parameters():\n",
    "        params_sum+=params.view(-1).size(0)\n",
    "    return params_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in created net = 11206962\n",
      "number of parameters in resnet18    = 11689512\n"
     ]
    }
   ],
   "source": [
    "# number of parameters in Net - compare to resnet18\n",
    "print(f'number of parameters in created net = {number_of_parameters(net=net)}')\n",
    "print(f'number of parameters in resnet18    = {number_of_parameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(val_dataloader=val_dataloader):\n",
    "    # copy and create new get_accuracy() func - per class\n",
    "    val_correct_count = 0\n",
    "    val_data_len = 0\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "\n",
    "    for i, data in enumerate(val_dataloader, 0):\n",
    "        net.eval()\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        outputs_for_val_correct_count = outputs.max(1, keepdim=True)[1].squeeze()\n",
    "        val_correct_count += (outputs_for_val_correct_count == labels).sum()\n",
    "        val_data_len += len(labels)\n",
    "\n",
    "    new_val_acc = val_correct_count / val_data_len\n",
    "    return new_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dcPPvHRO1JWA"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0hGHHfwJ4mUC",
    "outputId": "479aa43b-3b99-4f9f-d9f4-558eb29b8edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    train_correct_count = 0\n",
    "    train_data_len = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # print(i)\n",
    "        net.train()\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        outputs_for_train_correct_count = outputs.max(1, keepdim=True)[1].squeeze()\n",
    "        train_correct_count += (outputs_for_train_correct_count == labels).sum()\n",
    "        train_data_len += len(labels)\n",
    "\n",
    "        # # clear memory\n",
    "        # del inputs, labels, outputs\n",
    "        # torch.mps.empty_cache()\n",
    "\n",
    "        running_loss_single_iter = loss.item()\n",
    "        running_loss += running_loss_single_iter\n",
    "\n",
    "    new_train_acc = train_correct_count / train_data_len\n",
    "    train_acc.append(new_train_acc)\n",
    "\n",
    "    print(f'epoch {epoch} train accuracy = {new_train_acc}, val_accuracy = {get_accuracy()}')\n",
    "\n",
    "    print(f'[{epoch+1}/{NUM_EPOCHS}] loss: {running_loss/1000}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy = 0.01999545469880104\n"
     ]
    }
   ],
   "source": [
    "print(f'validation accuracy = {get_accuracy()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7aaad0630ad3230b7b955ab34166b9352cf35c53f01b298fd4177c5371ed1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
