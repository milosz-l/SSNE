{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4551f6b-5140-447a-a652-9a20b73d4d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from tqdm import tnrange\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398df0b1-5a07-4d93-98ac-a1ea23d13887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', delimiter=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e4772c-854c-465f-97e8-fe61cfeb8895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0  2011-01-20       1   0     1   0        0        4           1           1   \n",
       "1  2011-01-20       1   0     1   1        0        4           1           1   \n",
       "2  2011-01-20       1   0     1   2        0        4           1           1   \n",
       "3  2011-01-20       1   0     1   3        0        4           1           1   \n",
       "4  2011-01-20       1   0     1   4        0        4           1           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  \n",
       "0  0.26  0.2273  0.56     0.3881  \n",
       "1  0.26  0.2727  0.56     0.0000  \n",
       "2  0.26  0.2727  0.56     0.0000  \n",
       "3  0.26  0.2576  0.56     0.1642  \n",
       "4  0.26  0.2576  0.56     0.1642  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_csv('evaluation_data.csv', delimiter=\",\")\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72df30d-b549-46b1-b5cc-1f08705214ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8537.421183</td>\n",
       "      <td>2.506614</td>\n",
       "      <td>0.501929</td>\n",
       "      <td>6.521495</td>\n",
       "      <td>11.541613</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>2.998622</td>\n",
       "      <td>0.680875</td>\n",
       "      <td>1.418427</td>\n",
       "      <td>0.493436</td>\n",
       "      <td>0.473102</td>\n",
       "      <td>0.618865</td>\n",
       "      <td>0.191036</td>\n",
       "      <td>36.021955</td>\n",
       "      <td>155.552177</td>\n",
       "      <td>191.574132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5026.363303</td>\n",
       "      <td>1.116174</td>\n",
       "      <td>0.500019</td>\n",
       "      <td>3.444373</td>\n",
       "      <td>6.915838</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>2.007770</td>\n",
       "      <td>0.466159</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>0.190039</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.121859</td>\n",
       "      <td>49.960477</td>\n",
       "      <td>151.039033</td>\n",
       "      <td>181.144454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4282.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8666.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13016.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17093.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            instant        season            yr          mnth            hr  \\\n",
       "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
       "mean    8537.421183      2.506614      0.501929      6.521495     11.541613   \n",
       "std     5026.363303      1.116174      0.500019      3.444373      6.915838   \n",
       "min        1.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "25%     4282.250000      2.000000      0.000000      4.000000      6.000000   \n",
       "50%     8666.500000      3.000000      1.000000      7.000000     12.000000   \n",
       "75%    13016.750000      4.000000      1.000000     10.000000     18.000000   \n",
       "max    17093.000000      4.000000      1.000000     12.000000     23.000000   \n",
       "\n",
       "            holiday       weekday    workingday    weathersit          temp  \\\n",
       "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
       "mean       0.028569      2.998622      0.680875      1.418427      0.493436   \n",
       "std        0.166599      2.007770      0.466159      0.633839      0.190039   \n",
       "min        0.000000      0.000000      0.000000      1.000000      0.020000   \n",
       "25%        0.000000      1.000000      0.000000      1.000000      0.340000   \n",
       "50%        0.000000      3.000000      1.000000      1.000000      0.500000   \n",
       "75%        0.000000      5.000000      1.000000      2.000000      0.640000   \n",
       "max        1.000000      6.000000      1.000000      4.000000      1.000000   \n",
       "\n",
       "              atemp           hum     windspeed        casual    registered  \\\n",
       "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
       "mean       0.473102      0.618865      0.191036     36.021955    155.552177   \n",
       "std        0.169492      0.192450      0.121859     49.960477    151.039033   \n",
       "min        0.015200      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.333300      0.470000      0.104500      4.000000     36.000000   \n",
       "50%        0.484800      0.620000      0.194000     17.000000    118.000000   \n",
       "75%        0.621200      0.770000      0.253700     49.000000    222.000000   \n",
       "max        0.909100      1.000000      0.850700    367.000000    886.000000   \n",
       "\n",
       "                cnt  \n",
       "count  10886.000000  \n",
       "mean     191.574132  \n",
       "std      181.144454  \n",
       "min        1.000000  \n",
       "25%       42.000000  \n",
       "50%      145.000000  \n",
       "75%      284.000000  \n",
       "max      977.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b40a3a-180f-420f-93c2-d1d0d55d2960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "\n",
       "    atemp   hum  windspeed  cnt  \n",
       "0  0.2879  0.81        0.0   16  \n",
       "1  0.2727  0.80        0.0   40  \n",
       "2  0.2727  0.80        0.0   32  \n",
       "3  0.2879  0.75        0.0   13  \n",
       "4  0.2879  0.75        0.0    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['dteday', 'casual', 'registered', 'instant'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dabe6089-34ef-4c67-9476-dcbdaaa9f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d9a8ad-32bd-4378-be24-0fa2f49026d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:9500]\n",
    "val = df.iloc[9500:]\n",
    "# test = df.iloc[8500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "713690ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df_eval.drop(columns=['dteday'])\n",
    "test = df_eval.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ef6425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season   yr  mnth    hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0        1.0  0.0   1.0   0.0      0.0      4.0         1.0         1.0  0.26   \n",
       "1        1.0  0.0   1.0   1.0      0.0      4.0         1.0         1.0  0.26   \n",
       "2        1.0  0.0   1.0   2.0      0.0      4.0         1.0         1.0  0.26   \n",
       "3        1.0  0.0   1.0   3.0      0.0      4.0         1.0         1.0  0.26   \n",
       "4        1.0  0.0   1.0   4.0      0.0      4.0         1.0         1.0  0.26   \n",
       "...      ...  ...   ...   ...      ...      ...         ...         ...   ...   \n",
       "6488     1.0  1.0  12.0  19.0      0.0      1.0         1.0         2.0  0.26   \n",
       "6489     1.0  1.0  12.0  20.0      0.0      1.0         1.0         2.0  0.26   \n",
       "6490     1.0  1.0  12.0  21.0      0.0      1.0         1.0         1.0  0.26   \n",
       "6491     1.0  1.0  12.0  22.0      0.0      1.0         1.0         1.0  0.26   \n",
       "6492     1.0  1.0  12.0  23.0      0.0      1.0         1.0         1.0  0.26   \n",
       "\n",
       "       atemp   hum  windspeed  \n",
       "0     0.2273  0.56     0.3881  \n",
       "1     0.2727  0.56     0.0000  \n",
       "2     0.2727  0.56     0.0000  \n",
       "3     0.2576  0.56     0.1642  \n",
       "4     0.2576  0.56     0.1642  \n",
       "...      ...   ...        ...  \n",
       "6488  0.2576  0.60     0.1642  \n",
       "6489  0.2576  0.60     0.1642  \n",
       "6490  0.2576  0.60     0.1642  \n",
       "6491  0.2727  0.56     0.1343  \n",
       "6492  0.2727  0.65     0.1343  \n",
       "\n",
       "[6493 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7835b6d-b9b8-4f36-a1f2-c055790b4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 12)\n",
      "(1386, 12)\n",
      "(6493, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train= train.drop('cnt', axis=1), train['cnt']\n",
    "print(X_train.shape)\n",
    "\n",
    "X_val, y_val = val.drop('cnt', axis=1), val['cnt']\n",
    "print(X_val.shape)\n",
    "\n",
    "X_test = test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c990e09a-1e62-40e9-a86b-613be3bb1d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 475\n"
     ]
    }
   ],
   "source": [
    "f=20 # no. of batches\n",
    "\n",
    "train_batch = np.array_split(X_train, f) \n",
    "label_batch = np.array_split(y_train, f) # 50 sections/batches\n",
    "\n",
    "val_batch = np.array_split(X_val, f)\n",
    "val_label_batch = np.array_split(y_val, f)\n",
    "\n",
    "test_batch = np.array_split(X_test,f) \n",
    "# test_label_batch  = np.array_split(y_test, f)\n",
    "\n",
    "\n",
    "for i in range(len(train_batch)):\n",
    "    train_batch[i] = torch.from_numpy(train_batch[i].values).float()\n",
    "for i in range(len(label_batch)):\n",
    "    label_batch[i] = torch.from_numpy(label_batch[i].values).float().view(-1, 1)\n",
    "    \n",
    "for i in range(len(val_batch)):\n",
    "    val_batch[i] = torch.from_numpy(val_batch[i].values).float()\n",
    "for i in range(len(val_label_batch)):\n",
    "    val_label_batch[i] = torch.from_numpy(val_label_batch[i].values).float().view(-1, 1)\n",
    "    \n",
    "    \n",
    "for i in range(len(test_batch)):\n",
    "    test_batch[i] = torch.from_numpy(test_batch[i].values).float()\n",
    "# for i in range(len(test_label_batch)):\n",
    "#     test_label_batch[i] = torch.from_numpy(test_label_batch[i].values).float().view(-1, 1)\n",
    "    \n",
    "print(\"Batch size:\", len(train_batch[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77989b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d979c8-389d-416a-8f31-c63a994762a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(12, 24)\n",
    "        self.fc2 = nn.Linear(24, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.20)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Regressor()\n",
    "train_losses, val_losses = [], []\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003) # 0.015 87\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.1, patience=15) \n",
    "total_epochs=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f69cf77a-9ce5-49d7-810a-b6969d4410c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = copy.deepcopy(model)\n",
    "best_val_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db99d7a1-32b5-4cfa-95e8-2f26be9c97d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model replaced\n",
      "Epoch : 0 train_loss : 64141.763671875 Val loss:  101232.34607421875\n",
      "Model replaced\n",
      "Epoch : 1 train_loss : 64006.714575195314 Val loss:  101003.54298828126\n",
      "Model replaced\n",
      "Epoch : 2 train_loss : 63860.325854492185 Val loss:  100769.03435546874\n",
      "Model replaced\n",
      "Epoch : 3 train_loss : 63712.585180664064 Val loss:  100513.323046875\n",
      "Model replaced\n",
      "Epoch : 4 train_loss : 63552.296557617185 Val loss:  100246.36041015625\n",
      "Model replaced\n",
      "Epoch : 5 train_loss : 63375.55471191406 Val loss:  99944.91019531249\n",
      "Model replaced\n",
      "Epoch : 6 train_loss : 63176.43420410156 Val loss:  99614.98993164062\n",
      "Model replaced\n",
      "Epoch : 7 train_loss : 62962.04194335938 Val loss:  99259.59645507814\n",
      "Model replaced\n",
      "Epoch : 8 train_loss : 62725.46638183594 Val loss:  98860.1469140625\n",
      "Model replaced\n",
      "Epoch : 9 train_loss : 62476.67338867187 Val loss:  98444.59077148438\n",
      "Model replaced\n",
      "Epoch : 10 train_loss : 62215.25327148438 Val loss:  97991.76954101563\n",
      "Model replaced\n",
      "Epoch : 11 train_loss : 61921.183374023436 Val loss:  97481.04291015625\n",
      "Model replaced\n",
      "Epoch : 12 train_loss : 61617.68271484375 Val loss:  96969.23014648438\n",
      "Model replaced\n",
      "Epoch : 13 train_loss : 61283.06376953125 Val loss:  96423.00419921875\n",
      "Model replaced\n",
      "Epoch : 14 train_loss : 60903.45844726563 Val loss:  95783.27768554687\n",
      "Model replaced\n",
      "Epoch : 15 train_loss : 60543.35810546875 Val loss:  95176.01743164062\n",
      "Model replaced\n",
      "Epoch : 16 train_loss : 60122.93159179688 Val loss:  94561.76674804688\n",
      "Model replaced\n",
      "Epoch : 17 train_loss : 59677.65810546875 Val loss:  93785.30525390625\n",
      "Model replaced\n",
      "Epoch : 18 train_loss : 59272.523168945314 Val loss:  93091.5626171875\n",
      "Model replaced\n",
      "Epoch : 19 train_loss : 58820.52185058594 Val loss:  92346.05520507813\n",
      "Model replaced\n",
      "Epoch : 20 train_loss : 58367.167236328125 Val loss:  91538.418125\n",
      "Model replaced\n",
      "Epoch : 21 train_loss : 57821.75046386719 Val loss:  90692.82928710937\n",
      "Model replaced\n",
      "Epoch : 22 train_loss : 57299.08575439453 Val loss:  89805.64430664064\n",
      "Model replaced\n",
      "Epoch : 23 train_loss : 56800.51795654297 Val loss:  88917.92157226562\n",
      "Model replaced\n",
      "Epoch : 24 train_loss : 56195.19128417969 Val loss:  87873.032109375\n",
      "Model replaced\n",
      "Epoch : 25 train_loss : 55647.16715087891 Val loss:  86961.23951171876\n",
      "Model replaced\n",
      "Epoch : 26 train_loss : 54944.352014160155 Val loss:  86014.99989257813\n",
      "Model replaced\n",
      "Epoch : 27 train_loss : 54258.80343017578 Val loss:  84934.4929296875\n",
      "Model replaced\n",
      "Epoch : 28 train_loss : 53684.017590332034 Val loss:  83879.44850585939\n",
      "Model replaced\n",
      "Epoch : 29 train_loss : 52846.880078125 Val loss:  82766.18907226562\n",
      "Model replaced\n",
      "Epoch : 30 train_loss : 52297.77325439453 Val loss:  81633.91034179687\n",
      "Model replaced\n",
      "Epoch : 31 train_loss : 51548.53518066406 Val loss:  80498.9393359375\n",
      "Model replaced\n",
      "Epoch : 32 train_loss : 50920.58452148437 Val loss:  79333.89965820312\n",
      "Model replaced\n",
      "Epoch : 33 train_loss : 50241.48446044922 Val loss:  78192.404140625\n",
      "Model replaced\n",
      "Epoch : 34 train_loss : 49579.94345703125 Val loss:  77032.73438476563\n",
      "Model replaced\n",
      "Epoch : 35 train_loss : 48990.63946533203 Val loss:  75926.63790039063\n",
      "Model replaced\n",
      "Epoch : 36 train_loss : 48178.55483398437 Val loss:  74854.1148046875\n",
      "Model replaced\n",
      "Epoch : 37 train_loss : 47393.531677246094 Val loss:  73744.8562109375\n",
      "Model replaced\n",
      "Epoch : 38 train_loss : 46715.34732666016 Val loss:  72677.44191406251\n",
      "Model replaced\n",
      "Epoch : 39 train_loss : 46119.23084716797 Val loss:  71589.62060546875\n",
      "Model replaced\n",
      "Epoch : 40 train_loss : 45485.69289550781 Val loss:  70502.253671875\n",
      "Model replaced\n",
      "Epoch : 41 train_loss : 44837.16545410156 Val loss:  69539.52248046876\n",
      "Model replaced\n",
      "Epoch : 42 train_loss : 44237.05554199219 Val loss:  68373.81025390625\n",
      "Model replaced\n",
      "Epoch : 43 train_loss : 43579.640197753906 Val loss:  67534.4900390625\n",
      "Model replaced\n",
      "Epoch : 44 train_loss : 42950.179138183594 Val loss:  66307.91365234375\n",
      "Model replaced\n",
      "Epoch : 45 train_loss : 42371.90905761719 Val loss:  65339.14662109375\n",
      "Model replaced\n",
      "Epoch : 46 train_loss : 41654.38798828125 Val loss:  64310.78977539062\n",
      "Model replaced\n",
      "Epoch : 47 train_loss : 41239.015588378905 Val loss:  63505.420039062505\n",
      "Model replaced\n",
      "Epoch : 48 train_loss : 40546.675463867185 Val loss:  62444.02145019531\n",
      "Model replaced\n",
      "Epoch : 49 train_loss : 40160.47453613281 Val loss:  61614.14900390625\n",
      "Model replaced\n",
      "Epoch : 50 train_loss : 39721.861083984375 Val loss:  60666.744584960936\n",
      "Model replaced\n",
      "Epoch : 51 train_loss : 38929.759106445315 Val loss:  60053.309824218755\n",
      "Model replaced\n",
      "Epoch : 52 train_loss : 38594.709948730466 Val loss:  58860.44040527344\n",
      "Model replaced\n",
      "Epoch : 53 train_loss : 37952.14915771484 Val loss:  57963.25279296875\n",
      "Model replaced\n",
      "Epoch : 54 train_loss : 37547.843041992186 Val loss:  57393.70259765625\n",
      "Model replaced\n",
      "Epoch : 55 train_loss : 37045.64327392578 Val loss:  56684.773359375\n",
      "Model replaced\n",
      "Epoch : 56 train_loss : 36456.762524414065 Val loss:  56002.05633789062\n",
      "Model replaced\n",
      "Epoch : 57 train_loss : 36054.47725830078 Val loss:  54953.78597167969\n",
      "Model replaced\n",
      "Epoch : 58 train_loss : 35692.16796875 Val loss:  54312.67722167969\n",
      "Model replaced\n",
      "Epoch : 59 train_loss : 35171.95341796875 Val loss:  53824.078295898435\n",
      "Model replaced\n",
      "Epoch : 60 train_loss : 35050.144921875 Val loss:  53031.862109375\n",
      "Model replaced\n",
      "Epoch : 61 train_loss : 34569.330529785155 Val loss:  52467.55521484375\n",
      "Model replaced\n",
      "Epoch : 62 train_loss : 34195.619616699216 Val loss:  51903.35901367188\n",
      "Model replaced\n",
      "Epoch : 63 train_loss : 34109.45972900391 Val loss:  51194.66564453125\n",
      "Model replaced\n",
      "Epoch : 64 train_loss : 33368.8724243164 Val loss:  50720.044140625\n",
      "Model replaced\n",
      "Epoch : 65 train_loss : 33220.29564208984 Val loss:  50164.82922363281\n",
      "Model replaced\n",
      "Epoch : 66 train_loss : 32902.51141357422 Val loss:  49567.8748046875\n",
      "Model replaced\n",
      "Epoch : 67 train_loss : 32655.137915039064 Val loss:  49289.93400390625\n",
      "Model replaced\n",
      "Epoch : 68 train_loss : 32501.237084960936 Val loss:  48748.119384765625\n",
      "Model replaced\n",
      "Epoch : 69 train_loss : 32252.83234863281 Val loss:  48395.733359375\n",
      "Model replaced\n",
      "Epoch : 70 train_loss : 31961.74560546875 Val loss:  48056.79831542969\n",
      "Model replaced\n",
      "Epoch : 71 train_loss : 31714.58723144531 Val loss:  47538.93450683594\n",
      "Model replaced\n",
      "Epoch : 72 train_loss : 31546.074340820312 Val loss:  47124.7555859375\n",
      "Model replaced\n",
      "Epoch : 73 train_loss : 31076.21613769531 Val loss:  46885.73770996094\n",
      "Model replaced\n",
      "Epoch : 74 train_loss : 31411.925659179688 Val loss:  46607.39994140625\n",
      "Model replaced\n",
      "Epoch : 75 train_loss : 31099.602978515624 Val loss:  46187.238237304686\n",
      "Model replaced\n",
      "Epoch : 76 train_loss : 30639.63330078125 Val loss:  45855.21081054687\n",
      "Model replaced\n",
      "Epoch : 77 train_loss : 30950.98115234375 Val loss:  45622.43187011719\n",
      "Model replaced\n",
      "Epoch : 78 train_loss : 30606.316967773437 Val loss:  45224.693637695316\n",
      "Epoch : 79 train_loss : 30444.7341796875 Val loss:  45276.501044921875\n",
      "Model replaced\n",
      "Epoch : 80 train_loss : 30191.204370117186 Val loss:  44934.024594726565\n",
      "Model replaced\n",
      "Epoch : 81 train_loss : 30058.696215820313 Val loss:  44800.741655273436\n",
      "Model replaced\n",
      "Epoch : 82 train_loss : 29957.74736328125 Val loss:  44270.89732910156\n",
      "Model replaced\n",
      "Epoch : 83 train_loss : 29845.941821289063 Val loss:  44211.63490722656\n",
      "Epoch : 84 train_loss : 29806.916259765625 Val loss:  44227.407885742185\n",
      "Model replaced\n",
      "Epoch : 85 train_loss : 29707.731079101562 Val loss:  44027.252534179686\n",
      "Model replaced\n",
      "Epoch : 86 train_loss : 29748.0619140625 Val loss:  43557.939296874996\n",
      "Model replaced\n",
      "Epoch : 87 train_loss : 29380.71923828125 Val loss:  43518.871201171874\n",
      "Epoch : 88 train_loss : 29846.986059570314 Val loss:  43526.28525878907\n",
      "Model replaced\n",
      "Epoch : 89 train_loss : 29658.469580078126 Val loss:  43428.05712890625\n",
      "Model replaced\n",
      "Epoch : 90 train_loss : 29837.745532226563 Val loss:  43173.03515625\n",
      "Epoch : 91 train_loss : 29502.158471679686 Val loss:  43303.75574707032\n",
      "Model replaced\n",
      "Epoch : 92 train_loss : 29397.54543457031 Val loss:  42763.85758300781\n",
      "Epoch : 93 train_loss : 29555.902905273437 Val loss:  42794.20610351562\n",
      "Epoch : 94 train_loss : 29303.92509765625 Val loss:  42771.10750976562\n",
      "Epoch : 95 train_loss : 29118.027465820312 Val loss:  42864.692700195315\n",
      "Model replaced\n",
      "Epoch : 96 train_loss : 28917.751318359376 Val loss:  42641.526396484376\n",
      "Model replaced\n",
      "Epoch : 97 train_loss : 29388.001245117186 Val loss:  42555.482666015625\n",
      "Epoch : 98 train_loss : 29232.749462890624 Val loss:  42684.944091796875\n",
      "Model replaced\n",
      "Epoch : 99 train_loss : 28873.1759765625 Val loss:  42417.613286132815\n",
      "Model replaced\n",
      "Epoch : 100 train_loss : 29147.144775390625 Val loss:  42313.74847167969\n",
      "Epoch : 101 train_loss : 28828.674853515626 Val loss:  42388.239023437505\n",
      "Model replaced\n",
      "Epoch : 102 train_loss : 28866.337353515624 Val loss:  42215.39660644531\n",
      "Epoch : 103 train_loss : 29236.65537109375 Val loss:  42220.26277832031\n",
      "Epoch : 104 train_loss : 29159.23671875 Val loss:  42367.146455078124\n",
      "Model replaced\n",
      "Epoch : 105 train_loss : 29042.0841796875 Val loss:  42030.69962402344\n",
      "Epoch : 106 train_loss : 29376.983642578125 Val loss:  42230.884560546874\n",
      "Epoch : 107 train_loss : 28849.21787109375 Val loss:  42064.72694824218\n",
      "Epoch : 108 train_loss : 29159.1701171875 Val loss:  42168.8326171875\n",
      "Model replaced\n",
      "Epoch : 109 train_loss : 29132.360888671876 Val loss:  42028.86828125\n",
      "Model replaced\n",
      "Epoch : 110 train_loss : 28964.228173828124 Val loss:  41903.150122070314\n",
      "Model replaced\n",
      "Epoch : 111 train_loss : 28725.966381835937 Val loss:  41850.089140625\n",
      "Epoch : 112 train_loss : 28783.08193359375 Val loss:  41907.57244140625\n",
      "Epoch : 113 train_loss : 28893.4205078125 Val loss:  42122.51122070312\n",
      "Epoch : 114 train_loss : 29038.793408203124 Val loss:  42049.30076660156\n",
      "Model replaced\n",
      "Epoch : 115 train_loss : 28720.406591796876 Val loss:  41776.53193847656\n",
      "Model replaced\n",
      "Epoch : 116 train_loss : 28629.894140625 Val loss:  41523.21356445312\n",
      "Epoch : 117 train_loss : 28944.24501953125 Val loss:  41849.98365722656\n",
      "Epoch : 118 train_loss : 29119.4302734375 Val loss:  41934.78962402344\n",
      "Epoch : 119 train_loss : 28724.609228515626 Val loss:  41959.845981445316\n",
      "Epoch : 120 train_loss : 29051.76953125 Val loss:  41816.58032714844\n",
      "Model replaced\n",
      "Epoch : 121 train_loss : 28818.694921875 Val loss:  41187.03903808594\n",
      "Epoch : 122 train_loss : 28851.815966796876 Val loss:  41610.60206542969\n",
      "Epoch : 123 train_loss : 28902.917333984376 Val loss:  41733.09615234375\n",
      "Epoch : 124 train_loss : 28736.28095703125 Val loss:  41259.223911132816\n",
      "Epoch : 125 train_loss : 28684.724951171876 Val loss:  41688.50384765625\n",
      "Epoch : 126 train_loss : 28761.656982421875 Val loss:  41791.3341796875\n",
      "Epoch : 127 train_loss : 29121.705712890624 Val loss:  41714.18616210938\n",
      "Epoch : 128 train_loss : 29127.904541015625 Val loss:  41832.84916015625\n",
      "Epoch : 129 train_loss : 28917.261279296876 Val loss:  41256.77885742187\n",
      "Epoch : 130 train_loss : 28909.04501953125 Val loss:  41617.90340820312\n",
      "Epoch : 131 train_loss : 28810.343798828126 Val loss:  41718.63201171875\n",
      "Epoch : 132 train_loss : 29243.156591796876 Val loss:  41744.94581054688\n",
      "Epoch : 133 train_loss : 28932.246826171875 Val loss:  41454.35466796875\n",
      "Epoch : 134 train_loss : 28852.82890625 Val loss:  41505.39072265625\n",
      "Epoch : 135 train_loss : 29037.71357421875 Val loss:  41533.1171484375\n",
      "Epoch : 136 train_loss : 29153.922021484374 Val loss:  41464.63062011719\n",
      "Epoch : 137 train_loss : 28439.790673828124 Val loss:  41647.710859375\n",
      "Epoch : 138 train_loss : 29014.115234375 Val loss:  41648.93234375\n",
      "Epoch : 139 train_loss : 28916.6802734375 Val loss:  41582.79311035156\n",
      "Epoch : 140 train_loss : 28801.16435546875 Val loss:  41410.11758789063\n",
      "Epoch : 141 train_loss : 29070.891015625 Val loss:  41564.907294921875\n",
      "Epoch : 142 train_loss : 28920.857275390626 Val loss:  41588.30037109375\n",
      "Epoch : 143 train_loss : 28664.745654296876 Val loss:  41419.55916992187\n",
      "Epoch : 144 train_loss : 28804.539892578126 Val loss:  41224.55602539062\n",
      "Epoch : 145 train_loss : 28617.6515625 Val loss:  41600.882231445314\n",
      "Epoch : 146 train_loss : 28882.120361328125 Val loss:  41683.19556152344\n",
      "Epoch : 147 train_loss : 28717.2951171875 Val loss:  41449.85504394531\n",
      "Epoch : 148 train_loss : 28819.696142578126 Val loss:  41385.80913085937\n",
      "Epoch : 149 train_loss : 28512.943505859374 Val loss:  41581.03615722656\n",
      "Epoch : 150 train_loss : 28613.51044921875 Val loss:  41268.86078125\n",
      "Epoch : 151 train_loss : 28862.618896484375 Val loss:  41570.7821484375\n",
      "Epoch : 152 train_loss : 28856.186474609374 Val loss:  41414.6818359375\n",
      "Epoch : 153 train_loss : 28826.77783203125 Val loss:  41419.449877929685\n",
      "Epoch : 154 train_loss : 28904.67509765625 Val loss:  41191.96840332031\n",
      "Epoch : 155 train_loss : 28770.496484375 Val loss:  41330.85905273438\n",
      "Epoch : 156 train_loss : 28638.15478515625 Val loss:  41507.47345703125\n",
      "Epoch : 157 train_loss : 28529.79453125 Val loss:  41605.46438964844\n",
      "Epoch : 158 train_loss : 28738.90751953125 Val loss:  41615.34458984375\n",
      "Epoch : 159 train_loss : 28558.58720703125 Val loss:  41499.56914550781\n",
      "Epoch : 160 train_loss : 28808.25546875 Val loss:  41448.67381347656\n",
      "Epoch : 161 train_loss : 28428.7716796875 Val loss:  41511.088759765626\n",
      "Epoch : 162 train_loss : 28529.522900390624 Val loss:  41262.897841796876\n",
      "Epoch : 163 train_loss : 28760.49130859375 Val loss:  41547.351557617185\n",
      "Epoch : 164 train_loss : 29026.598193359376 Val loss:  41201.795317382814\n",
      "Epoch : 165 train_loss : 28609.97265625 Val loss:  41202.01751953125\n",
      "Epoch : 166 train_loss : 28578.29296875 Val loss:  41551.179594726564\n",
      "Epoch : 167 train_loss : 28727.447802734376 Val loss:  41413.92624511719\n",
      "Epoch : 168 train_loss : 28719.04267578125 Val loss:  41495.203281250004\n",
      "Epoch : 169 train_loss : 28652.35791015625 Val loss:  41302.67924804687\n",
      "Epoch : 170 train_loss : 29035.296484375 Val loss:  41399.25501464844\n",
      "Model replaced\n",
      "Epoch : 171 train_loss : 28485.753857421874 Val loss:  41089.340600585936\n",
      "Epoch : 172 train_loss : 28872.36513671875 Val loss:  41418.790747070314\n",
      "Epoch : 173 train_loss : 28585.028466796874 Val loss:  41324.60868652344\n",
      "Epoch : 174 train_loss : 29000.902734375 Val loss:  41242.12338378906\n",
      "Epoch : 175 train_loss : 28766.084716796875 Val loss:  41685.20049316406\n",
      "Epoch : 176 train_loss : 28445.088916015626 Val loss:  41592.353281250005\n",
      "Epoch : 177 train_loss : 28783.7181640625 Val loss:  41455.044965820314\n",
      "Epoch : 178 train_loss : 28685.812255859375 Val loss:  41257.41654296875\n",
      "Epoch : 179 train_loss : 28544.713330078124 Val loss:  41361.88439453125\n",
      "Epoch : 180 train_loss : 28524.20478515625 Val loss:  41352.52631835938\n",
      "Epoch : 181 train_loss : 28603.40234375 Val loss:  41232.48198730469\n",
      "Epoch : 182 train_loss : 28536.435400390626 Val loss:  41311.35654785157\n",
      "Epoch : 183 train_loss : 28980.68818359375 Val loss:  41239.5564453125\n",
      "Epoch : 184 train_loss : 28479.594775390626 Val loss:  41444.870097656254\n",
      "Epoch : 185 train_loss : 28610.044091796874 Val loss:  41455.53159667969\n",
      "Epoch : 186 train_loss : 28656.267578125 Val loss:  41351.399731445315\n",
      "Epoch : 187 train_loss : 28391.140380859375 Val loss:  41233.37045410156\n",
      "Epoch : 188 train_loss : 28703.287646484376 Val loss:  41581.014916992186\n",
      "Epoch : 189 train_loss : 28671.903271484374 Val loss:  41433.70119628906\n",
      "Epoch : 190 train_loss : 28423.812451171874 Val loss:  41357.37354492188\n",
      "Epoch : 191 train_loss : 29170.2755859375 Val loss:  41371.484067382815\n",
      "Epoch : 192 train_loss : 28812.36435546875 Val loss:  41302.85260253906\n",
      "Epoch : 193 train_loss : 28677.74453125 Val loss:  41308.824765625\n",
      "Epoch : 194 train_loss : 28722.7369140625 Val loss:  41410.26783691406\n",
      "Epoch : 195 train_loss : 28498.887841796874 Val loss:  41548.92412597656\n",
      "Epoch : 196 train_loss : 28876.634765625 Val loss:  41454.02289550781\n",
      "Model replaced\n",
      "Epoch : 197 train_loss : 28293.6400390625 Val loss:  40923.10991210937\n",
      "Epoch : 198 train_loss : 28413.738427734374 Val loss:  41449.05727539062\n",
      "Epoch : 199 train_loss : 27972.9390625 Val loss:  41400.51808105469\n",
      "Epoch : 200 train_loss : 28734.16171875 Val loss:  41214.59258300781\n",
      "Epoch : 201 train_loss : 28325.780517578125 Val loss:  41352.60743652344\n",
      "Epoch : 202 train_loss : 28646.931982421876 Val loss:  41419.49474609375\n",
      "Epoch : 203 train_loss : 28469.261376953124 Val loss:  41240.777348632815\n",
      "Epoch : 204 train_loss : 28603.90615234375 Val loss:  41309.26545898437\n",
      "Epoch : 205 train_loss : 28705.592333984376 Val loss:  41509.828828125\n",
      "Epoch : 206 train_loss : 28875.8943359375 Val loss:  41311.846484375\n",
      "Epoch : 207 train_loss : 28333.077880859375 Val loss:  41092.53203125\n",
      "Epoch : 208 train_loss : 28276.58896484375 Val loss:  41322.32629882813\n",
      "Epoch : 209 train_loss : 28795.59736328125 Val loss:  41419.728071289064\n",
      "Epoch : 210 train_loss : 28892.548291015624 Val loss:  41213.0872265625\n",
      "Epoch : 211 train_loss : 28706.54619140625 Val loss:  41071.561254882814\n",
      "Epoch : 212 train_loss : 28203.956982421874 Val loss:  41199.12962402344\n",
      "Epoch : 213 train_loss : 28252.534716796876 Val loss:  41454.18465332031\n",
      "Epoch : 214 train_loss : 28486.43544921875 Val loss:  41178.20973144531\n",
      "Epoch : 215 train_loss : 28361.00869140625 Val loss:  41183.88457519531\n",
      "Epoch : 216 train_loss : 28468.257861328126 Val loss:  41080.154853515625\n",
      "Epoch : 217 train_loss : 28434.28447265625 Val loss:  41284.32685058594\n",
      "Epoch : 218 train_loss : 28485.7513671875 Val loss:  41070.09680664063\n",
      "Epoch : 219 train_loss : 28593.973193359376 Val loss:  41061.85926269532\n",
      "Epoch : 220 train_loss : 28698.80927734375 Val loss:  41192.33845703125\n",
      "Epoch : 221 train_loss : 28388.716162109376 Val loss:  41214.26075683594\n",
      "Model replaced\n",
      "Epoch : 222 train_loss : 28409.87578125 Val loss:  40805.84767089844\n",
      "Epoch : 223 train_loss : 28439.430078125 Val loss:  41299.0596875\n",
      "Epoch : 224 train_loss : 28417.78251953125 Val loss:  41043.57365234375\n",
      "Epoch : 225 train_loss : 28351.997509765624 Val loss:  41243.60621582031\n",
      "Epoch : 226 train_loss : 28239.269091796876 Val loss:  41035.09358886719\n",
      "Epoch : 227 train_loss : 28121.559326171875 Val loss:  40997.59848632813\n",
      "Epoch : 228 train_loss : 28154.467041015625 Val loss:  41190.47666015625\n",
      "Epoch : 229 train_loss : 28275.35849609375 Val loss:  41075.968671875\n",
      "Epoch : 230 train_loss : 28127.091845703126 Val loss:  41244.87458984375\n",
      "Epoch : 231 train_loss : 28401.523046875 Val loss:  41008.97013671875\n",
      "Epoch : 232 train_loss : 28574.30810546875 Val loss:  41150.84487792969\n",
      "Epoch : 233 train_loss : 28207.891650390626 Val loss:  41191.64270507813\n",
      "Epoch : 234 train_loss : 28292.316015625 Val loss:  41003.20799316406\n",
      "Epoch : 235 train_loss : 28187.0697265625 Val loss:  41102.47768066406\n",
      "Epoch : 236 train_loss : 28498.254638671875 Val loss:  41332.741796875\n",
      "Epoch : 237 train_loss : 28489.819091796875 Val loss:  41106.666640625\n",
      "Epoch : 238 train_loss : 28145.736376953126 Val loss:  41053.562167968754\n",
      "Epoch : 239 train_loss : 28410.503515625 Val loss:  41312.84003417969\n",
      "Model replaced\n",
      "Epoch : 240 train_loss : 28132.487548828125 Val loss:  40758.76630371094\n",
      "Epoch : 241 train_loss : 28409.610546875 Val loss:  40973.68658203125\n",
      "Epoch : 242 train_loss : 28252.3576171875 Val loss:  40968.335234375\n",
      "Epoch : 243 train_loss : 28497.845947265625 Val loss:  41072.02032226563\n",
      "Epoch : 244 train_loss : 27892.2091796875 Val loss:  41257.32397949219\n",
      "Epoch : 245 train_loss : 28289.082861328126 Val loss:  41224.017758789065\n",
      "Epoch : 246 train_loss : 28128.51328125 Val loss:  41004.667246093755\n",
      "Epoch : 247 train_loss : 28277.05771484375 Val loss:  41279.02196289062\n",
      "Epoch : 248 train_loss : 28002.0310546875 Val loss:  40918.828193359375\n",
      "Epoch : 249 train_loss : 28351.752001953126 Val loss:  41119.382041015626\n",
      "Epoch : 250 train_loss : 28315.256884765626 Val loss:  41224.2476953125\n",
      "Epoch : 251 train_loss : 28489.455712890624 Val loss:  41215.14023925782\n",
      "Epoch : 252 train_loss : 28375.87255859375 Val loss:  41016.257143554685\n",
      "Epoch : 253 train_loss : 28027.869580078124 Val loss:  41179.93933105469\n",
      "Epoch : 254 train_loss : 28376.283984375 Val loss:  40866.05928222656\n",
      "Epoch : 255 train_loss : 28216.429736328126 Val loss:  41119.98515136719\n",
      "Epoch : 256 train_loss : 28031.41474609375 Val loss:  40854.52376464844\n",
      "Epoch : 257 train_loss : 28277.088427734376 Val loss:  41162.506079101564\n",
      "Epoch : 258 train_loss : 28107.627734375 Val loss:  40846.15728027344\n",
      "Epoch : 259 train_loss : 28098.85390625 Val loss:  40901.4296484375\n",
      "Epoch : 260 train_loss : 28149.70654296875 Val loss:  41228.550712890625\n",
      "Epoch : 261 train_loss : 28087.81474609375 Val loss:  41216.5228515625\n",
      "Epoch : 262 train_loss : 28065.34091796875 Val loss:  41029.211445312496\n",
      "Epoch : 263 train_loss : 28206.1654296875 Val loss:  41095.71273925781\n",
      "Epoch : 264 train_loss : 28459.469482421875 Val loss:  41172.90854980469\n",
      "Epoch : 265 train_loss : 28012.637890625 Val loss:  41013.87544921875\n",
      "Epoch : 266 train_loss : 28066.406005859375 Val loss:  41118.972812500004\n",
      "Epoch : 267 train_loss : 28516.263671875 Val loss:  40880.07942871094\n",
      "Epoch : 268 train_loss : 28337.31806640625 Val loss:  41137.94485839844\n",
      "Epoch : 269 train_loss : 28332.207080078126 Val loss:  41166.91611816407\n",
      "Epoch : 270 train_loss : 28128.739453125 Val loss:  40801.86506835937\n",
      "Epoch : 271 train_loss : 28203.00078125 Val loss:  41203.76017089844\n",
      "Epoch : 272 train_loss : 27981.283984375 Val loss:  41018.76937011719\n",
      "Epoch : 273 train_loss : 28463.7068359375 Val loss:  41100.56506347656\n",
      "Epoch : 274 train_loss : 28242.227197265624 Val loss:  41013.686484375\n",
      "Epoch : 275 train_loss : 28284.869189453126 Val loss:  40971.3243359375\n",
      "Epoch : 276 train_loss : 27861.434130859376 Val loss:  40924.27399902344\n",
      "Epoch : 277 train_loss : 28396.087060546874 Val loss:  40947.25965332032\n",
      "Epoch : 278 train_loss : 28312.254833984374 Val loss:  40940.41650390625\n",
      "Epoch : 279 train_loss : 27942.910986328126 Val loss:  41180.77910644531\n",
      "Epoch : 280 train_loss : 28305.741748046876 Val loss:  40922.48547851563\n",
      "Epoch : 281 train_loss : 27663.9767578125 Val loss:  41139.66547851563\n",
      "Epoch : 282 train_loss : 28044.68515625 Val loss:  40872.27771972657\n",
      "Epoch : 283 train_loss : 27952.881103515625 Val loss:  40804.00037109375\n",
      "Epoch : 284 train_loss : 27865.045654296875 Val loss:  41202.80476074219\n",
      "Epoch : 285 train_loss : 28280.88193359375 Val loss:  40881.81335449219\n",
      "Epoch : 286 train_loss : 28022.908447265625 Val loss:  40966.39390625\n",
      "Epoch : 287 train_loss : 28048.33564453125 Val loss:  40959.155966796876\n",
      "Epoch : 288 train_loss : 28315.4474609375 Val loss:  41116.721147460936\n",
      "Epoch : 289 train_loss : 28154.7099609375 Val loss:  41073.2936328125\n",
      "Epoch : 290 train_loss : 28025.265185546876 Val loss:  40785.141870117186\n",
      "Model replaced\n",
      "Epoch : 291 train_loss : 28183.91259765625 Val loss:  40719.663129882814\n",
      "Epoch : 292 train_loss : 28061.84609375 Val loss:  41100.909458007816\n",
      "Epoch : 293 train_loss : 28113.87314453125 Val loss:  40826.285673828126\n",
      "Epoch : 294 train_loss : 28391.624365234376 Val loss:  40894.65317382813\n",
      "Epoch : 295 train_loss : 27916.597119140624 Val loss:  40979.410703125\n",
      "Epoch : 296 train_loss : 27937.960107421874 Val loss:  41007.35688476563\n",
      "Epoch : 297 train_loss : 28019.5953125 Val loss:  40919.00336914063\n",
      "Epoch : 298 train_loss : 28117.527734375 Val loss:  40918.69248046875\n",
      "Epoch : 299 train_loss : 28027.49599609375 Val loss:  40730.097827148435\n",
      "Epoch : 300 train_loss : 27853.702734375 Val loss:  40956.03307617187\n",
      "Epoch : 301 train_loss : 28044.233837890624 Val loss:  40739.3762890625\n",
      "Epoch : 302 train_loss : 27881.160791015624 Val loss:  40823.25733398438\n",
      "Model replaced\n",
      "Epoch : 303 train_loss : 28183.134423828124 Val loss:  40705.33439941406\n",
      "Epoch : 304 train_loss : 27895.40673828125 Val loss:  40975.64428222656\n",
      "Epoch : 305 train_loss : 28076.658349609374 Val loss:  40708.613974609376\n",
      "Epoch : 306 train_loss : 27962.370263671874 Val loss:  40931.54329589844\n",
      "Epoch : 307 train_loss : 28114.699951171875 Val loss:  40723.556469726565\n",
      "Epoch : 308 train_loss : 27788.2912109375 Val loss:  41016.67659667969\n",
      "Epoch : 309 train_loss : 28219.214599609375 Val loss:  40822.676059570316\n",
      "Epoch : 310 train_loss : 27866.57470703125 Val loss:  40732.62389648437\n",
      "Epoch : 311 train_loss : 28169.1248046875 Val loss:  41008.06502441406\n",
      "Epoch : 312 train_loss : 27910.20537109375 Val loss:  40889.43498046875\n",
      "Epoch : 313 train_loss : 27845.810205078124 Val loss:  40933.45282714844\n",
      "Epoch : 314 train_loss : 28067.045068359374 Val loss:  40724.14936523438\n",
      "Epoch : 315 train_loss : 28235.410888671875 Val loss:  40969.350839843755\n",
      "Epoch : 316 train_loss : 28112.02744140625 Val loss:  40835.251245117186\n",
      "Model replaced\n",
      "Epoch : 317 train_loss : 28120.0390625 Val loss:  40695.50614746094\n",
      "Epoch : 318 train_loss : 27907.08837890625 Val loss:  40699.43290527344\n",
      "Epoch : 319 train_loss : 27901.089599609375 Val loss:  40845.59875976563\n",
      "Epoch : 320 train_loss : 27889.701025390626 Val loss:  40928.90475097656\n",
      "Epoch : 321 train_loss : 27850.40458984375 Val loss:  41028.806484374996\n",
      "Epoch : 322 train_loss : 27839.617236328126 Val loss:  40857.47200195312\n",
      "Epoch : 323 train_loss : 28119.11884765625 Val loss:  40845.14043457031\n",
      "Epoch : 324 train_loss : 28375.64638671875 Val loss:  41022.02384277344\n",
      "Epoch : 325 train_loss : 28005.130078125 Val loss:  40817.684399414065\n",
      "Epoch : 326 train_loss : 27861.02451171875 Val loss:  40910.06586914063\n",
      "Epoch : 327 train_loss : 28004.518701171874 Val loss:  40822.68201171875\n",
      "Epoch : 328 train_loss : 27735.011572265626 Val loss:  40825.410576171875\n",
      "Epoch : 329 train_loss : 28011.42314453125 Val loss:  40920.822724609374\n",
      "Model replaced\n",
      "Epoch : 330 train_loss : 27735.655029296875 Val loss:  40626.375766601566\n",
      "Epoch : 331 train_loss : 27766.497900390626 Val loss:  40698.019799804686\n",
      "Epoch : 332 train_loss : 27553.058056640624 Val loss:  40733.475756835935\n",
      "Epoch : 333 train_loss : 27450.6953125 Val loss:  40837.872290039064\n",
      "Epoch : 334 train_loss : 27695.190380859374 Val loss:  40850.91320800781\n",
      "Epoch : 335 train_loss : 27640.891259765624 Val loss:  40971.89527832031\n",
      "Epoch : 336 train_loss : 28168.619775390624 Val loss:  41031.59866699219\n",
      "Model replaced\n",
      "Epoch : 337 train_loss : 27681.173828125 Val loss:  40569.562031249996\n",
      "Model replaced\n",
      "Epoch : 338 train_loss : 28018.850146484376 Val loss:  40503.44376953125\n",
      "Epoch : 339 train_loss : 27797.71015625 Val loss:  40720.02731933594\n",
      "Model replaced\n",
      "Epoch : 340 train_loss : 27585.066943359376 Val loss:  40421.197373046874\n",
      "Epoch : 341 train_loss : 27743.594970703125 Val loss:  40711.63414550781\n",
      "Epoch : 342 train_loss : 27530.100146484376 Val loss:  40753.092290039065\n",
      "Epoch : 343 train_loss : 27849.623974609374 Val loss:  40716.81158691406\n",
      "Epoch : 344 train_loss : 27878.958251953125 Val loss:  40776.94847167969\n",
      "Epoch : 345 train_loss : 27966.206298828125 Val loss:  40574.241171875\n",
      "Epoch : 346 train_loss : 28308.210546875 Val loss:  40692.28126464844\n",
      "Epoch : 347 train_loss : 27971.7455078125 Val loss:  40657.9062890625\n",
      "Epoch : 348 train_loss : 27905.7548828125 Val loss:  40955.848413085936\n",
      "Epoch : 349 train_loss : 27811.764599609374 Val loss:  40894.171118164064\n",
      "Epoch : 350 train_loss : 27857.718212890624 Val loss:  40854.379150390625\n",
      "Epoch : 351 train_loss : 27661.803515625 Val loss:  40761.056396484375\n",
      "Epoch : 352 train_loss : 27180.4611328125 Val loss:  40630.55829589844\n",
      "Epoch : 353 train_loss : 27711.12412109375 Val loss:  40859.55463378906\n",
      "Epoch : 354 train_loss : 28208.868896484375 Val loss:  40563.68731445313\n",
      "Epoch : 355 train_loss : 27474.349951171876 Val loss:  40689.375307617185\n",
      "Epoch : 356 train_loss : 27694.5029296875 Val loss:  40712.47393066406\n",
      "Epoch : 357 train_loss : 27842.33515625 Val loss:  40530.158925781245\n",
      "Model replaced\n",
      "Epoch : 358 train_loss : 28003.152197265626 Val loss:  40343.956210937504\n",
      "Epoch : 359 train_loss : 27751.9876953125 Val loss:  40400.82775390625\n",
      "Epoch : 360 train_loss : 27557.181494140626 Val loss:  40615.34875\n",
      "Epoch : 361 train_loss : 27721.410302734374 Val loss:  40467.521752929686\n",
      "Epoch : 362 train_loss : 27789.48857421875 Val loss:  40960.294453124996\n",
      "Epoch : 363 train_loss : 27500.119677734376 Val loss:  40618.36835449219\n",
      "Epoch : 364 train_loss : 27534.9412109375 Val loss:  40594.63437988282\n",
      "Epoch : 365 train_loss : 27965.194580078125 Val loss:  40514.407709960935\n",
      "Epoch : 366 train_loss : 27575.42431640625 Val loss:  40798.78355957031\n",
      "Epoch : 367 train_loss : 27436.50263671875 Val loss:  40748.373842773435\n",
      "Epoch : 368 train_loss : 27681.468408203124 Val loss:  40399.5594921875\n",
      "Epoch : 369 train_loss : 27422.85703125 Val loss:  40802.77801757812\n",
      "Epoch : 370 train_loss : 27858.05849609375 Val loss:  40495.100820312495\n",
      "Epoch : 371 train_loss : 27729.070556640625 Val loss:  40642.409160156254\n",
      "Epoch : 372 train_loss : 27718.159716796876 Val loss:  40925.208242187495\n",
      "Epoch : 373 train_loss : 27686.9453125 Val loss:  40662.01380859375\n",
      "Epoch : 374 train_loss : 27443.749755859375 Val loss:  40543.805385742184\n",
      "Epoch : 375 train_loss : 27277.3501953125 Val loss:  40585.14907226562\n",
      "Epoch : 376 train_loss : 27887.357666015625 Val loss:  40772.5829296875\n",
      "Epoch : 377 train_loss : 27660.848046875 Val loss:  40535.936367187496\n",
      "Epoch : 378 train_loss : 27606.532470703125 Val loss:  40744.57701660156\n",
      "Epoch : 379 train_loss : 27603.19072265625 Val loss:  40856.4153125\n",
      "Epoch : 380 train_loss : 27723.989208984374 Val loss:  40516.959541015625\n",
      "Epoch : 381 train_loss : 27694.48173828125 Val loss:  40696.003237304685\n",
      "Epoch : 382 train_loss : 27734.0255859375 Val loss:  40465.17225097657\n",
      "Epoch : 383 train_loss : 27538.96396484375 Val loss:  40471.27293457031\n",
      "Epoch : 384 train_loss : 27639.014794921874 Val loss:  40419.26646972656\n",
      "Epoch : 385 train_loss : 27760.001904296874 Val loss:  40612.32102539063\n",
      "Epoch : 386 train_loss : 27513.741455078125 Val loss:  40633.038745117185\n",
      "Epoch : 387 train_loss : 27441.53896484375 Val loss:  40566.61382324219\n",
      "Epoch : 388 train_loss : 27710.508642578126 Val loss:  40699.695493164065\n",
      "Epoch : 389 train_loss : 27659.349658203126 Val loss:  40360.57661132813\n",
      "Epoch : 390 train_loss : 27587.580615234376 Val loss:  40767.83405761719\n",
      "Epoch : 391 train_loss : 27535.716796875 Val loss:  40398.782685546874\n",
      "Epoch : 392 train_loss : 27812.8974609375 Val loss:  40693.380903320314\n",
      "Epoch : 393 train_loss : 27323.222021484376 Val loss:  40424.61383300781\n",
      "Epoch : 394 train_loss : 27584.944287109374 Val loss:  40596.77213867188\n",
      "Epoch : 395 train_loss : 27653.999755859375 Val loss:  40791.35514160156\n",
      "Epoch : 396 train_loss : 27851.96416015625 Val loss:  40565.439174804684\n",
      "Model replaced\n",
      "Epoch : 397 train_loss : 27374.756591796875 Val loss:  40167.74053710938\n",
      "Epoch : 398 train_loss : 27466.40419921875 Val loss:  40651.41651855469\n",
      "Epoch : 399 train_loss : 27604.788623046876 Val loss:  40385.88193359375\n",
      "Epoch : 400 train_loss : 27607.477294921875 Val loss:  40365.93814941406\n",
      "Epoch : 401 train_loss : 27706.2525390625 Val loss:  40380.223347167965\n",
      "Epoch : 402 train_loss : 27729.746435546876 Val loss:  40677.23141113281\n",
      "Epoch : 403 train_loss : 27644.09208984375 Val loss:  40350.88666503906\n",
      "Epoch : 404 train_loss : 27338.589208984376 Val loss:  40349.84403808594\n",
      "Epoch : 405 train_loss : 27420.127490234376 Val loss:  40689.810263671876\n",
      "Epoch : 406 train_loss : 27239.37939453125 Val loss:  40407.306015625\n",
      "Epoch : 407 train_loss : 27371.85673828125 Val loss:  40364.301938476565\n",
      "Epoch : 408 train_loss : 27555.524755859376 Val loss:  40561.46951171875\n",
      "Epoch : 409 train_loss : 27454.70078125 Val loss:  40685.255952148436\n",
      "Epoch : 410 train_loss : 27319.08828125 Val loss:  40443.718168945314\n",
      "Epoch : 411 train_loss : 27383.715234375 Val loss:  40675.864726562504\n",
      "Epoch : 412 train_loss : 27750.905615234376 Val loss:  40588.06528808594\n",
      "Epoch : 413 train_loss : 27256.4060546875 Val loss:  40495.66583984375\n",
      "Epoch : 414 train_loss : 27590.452978515626 Val loss:  40201.30094726563\n",
      "Epoch : 415 train_loss : 27430.318994140624 Val loss:  40286.24496582031\n",
      "Epoch : 416 train_loss : 27368.659326171874 Val loss:  40527.035751953124\n",
      "Epoch : 417 train_loss : 27539.106005859376 Val loss:  40317.36898925781\n",
      "Epoch : 418 train_loss : 27469.156494140625 Val loss:  40727.052089843746\n",
      "Epoch : 419 train_loss : 27460.793359375 Val loss:  40721.8419921875\n",
      "Epoch : 420 train_loss : 27308.65087890625 Val loss:  40188.622666015624\n",
      "Epoch : 421 train_loss : 27273.941796875 Val loss:  40397.79526855469\n",
      "Epoch : 422 train_loss : 27100.25810546875 Val loss:  40444.776572265626\n",
      "Epoch : 423 train_loss : 27083.42890625 Val loss:  40549.26779296875\n",
      "Epoch : 424 train_loss : 27334.87763671875 Val loss:  40605.26391113281\n",
      "Epoch : 425 train_loss : 27149.025634765625 Val loss:  40475.83900878906\n",
      "Epoch : 426 train_loss : 27544.202880859375 Val loss:  40359.975278320315\n",
      "Epoch : 427 train_loss : 27354.573095703126 Val loss:  40299.71260253906\n",
      "Epoch : 428 train_loss : 27232.108154296875 Val loss:  40412.149697265624\n",
      "Epoch : 429 train_loss : 27198.56875 Val loss:  40460.17111328125\n",
      "Epoch : 430 train_loss : 27502.180029296876 Val loss:  40508.34865722656\n",
      "Epoch : 431 train_loss : 26727.143359375 Val loss:  40244.63137207031\n",
      "Epoch : 432 train_loss : 27506.22578125 Val loss:  40329.91403808594\n",
      "Epoch : 433 train_loss : 27340.241552734376 Val loss:  40433.52580078125\n",
      "Epoch : 434 train_loss : 26833.255322265624 Val loss:  40280.87013183594\n",
      "Epoch : 435 train_loss : 27519.44931640625 Val loss:  40285.03926269531\n",
      "Epoch : 436 train_loss : 27423.481982421876 Val loss:  40413.76059082031\n",
      "Epoch : 437 train_loss : 27247.3568359375 Val loss:  40437.39326171875\n",
      "Epoch : 438 train_loss : 27340.54619140625 Val loss:  40305.27835449219\n",
      "Epoch : 439 train_loss : 27369.084619140624 Val loss:  40224.82922363281\n",
      "Epoch : 440 train_loss : 27198.645263671875 Val loss:  40484.91142578125\n",
      "Epoch : 441 train_loss : 27085.518310546875 Val loss:  40555.47801757812\n",
      "Epoch : 442 train_loss : 27141.030029296875 Val loss:  40313.45328613281\n",
      "Model replaced\n",
      "Epoch : 443 train_loss : 27624.135205078124 Val loss:  40104.335546875\n",
      "Epoch : 444 train_loss : 27155.489697265624 Val loss:  40253.829907226565\n",
      "Epoch : 445 train_loss : 27405.224853515625 Val loss:  40525.01440917969\n",
      "Epoch : 446 train_loss : 27196.796142578125 Val loss:  40459.542226562495\n",
      "Epoch : 447 train_loss : 27128.15146484375 Val loss:  40397.50315917969\n",
      "Epoch : 448 train_loss : 26980.514990234376 Val loss:  40447.591796875\n",
      "Epoch : 449 train_loss : 27011.9748046875 Val loss:  40278.74994628906\n",
      "Epoch : 450 train_loss : 27186.5181640625 Val loss:  40505.53787109375\n",
      "Epoch : 451 train_loss : 27131.548095703125 Val loss:  40177.30308105469\n",
      "Epoch : 452 train_loss : 27308.1255859375 Val loss:  40197.14343261719\n",
      "Epoch : 453 train_loss : 27493.528857421876 Val loss:  40122.16784667969\n",
      "Epoch : 454 train_loss : 27433.090625 Val loss:  40379.6856640625\n",
      "Epoch : 455 train_loss : 27078.633349609376 Val loss:  40380.17747070313\n",
      "Epoch : 456 train_loss : 27280.40751953125 Val loss:  40125.93615234375\n",
      "Epoch : 457 train_loss : 26820.346435546875 Val loss:  40385.644799804686\n",
      "Epoch : 458 train_loss : 27131.28857421875 Val loss:  40352.992983398435\n",
      "Epoch : 459 train_loss : 27371.57705078125 Val loss:  40233.97646484375\n",
      "Epoch : 460 train_loss : 27366.78681640625 Val loss:  40154.8599609375\n",
      "Model replaced\n",
      "Epoch : 461 train_loss : 27211.60693359375 Val loss:  40062.009658203126\n",
      "Epoch : 462 train_loss : 27148.341259765624 Val loss:  40293.14009765625\n",
      "Epoch : 463 train_loss : 27279.17724609375 Val loss:  40278.733491210936\n",
      "Epoch : 464 train_loss : 27107.309326171875 Val loss:  40107.16079589844\n",
      "Epoch : 465 train_loss : 26889.721142578124 Val loss:  40459.12224609375\n",
      "Epoch : 466 train_loss : 27336.50966796875 Val loss:  40152.07645996094\n",
      "Epoch : 467 train_loss : 27249.68291015625 Val loss:  40235.218481445314\n",
      "Model replaced\n",
      "Epoch : 468 train_loss : 27291.294384765624 Val loss:  40011.79381347656\n",
      "Epoch : 469 train_loss : 27002.4689453125 Val loss:  40129.61921386719\n",
      "Epoch : 470 train_loss : 27282.559716796874 Val loss:  40359.28472167969\n",
      "Epoch : 471 train_loss : 27469.2759765625 Val loss:  40262.230151367185\n",
      "Epoch : 472 train_loss : 27158.53798828125 Val loss:  40079.02595703125\n",
      "Epoch : 473 train_loss : 27108.443310546874 Val loss:  40096.04185546875\n",
      "Epoch : 474 train_loss : 27097.724072265624 Val loss:  40355.36217773437\n",
      "Epoch : 475 train_loss : 27352.854736328125 Val loss:  40284.91419921875\n",
      "Epoch : 476 train_loss : 27239.353125 Val loss:  40048.71297363281\n",
      "Epoch : 477 train_loss : 26833.681591796874 Val loss:  40315.99587890625\n",
      "Epoch : 478 train_loss : 27275.13193359375 Val loss:  40091.58235351562\n",
      "Epoch : 479 train_loss : 27341.501513671876 Val loss:  40162.72859863281\n",
      "Epoch : 480 train_loss : 26762.934619140626 Val loss:  40149.7401953125\n",
      "Epoch : 481 train_loss : 26864.84462890625 Val loss:  40142.6958984375\n",
      "Model replaced\n",
      "Epoch : 482 train_loss : 26815.603955078124 Val loss:  40008.244135742185\n",
      "Epoch : 483 train_loss : 26888.60439453125 Val loss:  40054.879086914065\n",
      "Epoch : 484 train_loss : 27000.806591796874 Val loss:  40219.4359765625\n",
      "Model replaced\n",
      "Epoch : 485 train_loss : 27160.487890625 Val loss:  39935.72986816407\n",
      "Epoch : 486 train_loss : 26890.520654296874 Val loss:  40070.974291992185\n",
      "Epoch : 487 train_loss : 26958.919775390626 Val loss:  40239.36085449219\n",
      "Epoch : 488 train_loss : 27081.590869140626 Val loss:  40346.16051269531\n",
      "Epoch : 489 train_loss : 27136.136669921874 Val loss:  40232.669277343746\n",
      "Epoch : 490 train_loss : 27043.43984375 Val loss:  40141.165634765624\n",
      "Epoch : 491 train_loss : 27002.73701171875 Val loss:  40356.08254394531\n",
      "Epoch : 492 train_loss : 27294.138134765624 Val loss:  40382.270761718755\n",
      "Epoch : 493 train_loss : 26890.158447265625 Val loss:  40160.78179199219\n",
      "Epoch : 494 train_loss : 26997.3357421875 Val loss:  40146.68671875\n",
      "Epoch : 495 train_loss : 27230.956640625 Val loss:  40287.348540039064\n",
      "Epoch : 496 train_loss : 26631.524365234374 Val loss:  40233.23915527343\n",
      "Epoch : 497 train_loss : 27232.857470703126 Val loss:  40203.680493164065\n",
      "Epoch : 498 train_loss : 26914.26904296875 Val loss:  40155.018774414064\n",
      "Model replaced\n",
      "Epoch : 499 train_loss : 26487.615966796875 Val loss:  39933.082026367185\n",
      "Epoch : 500 train_loss : 26637.600830078125 Val loss:  39976.50279296875\n",
      "Epoch : 501 train_loss : 26929.5654296875 Val loss:  40275.23141113281\n",
      "Epoch : 502 train_loss : 27001.92119140625 Val loss:  40125.26910644531\n",
      "Model replaced\n",
      "Epoch : 503 train_loss : 27192.74658203125 Val loss:  39911.84533691406\n",
      "Epoch : 504 train_loss : 26867.99970703125 Val loss:  40148.56676269531\n",
      "Epoch : 505 train_loss : 27196.929150390624 Val loss:  40069.55064453125\n",
      "Epoch : 506 train_loss : 26905.426904296874 Val loss:  40176.11571289062\n",
      "Epoch : 507 train_loss : 26941.363427734374 Val loss:  40197.29354492187\n",
      "Epoch : 508 train_loss : 27111.297607421875 Val loss:  40065.003149414064\n",
      "Epoch : 509 train_loss : 26875.139306640624 Val loss:  40268.44377441406\n",
      "Model replaced\n",
      "Epoch : 510 train_loss : 27100.11181640625 Val loss:  39825.71976074219\n",
      "Epoch : 511 train_loss : 27076.324609375 Val loss:  40132.46307617187\n",
      "Epoch : 512 train_loss : 27018.052880859374 Val loss:  39972.36586914062\n",
      "Epoch : 513 train_loss : 26691.28779296875 Val loss:  40097.76948242188\n",
      "Epoch : 514 train_loss : 26920.8056640625 Val loss:  40265.073261718746\n",
      "Epoch : 515 train_loss : 26692.3060546875 Val loss:  39979.50137695313\n",
      "Epoch : 516 train_loss : 26823.29921875 Val loss:  39941.3150390625\n",
      "Epoch : 517 train_loss : 26909.42783203125 Val loss:  40078.28696777344\n",
      "Model replaced\n",
      "Epoch : 518 train_loss : 26795.676611328126 Val loss:  39614.09770507812\n",
      "Epoch : 519 train_loss : 26750.106201171875 Val loss:  39903.951064453126\n",
      "Epoch : 520 train_loss : 26727.06904296875 Val loss:  39986.68095214844\n",
      "Epoch : 521 train_loss : 26895.847509765626 Val loss:  40308.93660644531\n",
      "Epoch : 522 train_loss : 27057.43935546875 Val loss:  40046.586215820316\n",
      "Epoch : 523 train_loss : 27105.650537109374 Val loss:  40032.506591796875\n",
      "Epoch : 524 train_loss : 26786.861474609374 Val loss:  40057.19007324219\n",
      "Epoch : 525 train_loss : 26636.68271484375 Val loss:  40080.166435546875\n",
      "Epoch : 526 train_loss : 26669.05830078125 Val loss:  40076.76550292969\n",
      "Epoch : 527 train_loss : 26691.032958984375 Val loss:  40036.723803710935\n",
      "Epoch : 528 train_loss : 26603.97978515625 Val loss:  39800.60885253906\n",
      "Epoch : 529 train_loss : 26892.4017578125 Val loss:  39862.6009375\n",
      "Epoch : 530 train_loss : 26769.1970703125 Val loss:  40038.917685546876\n",
      "Epoch : 531 train_loss : 27010.301220703124 Val loss:  40064.68738769532\n",
      "Epoch : 532 train_loss : 27069.069873046876 Val loss:  40010.78232910157\n",
      "Epoch : 533 train_loss : 27048.54453125 Val loss:  39818.23009277343\n",
      "Epoch : 534 train_loss : 27114.404443359374 Val loss:  40088.36515625\n",
      "Epoch : 535 train_loss : 26697.06015625 Val loss:  39999.70105957032\n",
      "Epoch : 536 train_loss : 26626.3609375 Val loss:  40153.94713378906\n",
      "Epoch : 537 train_loss : 26379.812109375 Val loss:  39898.55571777344\n",
      "Epoch : 538 train_loss : 26751.332861328126 Val loss:  39952.76131835937\n",
      "Epoch : 539 train_loss : 26526.572265625 Val loss:  39958.28087402343\n",
      "Epoch : 540 train_loss : 26506.4302734375 Val loss:  39845.51375488281\n",
      "Epoch : 541 train_loss : 26596.22568359375 Val loss:  39944.4587890625\n",
      "Epoch : 542 train_loss : 26518.89072265625 Val loss:  39866.644047851565\n",
      "Epoch : 543 train_loss : 26740.467236328124 Val loss:  39790.70466796875\n",
      "Epoch : 544 train_loss : 26619.801318359376 Val loss:  39858.87681640625\n",
      "Epoch : 545 train_loss : 26703.4177734375 Val loss:  39937.8691796875\n",
      "Epoch : 546 train_loss : 26852.656640625 Val loss:  39839.05236816406\n",
      "Epoch : 547 train_loss : 26566.7412109375 Val loss:  39992.926484375\n",
      "Epoch : 548 train_loss : 27104.23916015625 Val loss:  40042.80768066406\n",
      "Epoch : 549 train_loss : 26395.13955078125 Val loss:  39957.437104492186\n",
      "Epoch : 550 train_loss : 27064.20947265625 Val loss:  39875.98282714844\n",
      "Epoch : 551 train_loss : 26640.556640625 Val loss:  40014.484443359375\n",
      "Epoch : 552 train_loss : 26686.64365234375 Val loss:  40071.61152832031\n",
      "Epoch : 553 train_loss : 26522.021337890626 Val loss:  39837.283515625\n",
      "Epoch : 554 train_loss : 26835.97216796875 Val loss:  40145.87587890625\n",
      "Epoch : 555 train_loss : 26692.371826171875 Val loss:  39850.20735839844\n",
      "Epoch : 556 train_loss : 26522.432470703126 Val loss:  40022.79082519531\n",
      "Epoch : 557 train_loss : 26814.252880859374 Val loss:  40089.9923046875\n",
      "Epoch : 558 train_loss : 27012.75849609375 Val loss:  39852.69541503907\n",
      "Epoch : 559 train_loss : 26603.1697265625 Val loss:  40168.98739257812\n",
      "Epoch : 560 train_loss : 26791.099560546874 Val loss:  39925.06333007813\n",
      "Epoch : 561 train_loss : 26335.372900390626 Val loss:  39796.20660644531\n",
      "Epoch : 562 train_loss : 26384.51513671875 Val loss:  40007.858642578125\n",
      "Epoch : 563 train_loss : 26365.947314453126 Val loss:  39957.286040039064\n",
      "Epoch : 564 train_loss : 26774.637060546876 Val loss:  40080.156420898435\n",
      "Epoch : 565 train_loss : 26916.994775390624 Val loss:  39678.38464355469\n",
      "Epoch : 566 train_loss : 26484.945458984374 Val loss:  40021.541782226566\n",
      "Epoch : 567 train_loss : 26754.612744140624 Val loss:  39715.328330078126\n",
      "Model replaced\n",
      "Epoch : 568 train_loss : 26585.840478515624 Val loss:  39597.76106933594\n",
      "Model replaced\n",
      "Epoch : 569 train_loss : 26749.006298828124 Val loss:  39544.843217773436\n",
      "Epoch : 570 train_loss : 26584.2408203125 Val loss:  39887.04400878906\n",
      "Model replaced\n",
      "Epoch : 571 train_loss : 26425.755419921876 Val loss:  39468.44135253906\n",
      "Epoch : 572 train_loss : 26641.48359375 Val loss:  39802.906181640625\n",
      "Epoch : 573 train_loss : 26517.979638671874 Val loss:  39944.58873046875\n",
      "Epoch : 574 train_loss : 26442.684521484374 Val loss:  39788.30802734375\n",
      "Epoch : 575 train_loss : 26730.775146484375 Val loss:  39838.16718261719\n",
      "Epoch : 576 train_loss : 26428.954541015624 Val loss:  39759.70799804687\n",
      "Epoch : 577 train_loss : 26314.363916015624 Val loss:  40011.640795898435\n",
      "Epoch : 578 train_loss : 26562.370849609375 Val loss:  39816.55551269531\n",
      "Epoch : 579 train_loss : 26913.400439453126 Val loss:  40173.49748535156\n",
      "Epoch : 580 train_loss : 26538.781494140625 Val loss:  39974.617407226564\n",
      "Epoch : 581 train_loss : 26547.603955078124 Val loss:  39708.35179199219\n",
      "Epoch : 582 train_loss : 26728.65751953125 Val loss:  39678.18545898438\n",
      "Epoch : 583 train_loss : 26534.5970703125 Val loss:  39679.645302734374\n",
      "Epoch : 584 train_loss : 26459.752587890624 Val loss:  39642.590546875\n",
      "Epoch : 585 train_loss : 26585.65322265625 Val loss:  39881.86462890625\n",
      "Epoch : 586 train_loss : 26594.12998046875 Val loss:  39826.031093749996\n",
      "Epoch : 587 train_loss : 26325.589501953124 Val loss:  39732.763906249995\n",
      "Epoch : 588 train_loss : 26641.523388671874 Val loss:  39912.47780273437\n",
      "Epoch : 589 train_loss : 26444.164892578126 Val loss:  39796.85590820313\n",
      "Epoch : 590 train_loss : 26502.6677734375 Val loss:  39564.88231445312\n",
      "Epoch : 591 train_loss : 26496.279443359374 Val loss:  39897.234121093745\n",
      "Epoch : 592 train_loss : 26445.535009765626 Val loss:  39499.73405273438\n",
      "Epoch : 593 train_loss : 26192.469873046874 Val loss:  39856.294609375\n",
      "Epoch : 594 train_loss : 26305.35402832031 Val loss:  39653.71687011719\n",
      "Epoch : 595 train_loss : 26244.34697265625 Val loss:  39912.21284179688\n",
      "Epoch : 596 train_loss : 26257.47841796875 Val loss:  39748.014921875\n",
      "Epoch : 597 train_loss : 26483.887841796874 Val loss:  39700.43157714844\n",
      "Epoch : 598 train_loss : 26285.562109375 Val loss:  39612.614189453125\n",
      "Epoch : 599 train_loss : 26485.922509765624 Val loss:  39864.668774414065\n",
      "Epoch : 600 train_loss : 26315.8990234375 Val loss:  39736.90279785156\n",
      "Epoch : 601 train_loss : 26597.2541015625 Val loss:  39765.38095703125\n",
      "Epoch : 602 train_loss : 26414.21640625 Val loss:  39499.45695800781\n",
      "Epoch : 603 train_loss : 26447.023486328126 Val loss:  39621.37959472656\n",
      "Epoch : 604 train_loss : 26494.150634765625 Val loss:  39913.43458496094\n",
      "Epoch : 605 train_loss : 26273.6826171875 Val loss:  39594.71142578125\n",
      "Epoch : 606 train_loss : 26344.30869140625 Val loss:  39785.22417480469\n",
      "Epoch : 607 train_loss : 26082.811279296875 Val loss:  39654.02721679687\n",
      "Epoch : 608 train_loss : 26612.341357421876 Val loss:  39828.81132324219\n",
      "Epoch : 609 train_loss : 26632.860888671876 Val loss:  39738.61831054687\n",
      "Epoch : 610 train_loss : 26375.5384765625 Val loss:  39874.96396484375\n",
      "Epoch : 611 train_loss : 26068.2205078125 Val loss:  39693.87952148438\n",
      "Epoch : 612 train_loss : 26149.372119140626 Val loss:  39739.02443847656\n",
      "Epoch : 613 train_loss : 26514.9869140625 Val loss:  39885.16391601563\n",
      "Epoch : 614 train_loss : 26081.10556640625 Val loss:  39591.61468261719\n",
      "Epoch : 615 train_loss : 26246.021337890626 Val loss:  39614.77393554688\n",
      "Epoch : 616 train_loss : 26458.6240234375 Val loss:  39551.823623046876\n",
      "Epoch : 617 train_loss : 25965.816455078126 Val loss:  39880.181308593754\n",
      "Epoch : 618 train_loss : 26264.439599609374 Val loss:  39613.92666992188\n",
      "Epoch : 619 train_loss : 26379.078662109376 Val loss:  39508.95760742187\n",
      "Epoch : 620 train_loss : 26220.52900390625 Val loss:  39785.28594726563\n",
      "Epoch : 621 train_loss : 26102.618115234374 Val loss:  39757.52759277344\n",
      "Epoch : 622 train_loss : 26396.5521484375 Val loss:  39630.19896972656\n",
      "Model replaced\n",
      "Epoch : 623 train_loss : 26351.743505859376 Val loss:  39460.49938476562\n",
      "Epoch : 624 train_loss : 26310.27509765625 Val loss:  39654.25831542969\n",
      "Epoch : 625 train_loss : 26238.553466796875 Val loss:  39820.385273437496\n",
      "Epoch : 626 train_loss : 26280.117529296876 Val loss:  39640.38034667969\n",
      "Epoch : 627 train_loss : 26343.957666015624 Val loss:  39973.75791503907\n",
      "Epoch : 628 train_loss : 26313.80029296875 Val loss:  39696.55073242188\n",
      "Epoch : 629 train_loss : 26246.600927734376 Val loss:  39718.574536132815\n",
      "Epoch : 630 train_loss : 26447.995263671874 Val loss:  39610.98006347656\n",
      "Epoch : 631 train_loss : 26606.043359375 Val loss:  39586.26448242187\n",
      "Epoch : 632 train_loss : 26156.48388671875 Val loss:  39639.252197265625\n",
      "Epoch : 633 train_loss : 26473.7138671875 Val loss:  39656.59409667969\n",
      "Epoch : 634 train_loss : 26204.22734375 Val loss:  39475.71378417969\n",
      "Epoch : 635 train_loss : 26204.26328125 Val loss:  39818.466215820314\n",
      "Model replaced\n",
      "Epoch : 636 train_loss : 26076.085791015626 Val loss:  39426.405092773435\n",
      "Epoch : 637 train_loss : 26358.455419921876 Val loss:  39653.91788574219\n",
      "Epoch : 638 train_loss : 26227.57802734375 Val loss:  39543.556884765625\n",
      "Epoch : 639 train_loss : 26009.834765625 Val loss:  39559.80862792969\n",
      "Model replaced\n",
      "Epoch : 640 train_loss : 25915.08466796875 Val loss:  39346.21117675781\n",
      "Epoch : 641 train_loss : 26249.6970703125 Val loss:  39428.233955078125\n",
      "Epoch : 642 train_loss : 26265.24482421875 Val loss:  39476.392060546874\n",
      "Epoch : 643 train_loss : 25954.113916015624 Val loss:  39531.87031738281\n",
      "Epoch : 644 train_loss : 26283.907275390626 Val loss:  39666.20860839843\n",
      "Epoch : 645 train_loss : 26424.127001953126 Val loss:  39650.81981445312\n",
      "Epoch : 646 train_loss : 26088.160498046876 Val loss:  39750.97529296875\n",
      "Epoch : 647 train_loss : 26219.440771484376 Val loss:  39498.37696777344\n",
      "Epoch : 648 train_loss : 26185.261962890625 Val loss:  39625.442211914065\n",
      "Epoch : 649 train_loss : 26418.998095703126 Val loss:  39491.071870117186\n",
      "Epoch : 650 train_loss : 26039.103369140626 Val loss:  39475.65010253906\n",
      "Epoch : 651 train_loss : 26052.930859375 Val loss:  39753.40124023437\n",
      "Epoch : 652 train_loss : 26061.885986328125 Val loss:  39493.454370117186\n",
      "Model replaced\n",
      "Epoch : 653 train_loss : 26294.155224609374 Val loss:  39304.621015625\n",
      "Epoch : 654 train_loss : 25940.76560058594 Val loss:  39779.78088867188\n",
      "Epoch : 655 train_loss : 26132.6048828125 Val loss:  39417.05076660156\n",
      "Epoch : 656 train_loss : 26170.525634765625 Val loss:  39449.127885742186\n",
      "Epoch : 657 train_loss : 25946.0783203125 Val loss:  39473.88812011719\n",
      "Epoch : 658 train_loss : 26155.79873046875 Val loss:  39558.407158203125\n",
      "Epoch : 659 train_loss : 25984.7431640625 Val loss:  39460.289760742184\n",
      "Epoch : 660 train_loss : 25735.04072265625 Val loss:  39740.39791015625\n",
      "Epoch : 661 train_loss : 25849.358642578125 Val loss:  39465.75113769531\n",
      "Epoch : 662 train_loss : 26211.4697265625 Val loss:  39643.350766601565\n",
      "Epoch : 663 train_loss : 26029.49697265625 Val loss:  39532.43834960937\n",
      "Epoch : 664 train_loss : 25802.565576171874 Val loss:  39812.84770507812\n",
      "Epoch : 665 train_loss : 25817.865234375 Val loss:  39636.54321777344\n",
      "Epoch : 666 train_loss : 26179.9220703125 Val loss:  39427.57456054688\n",
      "Epoch : 667 train_loss : 26094.791455078124 Val loss:  39642.88252441406\n",
      "Epoch : 668 train_loss : 26272.060009765624 Val loss:  39515.929780273436\n",
      "Epoch : 669 train_loss : 26421.6720703125 Val loss:  39426.83536132813\n",
      "Epoch : 670 train_loss : 26169.95771484375 Val loss:  39368.04022460937\n",
      "Epoch : 671 train_loss : 25852.240185546874 Val loss:  39356.362333984376\n",
      "Epoch : 672 train_loss : 26218.60759277344 Val loss:  39340.69198242187\n",
      "Epoch : 673 train_loss : 26047.13232421875 Val loss:  39470.348398437505\n",
      "Epoch : 674 train_loss : 26017.58173828125 Val loss:  39606.94060546875\n",
      "Epoch : 675 train_loss : 25849.90986328125 Val loss:  39454.08482421875\n",
      "Epoch : 676 train_loss : 26199.262353515624 Val loss:  39539.903139648435\n",
      "Epoch : 677 train_loss : 25789.92578125 Val loss:  39481.39385253906\n",
      "Epoch : 678 train_loss : 25880.13740234375 Val loss:  39358.99013671875\n",
      "Epoch : 679 train_loss : 26172.984033203124 Val loss:  39588.289555664065\n",
      "Epoch : 680 train_loss : 26029.9921875 Val loss:  39563.15693359375\n",
      "Epoch : 681 train_loss : 25690.57666015625 Val loss:  39686.09028320313\n",
      "Epoch : 682 train_loss : 25903.60390625 Val loss:  39494.13483886719\n",
      "Epoch : 683 train_loss : 26058.430029296876 Val loss:  39566.06312011719\n",
      "Model replaced\n",
      "Epoch : 684 train_loss : 25866.19287109375 Val loss:  39292.8863671875\n",
      "Epoch : 685 train_loss : 25889.495166015626 Val loss:  39632.79611328125\n",
      "Epoch : 686 train_loss : 26305.75712890625 Val loss:  39504.04020019531\n",
      "Epoch : 687 train_loss : 25993.707861328126 Val loss:  39549.018320312505\n",
      "Epoch : 688 train_loss : 25767.36318359375 Val loss:  39437.42151367188\n",
      "Epoch : 689 train_loss : 26157.0189453125 Val loss:  39474.255952148436\n",
      "Epoch : 690 train_loss : 25798.0576171875 Val loss:  39333.11846191406\n",
      "Epoch : 691 train_loss : 26089.352197265624 Val loss:  39353.618671874996\n",
      "Epoch : 692 train_loss : 26018.367578125 Val loss:  39436.2571875\n",
      "Epoch : 693 train_loss : 25874.750341796876 Val loss:  39473.04849121094\n",
      "Epoch : 694 train_loss : 25770.896704101564 Val loss:  39437.75089355469\n",
      "Epoch : 695 train_loss : 25930.631396484376 Val loss:  39480.367294921874\n",
      "Epoch : 696 train_loss : 25883.2990234375 Val loss:  39360.35494140625\n",
      "Model replaced\n",
      "Epoch : 697 train_loss : 25811.89387207031 Val loss:  39292.05323242188\n",
      "Epoch : 698 train_loss : 25926.292749023436 Val loss:  39295.70717773437\n",
      "Epoch : 699 train_loss : 25881.988232421874 Val loss:  39339.31669433594\n",
      "Epoch : 700 train_loss : 25919.6513671875 Val loss:  39312.76068847656\n",
      "Epoch : 701 train_loss : 25629.558837890625 Val loss:  39501.52615234375\n",
      "Model replaced\n",
      "Epoch : 702 train_loss : 25874.3107421875 Val loss:  39244.827617187504\n",
      "Model replaced\n",
      "Epoch : 703 train_loss : 26038.824560546876 Val loss:  39228.801689453125\n",
      "Epoch : 704 train_loss : 25701.179443359375 Val loss:  39420.43409667969\n",
      "Model replaced\n",
      "Epoch : 705 train_loss : 25826.40090332031 Val loss:  39178.04719726562\n",
      "Epoch : 706 train_loss : 25898.80712890625 Val loss:  39251.54235839844\n",
      "Epoch : 707 train_loss : 25946.65361328125 Val loss:  39372.439848632814\n",
      "Epoch : 708 train_loss : 25697.1265625 Val loss:  39372.17077148437\n",
      "Epoch : 709 train_loss : 25859.767724609374 Val loss:  39549.14299316406\n",
      "Epoch : 710 train_loss : 25735.79580078125 Val loss:  39412.169462890626\n",
      "Epoch : 711 train_loss : 26085.611328125 Val loss:  39291.043974609376\n",
      "Model replaced\n",
      "Epoch : 712 train_loss : 26165.636962890625 Val loss:  39047.930634765624\n",
      "Epoch : 713 train_loss : 25624.796826171874 Val loss:  39431.5584765625\n",
      "Epoch : 714 train_loss : 25944.92724609375 Val loss:  39342.91225585937\n",
      "Epoch : 715 train_loss : 26045.492822265624 Val loss:  39301.35293945313\n",
      "Epoch : 716 train_loss : 25649.1029296875 Val loss:  39392.53967773438\n",
      "Epoch : 717 train_loss : 26030.464721679688 Val loss:  39272.77163085937\n",
      "Epoch : 718 train_loss : 25772.840478515624 Val loss:  39242.559077148435\n",
      "Epoch : 719 train_loss : 25940.871533203124 Val loss:  39159.79329589844\n",
      "Epoch : 720 train_loss : 25799.820654296876 Val loss:  39393.127651367184\n",
      "Epoch : 721 train_loss : 25653.614697265624 Val loss:  39264.83592285156\n",
      "Epoch : 722 train_loss : 25608.393896484376 Val loss:  39428.196796874996\n",
      "Epoch : 723 train_loss : 25839.6451171875 Val loss:  39352.35537109375\n",
      "Model replaced\n",
      "Epoch : 724 train_loss : 25652.3580078125 Val loss:  39028.638359375\n",
      "Epoch : 725 train_loss : 25888.966015625 Val loss:  39195.31920898437\n",
      "Epoch : 726 train_loss : 25711.36357421875 Val loss:  39298.07724609375\n",
      "Epoch : 727 train_loss : 26001.331005859374 Val loss:  39231.17342285156\n",
      "Epoch : 728 train_loss : 25731.74345703125 Val loss:  39262.374267578125\n",
      "Epoch : 729 train_loss : 25570.700439453125 Val loss:  39203.839912109375\n",
      "Epoch : 730 train_loss : 25872.496826171875 Val loss:  39223.016918945315\n",
      "Epoch : 731 train_loss : 25575.290087890626 Val loss:  39346.65590820312\n",
      "Epoch : 732 train_loss : 26176.807348632814 Val loss:  39467.093281249996\n",
      "Epoch : 733 train_loss : 25604.036083984374 Val loss:  39237.276645507816\n",
      "Epoch : 734 train_loss : 25536.371337890625 Val loss:  39556.14369140625\n",
      "Epoch : 735 train_loss : 25542.314013671876 Val loss:  39366.41268066406\n",
      "Epoch : 736 train_loss : 25658.5060546875 Val loss:  39189.85118652343\n",
      "Epoch : 737 train_loss : 25476.516455078126 Val loss:  39106.19732910156\n",
      "Epoch : 738 train_loss : 25778.562548828126 Val loss:  39427.58390625\n",
      "Epoch : 739 train_loss : 25601.663427734376 Val loss:  39243.58649902344\n",
      "Epoch : 740 train_loss : 25532.33937988281 Val loss:  39136.10182617187\n",
      "Epoch : 741 train_loss : 25697.122900390626 Val loss:  39086.61896484375\n",
      "Epoch : 742 train_loss : 25831.242822265624 Val loss:  39261.569340820315\n",
      "Epoch : 743 train_loss : 25495.426684570313 Val loss:  39366.423857421876\n",
      "Epoch : 744 train_loss : 25289.972998046876 Val loss:  39329.096875\n",
      "Epoch : 745 train_loss : 25641.81650390625 Val loss:  39307.3201171875\n",
      "Epoch : 746 train_loss : 25645.9658203125 Val loss:  39269.375390625\n",
      "Epoch : 747 train_loss : 25695.150927734376 Val loss:  39119.14873046875\n",
      "Epoch : 748 train_loss : 25545.720336914062 Val loss:  39080.00639648437\n",
      "Epoch : 749 train_loss : 25592.00615234375 Val loss:  39224.484370117185\n",
      "Epoch : 750 train_loss : 25321.773315429688 Val loss:  39140.62895507812\n",
      "Epoch : 751 train_loss : 25653.560546875 Val loss:  39203.290292968755\n",
      "Epoch : 752 train_loss : 25741.561181640624 Val loss:  39070.23549316406\n",
      "Epoch : 753 train_loss : 25389.710693359375 Val loss:  39229.54349609375\n",
      "Epoch : 754 train_loss : 25576.061669921874 Val loss:  39251.731464843746\n",
      "Model replaced\n",
      "Epoch : 755 train_loss : 25838.73232421875 Val loss:  39015.36822265625\n",
      "Epoch : 756 train_loss : 25646.2119140625 Val loss:  39210.20313964844\n",
      "Model replaced\n",
      "Epoch : 757 train_loss : 25567.2552734375 Val loss:  38980.60615234375\n",
      "Epoch : 758 train_loss : 25559.297607421875 Val loss:  39176.14567382813\n",
      "Model replaced\n",
      "Epoch : 759 train_loss : 25462.131884765626 Val loss:  38895.60177734375\n",
      "Epoch : 760 train_loss : 25443.60595703125 Val loss:  39238.945629882815\n",
      "Epoch : 761 train_loss : 25763.64755859375 Val loss:  39164.34383300781\n",
      "Epoch : 762 train_loss : 25471.4923828125 Val loss:  39322.200102539064\n",
      "Epoch : 763 train_loss : 25494.024951171876 Val loss:  39260.336191406255\n",
      "Epoch : 764 train_loss : 25551.61220703125 Val loss:  39245.35768554687\n",
      "Epoch : 765 train_loss : 25401.219482421875 Val loss:  39316.812246093745\n",
      "Epoch : 766 train_loss : 25691.12470703125 Val loss:  39114.03815917969\n",
      "Epoch : 767 train_loss : 25509.13818359375 Val loss:  38900.502207031255\n",
      "Epoch : 768 train_loss : 25519.310400390626 Val loss:  39248.10354003906\n",
      "Epoch : 769 train_loss : 25254.196533203125 Val loss:  39061.909208984376\n",
      "Epoch : 770 train_loss : 25442.12001953125 Val loss:  38948.48085449218\n",
      "Epoch : 771 train_loss : 25213.39973144531 Val loss:  39369.17467285156\n",
      "Model replaced\n",
      "Epoch : 772 train_loss : 25678.78420410156 Val loss:  38834.90767578125\n",
      "Epoch : 773 train_loss : 25589.463720703126 Val loss:  39075.09052734375\n",
      "Epoch : 774 train_loss : 25166.0671875 Val loss:  38879.45619140625\n",
      "Epoch : 775 train_loss : 25210.654248046874 Val loss:  39198.23986328125\n",
      "Epoch : 776 train_loss : 25255.509423828124 Val loss:  39068.58698730469\n",
      "Epoch : 777 train_loss : 25150.288940429688 Val loss:  39355.740654296875\n",
      "Epoch : 778 train_loss : 25523.81982421875 Val loss:  39036.75089355469\n",
      "Epoch : 779 train_loss : 25378.05402832031 Val loss:  39069.86490722656\n",
      "Epoch : 780 train_loss : 25620.30322265625 Val loss:  39133.92600585938\n",
      "Epoch : 781 train_loss : 25668.6478515625 Val loss:  39015.86906738281\n",
      "Epoch : 782 train_loss : 25548.94736328125 Val loss:  39219.70665527343\n",
      "Epoch : 783 train_loss : 25633.626318359376 Val loss:  39209.94448242187\n",
      "Epoch : 784 train_loss : 25398.90771484375 Val loss:  39035.04706542969\n",
      "Epoch : 785 train_loss : 25474.6998046875 Val loss:  38924.64112304688\n",
      "Model replaced\n",
      "Epoch : 786 train_loss : 25382.76162109375 Val loss:  38710.182524414064\n",
      "Epoch : 787 train_loss : 25563.208349609376 Val loss:  38975.69860351562\n",
      "Epoch : 788 train_loss : 25338.023486328126 Val loss:  38895.94144042969\n",
      "Epoch : 789 train_loss : 25570.081689453124 Val loss:  39012.93666503906\n",
      "Epoch : 790 train_loss : 25058.10068359375 Val loss:  39018.55802734375\n",
      "Epoch : 791 train_loss : 25022.984594726564 Val loss:  39059.519560546876\n",
      "Epoch : 792 train_loss : 25401.56818847656 Val loss:  38891.58057373047\n",
      "Epoch : 793 train_loss : 25459.326245117187 Val loss:  39087.2330078125\n",
      "Epoch : 794 train_loss : 25613.24655761719 Val loss:  39027.986640625\n",
      "Epoch : 795 train_loss : 25468.1697265625 Val loss:  38891.422890625\n",
      "Epoch : 796 train_loss : 25363.4388671875 Val loss:  39134.686630859374\n",
      "Epoch : 797 train_loss : 25258.1458984375 Val loss:  39083.389882812495\n",
      "Epoch : 798 train_loss : 25049.932885742186 Val loss:  38909.79435546875\n",
      "Epoch : 799 train_loss : 25328.827514648438 Val loss:  39232.04520996094\n",
      "Epoch : 800 train_loss : 25674.6076171875 Val loss:  39032.677001953125\n",
      "Epoch : 801 train_loss : 25322.9251953125 Val loss:  38872.56028320313\n",
      "Epoch : 802 train_loss : 25077.51462402344 Val loss:  39082.433828124995\n",
      "Epoch : 803 train_loss : 25410.393139648437 Val loss:  38856.923549804684\n",
      "Epoch : 804 train_loss : 25036.899267578126 Val loss:  39007.32318847656\n",
      "Epoch : 805 train_loss : 25249.07685546875 Val loss:  39009.001884765625\n",
      "Epoch : 806 train_loss : 25202.26171875 Val loss:  39083.168212890625\n",
      "Epoch : 807 train_loss : 25468.461206054686 Val loss:  38925.357265624996\n",
      "Epoch : 808 train_loss : 25254.047583007814 Val loss:  38995.28802734375\n",
      "Epoch : 809 train_loss : 25533.17155761719 Val loss:  38852.54532226563\n",
      "Epoch : 810 train_loss : 25171.62644042969 Val loss:  39098.40836425781\n",
      "Model replaced\n",
      "Epoch : 811 train_loss : 25219.93117675781 Val loss:  38708.22393554688\n",
      "Epoch : 812 train_loss : 25341.06052246094 Val loss:  39145.806547851564\n",
      "Epoch : 813 train_loss : 25364.26369628906 Val loss:  38967.580595703126\n",
      "Epoch : 814 train_loss : 25468.1150390625 Val loss:  38875.69376953125\n",
      "Epoch : 815 train_loss : 25092.949560546876 Val loss:  39008.958212890626\n",
      "Epoch : 816 train_loss : 25479.19191894531 Val loss:  38930.71180175782\n",
      "Epoch : 817 train_loss : 25394.99375 Val loss:  38791.64744628906\n",
      "Epoch : 818 train_loss : 25017.450634765624 Val loss:  38827.74205078125\n",
      "Epoch : 819 train_loss : 24986.30810546875 Val loss:  39039.056406250005\n",
      "Epoch : 820 train_loss : 25302.01728515625 Val loss:  38966.17883300781\n",
      "Epoch : 821 train_loss : 25144.61618652344 Val loss:  38889.50373046875\n",
      "Epoch : 822 train_loss : 25287.277294921874 Val loss:  38933.25701171875\n",
      "Epoch : 823 train_loss : 25177.289501953124 Val loss:  38751.00892089844\n",
      "Epoch : 824 train_loss : 25105.19130859375 Val loss:  39024.894453125\n",
      "Epoch : 825 train_loss : 24912.178955078125 Val loss:  39108.71524414063\n",
      "Epoch : 826 train_loss : 25399.741357421874 Val loss:  38930.83141601562\n",
      "Epoch : 827 train_loss : 25104.29636230469 Val loss:  39100.98241210937\n",
      "Epoch : 828 train_loss : 25195.671923828126 Val loss:  38909.662602539065\n",
      "Epoch : 829 train_loss : 25460.3255859375 Val loss:  38970.70299804687\n",
      "Epoch : 830 train_loss : 25062.5734375 Val loss:  38858.498740234376\n",
      "Epoch : 831 train_loss : 25365.085034179687 Val loss:  38793.31486328125\n",
      "Epoch : 832 train_loss : 25359.234130859375 Val loss:  39055.850625\n",
      "Epoch : 833 train_loss : 25087.78352050781 Val loss:  38974.08797363281\n",
      "Epoch : 834 train_loss : 25189.11667480469 Val loss:  38927.06992675782\n",
      "Epoch : 835 train_loss : 24938.988525390625 Val loss:  38822.143276367184\n",
      "Epoch : 836 train_loss : 25336.36064453125 Val loss:  39087.301875\n",
      "Epoch : 837 train_loss : 24828.0640625 Val loss:  39119.024082031254\n",
      "Epoch : 838 train_loss : 24954.225390625 Val loss:  38830.149658203125\n",
      "Epoch : 839 train_loss : 25247.092724609374 Val loss:  38765.22580078125\n",
      "Epoch : 840 train_loss : 25343.4080078125 Val loss:  38806.83790039063\n",
      "Epoch : 841 train_loss : 25447.259692382813 Val loss:  38967.74767089843\n",
      "Epoch : 842 train_loss : 24897.11025390625 Val loss:  38796.58466796875\n",
      "Epoch : 843 train_loss : 24735.59736328125 Val loss:  39010.68837402343\n",
      "Epoch : 844 train_loss : 25010.32746582031 Val loss:  38937.05121582031\n",
      "Epoch : 845 train_loss : 25213.68425292969 Val loss:  38845.75642089844\n",
      "Model replaced\n",
      "Epoch : 846 train_loss : 25202.531494140625 Val loss:  38574.741542968746\n",
      "Epoch : 847 train_loss : 25130.198291015626 Val loss:  38923.02939941407\n",
      "Epoch : 848 train_loss : 25144.65791015625 Val loss:  38832.597373046876\n",
      "Epoch : 849 train_loss : 25140.504272460938 Val loss:  38960.745634765626\n",
      "Epoch : 850 train_loss : 25156.25065917969 Val loss:  38905.5955078125\n",
      "Epoch : 851 train_loss : 25142.376831054688 Val loss:  38760.1428515625\n",
      "Epoch : 852 train_loss : 25062.306079101563 Val loss:  38976.22967773437\n",
      "Epoch : 853 train_loss : 25240.074780273437 Val loss:  38901.224677734375\n",
      "Epoch : 854 train_loss : 24931.39130859375 Val loss:  38602.80554199219\n",
      "Epoch : 855 train_loss : 25166.66220703125 Val loss:  38858.386723632815\n",
      "Epoch : 856 train_loss : 25173.229052734376 Val loss:  38910.15254394531\n",
      "Epoch : 857 train_loss : 25205.48342285156 Val loss:  38861.12760253906\n",
      "Epoch : 858 train_loss : 25061.529565429686 Val loss:  38813.77633300781\n",
      "Epoch : 859 train_loss : 25299.2986328125 Val loss:  38720.708178710935\n",
      "Epoch : 860 train_loss : 24946.869506835938 Val loss:  38710.27928710937\n",
      "Epoch : 861 train_loss : 24944.853247070314 Val loss:  38793.54532714844\n",
      "Epoch : 862 train_loss : 25268.433715820312 Val loss:  39000.821782226565\n",
      "Epoch : 863 train_loss : 25156.649145507814 Val loss:  38840.85052246094\n",
      "Epoch : 864 train_loss : 25083.66923828125 Val loss:  38763.59253417969\n",
      "Epoch : 865 train_loss : 25023.11572265625 Val loss:  38808.40032714844\n",
      "Epoch : 866 train_loss : 25003.211767578126 Val loss:  38849.00545410156\n",
      "Epoch : 867 train_loss : 25106.607470703126 Val loss:  38648.53554199218\n",
      "Epoch : 868 train_loss : 25120.5755859375 Val loss:  38766.90353515625\n",
      "Epoch : 869 train_loss : 25254.566796875 Val loss:  38905.99102050781\n",
      "Epoch : 870 train_loss : 25464.774047851562 Val loss:  38821.211430664065\n",
      "Epoch : 871 train_loss : 24955.209399414063 Val loss:  38823.517158203125\n",
      "Epoch : 872 train_loss : 24956.90788574219 Val loss:  39037.58282226563\n",
      "Epoch : 873 train_loss : 25082.181518554688 Val loss:  38786.67658203125\n",
      "Epoch : 874 train_loss : 25265.07373046875 Val loss:  38894.053466796875\n",
      "Epoch : 875 train_loss : 25109.575 Val loss:  38864.97036621094\n",
      "Epoch : 876 train_loss : 24795.314038085937 Val loss:  38754.17060546875\n",
      "Epoch : 877 train_loss : 24891.580615234376 Val loss:  38936.16704101562\n",
      "Epoch : 878 train_loss : 24861.385986328125 Val loss:  38796.096748046875\n",
      "Epoch : 879 train_loss : 24793.45573730469 Val loss:  38894.910087890625\n",
      "Epoch : 880 train_loss : 24949.997924804688 Val loss:  38653.389882812495\n",
      "Model replaced\n",
      "Epoch : 881 train_loss : 25040.443579101564 Val loss:  38512.611875\n",
      "Epoch : 882 train_loss : 25057.451123046874 Val loss:  38681.88\n",
      "Epoch : 883 train_loss : 24866.57878417969 Val loss:  38944.368959960935\n",
      "Epoch : 884 train_loss : 24996.298071289064 Val loss:  38614.73680175781\n",
      "Epoch : 885 train_loss : 24990.839233398438 Val loss:  38916.895390625\n",
      "Epoch : 886 train_loss : 24875.135473632814 Val loss:  38768.99916992187\n",
      "Epoch : 887 train_loss : 24771.920361328124 Val loss:  38749.38603027344\n",
      "Epoch : 888 train_loss : 24699.69094238281 Val loss:  38678.80785644531\n",
      "Epoch : 889 train_loss : 25182.059692382812 Val loss:  38793.80641601562\n",
      "Model replaced\n",
      "Epoch : 890 train_loss : 25006.335571289062 Val loss:  38480.54732421875\n",
      "Epoch : 891 train_loss : 25015.705297851564 Val loss:  38822.47561035156\n",
      "Epoch : 892 train_loss : 24798.168676757814 Val loss:  38743.88774414062\n",
      "Epoch : 893 train_loss : 25079.566528320312 Val loss:  38768.73270996094\n",
      "Epoch : 894 train_loss : 24776.0255859375 Val loss:  38597.97775390625\n",
      "Epoch : 895 train_loss : 24867.29768066406 Val loss:  38590.24037597656\n",
      "Epoch : 896 train_loss : 24689.821362304687 Val loss:  38829.15117675781\n",
      "Epoch : 897 train_loss : 24765.849169921876 Val loss:  38575.210869140625\n",
      "Epoch : 898 train_loss : 24982.65900878906 Val loss:  38761.04582519531\n",
      "Epoch : 899 train_loss : 24960.23503417969 Val loss:  38797.929516601565\n",
      "Epoch : 900 train_loss : 25024.874243164064 Val loss:  38866.966767578124\n",
      "Model replaced\n",
      "Epoch : 901 train_loss : 24849.61357421875 Val loss:  38452.714687499996\n",
      "Epoch : 902 train_loss : 24867.948120117188 Val loss:  38816.206171875\n",
      "Epoch : 903 train_loss : 24941.52019042969 Val loss:  38796.104921875\n",
      "Epoch : 904 train_loss : 24756.476293945314 Val loss:  38849.33437011718\n",
      "Epoch : 905 train_loss : 24668.195166015626 Val loss:  38719.77450195312\n",
      "Epoch : 906 train_loss : 24579.434619140626 Val loss:  38955.811103515625\n",
      "Epoch : 907 train_loss : 24897.53171386719 Val loss:  38745.063759765624\n",
      "Epoch : 908 train_loss : 24671.802368164062 Val loss:  38572.97516113281\n",
      "Epoch : 909 train_loss : 24699.865625 Val loss:  38593.92630371094\n",
      "Epoch : 910 train_loss : 24745.61799316406 Val loss:  38843.35505371094\n",
      "Epoch : 911 train_loss : 25013.22722167969 Val loss:  38545.643823242186\n",
      "Epoch : 912 train_loss : 24743.60397949219 Val loss:  38760.23234375\n",
      "Epoch : 913 train_loss : 24931.70979003906 Val loss:  38741.444643554685\n",
      "Epoch : 914 train_loss : 24779.581176757812 Val loss:  38657.36884765625\n",
      "Model replaced\n",
      "Epoch : 915 train_loss : 24900.41501464844 Val loss:  38446.632592773436\n",
      "Epoch : 916 train_loss : 24992.66396484375 Val loss:  38648.097402343745\n",
      "Epoch : 917 train_loss : 24684.892919921876 Val loss:  38602.33851074219\n",
      "Epoch : 918 train_loss : 24895.531860351562 Val loss:  38810.800297851565\n",
      "Epoch : 919 train_loss : 24762.176171875 Val loss:  38576.42350585938\n",
      "Epoch : 920 train_loss : 24842.765893554686 Val loss:  38802.58021484375\n",
      "Epoch : 921 train_loss : 24878.823510742186 Val loss:  38614.87417480469\n",
      "Epoch : 922 train_loss : 24982.743701171876 Val loss:  38702.51172851563\n",
      "Epoch : 923 train_loss : 24620.4529296875 Val loss:  38813.82823730468\n",
      "Epoch : 924 train_loss : 24742.757861328126 Val loss:  38744.63610839844\n",
      "Epoch : 925 train_loss : 24791.280029296875 Val loss:  38492.52581542969\n",
      "Epoch : 926 train_loss : 24477.272827148438 Val loss:  38676.86260253906\n",
      "Model replaced\n",
      "Epoch : 927 train_loss : 24969.705029296874 Val loss:  38421.542900390625\n",
      "Epoch : 928 train_loss : 24902.250366210938 Val loss:  38598.760390625\n",
      "Epoch : 929 train_loss : 24667.36247558594 Val loss:  38575.85495605469\n",
      "Epoch : 930 train_loss : 25033.01904296875 Val loss:  38556.76608886719\n",
      "Epoch : 931 train_loss : 24743.60349121094 Val loss:  38707.12626953125\n",
      "Epoch : 932 train_loss : 24966.72365722656 Val loss:  38485.564833984376\n",
      "Epoch : 933 train_loss : 24892.429418945314 Val loss:  38548.467504882814\n",
      "Epoch : 934 train_loss : 24681.7306640625 Val loss:  38636.54975585938\n",
      "Epoch : 935 train_loss : 24640.31203613281 Val loss:  38867.63786132813\n",
      "Epoch : 936 train_loss : 24944.2498046875 Val loss:  38583.76310058594\n",
      "Epoch : 937 train_loss : 24570.662451171876 Val loss:  38655.91607910156\n",
      "Epoch : 938 train_loss : 24660.265258789062 Val loss:  38612.113979492184\n",
      "Epoch : 939 train_loss : 24931.905151367188 Val loss:  38714.92844726563\n",
      "Epoch : 940 train_loss : 24776.4859375 Val loss:  38704.88153320312\n",
      "Epoch : 941 train_loss : 24750.441479492187 Val loss:  38713.143950195314\n",
      "Epoch : 942 train_loss : 24528.09079589844 Val loss:  38635.71821289063\n",
      "Epoch : 943 train_loss : 25102.36494140625 Val loss:  38498.038505859375\n",
      "Epoch : 944 train_loss : 24511.83095703125 Val loss:  38640.03843261719\n",
      "Model replaced\n",
      "Epoch : 945 train_loss : 24722.087646484375 Val loss:  38334.82187988282\n",
      "Epoch : 946 train_loss : 24585.89345703125 Val loss:  38830.88187011719\n",
      "Epoch : 947 train_loss : 24612.249853515626 Val loss:  38656.177216796874\n",
      "Epoch : 948 train_loss : 24906.578833007814 Val loss:  38342.72244140625\n",
      "Epoch : 949 train_loss : 24799.853564453126 Val loss:  38674.05333496093\n",
      "Epoch : 950 train_loss : 25103.91376953125 Val loss:  38626.48793457031\n",
      "Epoch : 951 train_loss : 24777.354565429687 Val loss:  38727.36292480469\n",
      "Epoch : 952 train_loss : 24728.578344726564 Val loss:  38609.90389160156\n",
      "Epoch : 953 train_loss : 24811.15383300781 Val loss:  38445.713798828125\n",
      "Epoch : 954 train_loss : 24432.911962890626 Val loss:  38546.57614746094\n",
      "Epoch : 955 train_loss : 24926.864013671875 Val loss:  38526.90899414063\n",
      "Epoch : 956 train_loss : 24463.870971679688 Val loss:  38627.72866210937\n",
      "Epoch : 957 train_loss : 24864.97067871094 Val loss:  38479.47452148438\n",
      "Epoch : 958 train_loss : 24572.748046875 Val loss:  38544.70719726563\n",
      "Epoch : 959 train_loss : 24551.79196777344 Val loss:  38775.38138183594\n",
      "Epoch : 960 train_loss : 24914.232983398437 Val loss:  38491.1387890625\n",
      "Epoch : 961 train_loss : 24635.892333984375 Val loss:  38668.28119628906\n",
      "Epoch : 962 train_loss : 24924.9380859375 Val loss:  38776.967866210936\n",
      "Epoch : 963 train_loss : 24873.284375 Val loss:  38796.28159667969\n",
      "Epoch : 964 train_loss : 24394.820703125 Val loss:  38689.778125\n",
      "Epoch : 965 train_loss : 24721.841357421876 Val loss:  38528.60691894531\n",
      "Epoch : 966 train_loss : 24760.77521972656 Val loss:  38497.263852539065\n",
      "Epoch : 967 train_loss : 24640.1044921875 Val loss:  38557.0458984375\n",
      "Epoch : 968 train_loss : 24433.47177734375 Val loss:  38491.766015625\n",
      "Epoch : 969 train_loss : 24810.036254882812 Val loss:  38623.87591308594\n",
      "Epoch : 970 train_loss : 24588.331982421874 Val loss:  38406.92077148437\n",
      "Epoch : 971 train_loss : 24736.48566894531 Val loss:  38525.10679199219\n",
      "Epoch : 972 train_loss : 24442.17253417969 Val loss:  38394.85021484375\n",
      "Epoch : 973 train_loss : 24567.339599609375 Val loss:  38531.92679199219\n",
      "Epoch : 974 train_loss : 24609.841943359374 Val loss:  38638.40030761719\n",
      "Epoch : 975 train_loss : 24626.891650390626 Val loss:  38535.539794921875\n",
      "Epoch : 976 train_loss : 24580.176171875 Val loss:  38398.34839355469\n",
      "Epoch : 977 train_loss : 24653.892700195312 Val loss:  38561.391855468755\n",
      "Epoch : 978 train_loss : 24461.35732421875 Val loss:  38437.14605957031\n",
      "Epoch : 979 train_loss : 24737.7275390625 Val loss:  38403.55424804687\n",
      "Epoch : 980 train_loss : 24575.353515625 Val loss:  38362.84887207031\n",
      "Epoch : 981 train_loss : 24489.66716308594 Val loss:  38579.21823730469\n",
      "Epoch : 982 train_loss : 24250.760595703126 Val loss:  38383.084941406254\n",
      "Epoch : 983 train_loss : 24445.136791992187 Val loss:  38372.96179199219\n",
      "Epoch : 984 train_loss : 24690.627734375 Val loss:  38486.614013671875\n",
      "Epoch : 985 train_loss : 24368.2640625 Val loss:  38741.131484375\n",
      "Epoch : 986 train_loss : 24634.062280273436 Val loss:  38391.49171386719\n",
      "Epoch : 987 train_loss : 24580.314501953126 Val loss:  38385.72211914063\n",
      "Epoch : 988 train_loss : 24624.23000488281 Val loss:  38645.09003417969\n",
      "Epoch : 989 train_loss : 24724.83818359375 Val loss:  38587.597109375\n",
      "Epoch : 990 train_loss : 24966.091845703126 Val loss:  38490.92650878906\n",
      "Epoch : 991 train_loss : 24671.97248535156 Val loss:  38376.722939453124\n",
      "Epoch : 992 train_loss : 24723.960571289062 Val loss:  38570.41857421875\n",
      "Epoch : 993 train_loss : 24635.12761230469 Val loss:  38570.11929199219\n",
      "Model replaced\n",
      "Epoch : 994 train_loss : 24510.751513671876 Val loss:  38282.521025390626\n",
      "Epoch : 995 train_loss : 24681.479541015626 Val loss:  38399.65384277344\n",
      "Epoch : 996 train_loss : 24259.944091796875 Val loss:  38348.44049316406\n",
      "Epoch : 997 train_loss : 24678.731005859376 Val loss:  38443.12418457031\n",
      "Epoch : 998 train_loss : 24907.94169921875 Val loss:  38460.3710546875\n",
      "Epoch : 999 train_loss : 24384.15915527344 Val loss:  38507.59453125\n",
      "Epoch : 1000 train_loss : 24342.41728515625 Val loss:  38546.814296874996\n",
      "Epoch : 1001 train_loss : 24431.45344238281 Val loss:  38454.88611816407\n",
      "Epoch : 1002 train_loss : 24309.00107421875 Val loss:  38377.59029296875\n",
      "Epoch : 1003 train_loss : 24696.333911132813 Val loss:  38524.09931640625\n",
      "Model replaced\n",
      "Epoch : 1004 train_loss : 24330.147045898437 Val loss:  38117.758994140626\n",
      "Epoch : 1005 train_loss : 24706.49033203125 Val loss:  38380.75184082032\n",
      "Epoch : 1006 train_loss : 24497.646215820314 Val loss:  38613.96132324218\n",
      "Epoch : 1007 train_loss : 24853.530346679687 Val loss:  38310.19427734375\n",
      "Epoch : 1008 train_loss : 24643.957299804686 Val loss:  38728.47540039063\n",
      "Epoch : 1009 train_loss : 24476.38369140625 Val loss:  38680.17575683594\n",
      "Epoch : 1010 train_loss : 24478.45461425781 Val loss:  38373.81560546875\n",
      "Epoch : 1011 train_loss : 24577.01418457031 Val loss:  38464.91053222657\n",
      "Epoch : 1012 train_loss : 24516.18894042969 Val loss:  38433.921542968754\n",
      "Epoch : 1013 train_loss : 24238.55986328125 Val loss:  38383.52765625\n",
      "Epoch : 1014 train_loss : 24590.868994140626 Val loss:  38601.8821484375\n",
      "Epoch : 1015 train_loss : 24605.966162109376 Val loss:  38393.83531738281\n",
      "Epoch : 1016 train_loss : 24791.118603515624 Val loss:  38387.20891113281\n",
      "Epoch : 1017 train_loss : 24862.38193359375 Val loss:  38415.61873535156\n",
      "Epoch : 1018 train_loss : 24516.402197265626 Val loss:  38395.37875488281\n",
      "Epoch : 1019 train_loss : 24675.120703125 Val loss:  38488.21019042969\n",
      "Epoch : 1020 train_loss : 24512.47607421875 Val loss:  38216.69439941406\n",
      "Epoch : 1021 train_loss : 24455.58771972656 Val loss:  38575.58401855469\n",
      "Epoch : 1022 train_loss : 24591.259619140626 Val loss:  38420.686416015626\n",
      "Epoch : 1023 train_loss : 24429.328955078126 Val loss:  38537.72430664062\n",
      "Epoch : 1024 train_loss : 24168.345654296874 Val loss:  38351.40153320313\n",
      "Epoch : 1025 train_loss : 24389.585815429688 Val loss:  38507.66294921875\n",
      "Epoch : 1026 train_loss : 24186.885864257812 Val loss:  38339.36766113281\n",
      "Epoch : 1027 train_loss : 24420.29873046875 Val loss:  38626.02140136719\n",
      "Epoch : 1028 train_loss : 24559.28776855469 Val loss:  38188.9040234375\n",
      "Epoch : 1029 train_loss : 24151.24765625 Val loss:  38619.465151367185\n",
      "Epoch : 1030 train_loss : 24556.8759765625 Val loss:  38494.82866210937\n",
      "Epoch : 1031 train_loss : 24526.894946289063 Val loss:  38307.84185546875\n",
      "Epoch : 1032 train_loss : 24415.557397460936 Val loss:  38406.370937499996\n",
      "Epoch : 1033 train_loss : 24520.647338867188 Val loss:  38314.190400390624\n",
      "Epoch : 1034 train_loss : 24530.28837890625 Val loss:  38186.712133789064\n",
      "Epoch : 1035 train_loss : 24793.13947753906 Val loss:  38608.80412597656\n",
      "Epoch : 1036 train_loss : 24440.809838867186 Val loss:  38463.910649414065\n",
      "Model replaced\n",
      "Epoch : 1037 train_loss : 24353.30625 Val loss:  38103.03181640625\n",
      "Epoch : 1038 train_loss : 24404.75017089844 Val loss:  38571.42290527344\n",
      "Epoch : 1039 train_loss : 24469.050415039062 Val loss:  38206.80854003906\n",
      "Epoch : 1040 train_loss : 24193.183374023436 Val loss:  38227.363515624995\n",
      "Epoch : 1041 train_loss : 24574.82529296875 Val loss:  38286.375908203125\n",
      "Epoch : 1042 train_loss : 24567.00546875 Val loss:  38311.74061035157\n",
      "Epoch : 1043 train_loss : 24425.31838378906 Val loss:  38457.08766113281\n",
      "Epoch : 1044 train_loss : 24309.968896484374 Val loss:  38172.28629882813\n",
      "Epoch : 1045 train_loss : 24577.1205078125 Val loss:  38376.846372070315\n",
      "Model replaced\n",
      "Epoch : 1046 train_loss : 24231.285400390625 Val loss:  38018.524667968755\n",
      "Epoch : 1047 train_loss : 24374.569921875 Val loss:  38386.192138671875\n",
      "Epoch : 1048 train_loss : 24513.869970703126 Val loss:  38470.30215820313\n",
      "Epoch : 1049 train_loss : 24310.98698730469 Val loss:  38220.90294921875\n",
      "Epoch : 1050 train_loss : 24483.883862304687 Val loss:  38330.052714843754\n",
      "Epoch : 1051 train_loss : 24270.72165527344 Val loss:  38619.08947753906\n",
      "Epoch : 1052 train_loss : 23992.26560058594 Val loss:  38326.525346679686\n",
      "Epoch : 1053 train_loss : 24447.883715820313 Val loss:  38224.576279296874\n",
      "Epoch : 1054 train_loss : 24381.63688964844 Val loss:  38423.14880859375\n",
      "Epoch : 1055 train_loss : 24350.39345703125 Val loss:  38223.60918945313\n",
      "Epoch : 1056 train_loss : 24344.46376953125 Val loss:  38475.34947753906\n",
      "Epoch : 1057 train_loss : 24472.638745117187 Val loss:  38178.75462402344\n",
      "Epoch : 1058 train_loss : 24509.194409179687 Val loss:  38293.81139648437\n",
      "Epoch : 1059 train_loss : 24325.204321289064 Val loss:  38119.45714355468\n",
      "Epoch : 1060 train_loss : 24285.909912109375 Val loss:  38326.18738769532\n",
      "Epoch : 1061 train_loss : 24552.2638671875 Val loss:  38265.8658203125\n",
      "Epoch : 1062 train_loss : 24292.32255859375 Val loss:  38453.14487304688\n",
      "Epoch : 1063 train_loss : 24332.63215332031 Val loss:  38445.34154785156\n",
      "Epoch : 1064 train_loss : 24051.382055664064 Val loss:  38487.180908203125\n",
      "Epoch : 1065 train_loss : 24244.43977050781 Val loss:  38646.36934082031\n",
      "Epoch : 1066 train_loss : 24314.5865234375 Val loss:  38292.016391601566\n",
      "Epoch : 1067 train_loss : 24204.44033203125 Val loss:  38257.01361816406\n",
      "Epoch : 1068 train_loss : 24544.71181640625 Val loss:  38173.93629394531\n",
      "Epoch : 1069 train_loss : 24244.1587890625 Val loss:  38348.29459472656\n",
      "Epoch : 1070 train_loss : 23953.30808105469 Val loss:  38290.782119140626\n",
      "Epoch : 1071 train_loss : 24436.605615234374 Val loss:  38284.29801269531\n",
      "Epoch : 1072 train_loss : 24323.179272460937 Val loss:  38396.14361328125\n",
      "Epoch : 1073 train_loss : 24622.359643554686 Val loss:  38122.54280273437\n",
      "Epoch : 1074 train_loss : 24349.69384765625 Val loss:  38328.830673828124\n",
      "Epoch : 1075 train_loss : 24436.79794921875 Val loss:  38330.81265136719\n",
      "Epoch : 1076 train_loss : 24364.2439453125 Val loss:  38484.49506835938\n",
      "Epoch : 1077 train_loss : 24132.912670898437 Val loss:  38341.108129882814\n",
      "Epoch : 1078 train_loss : 24352.09621582031 Val loss:  38316.03349609375\n",
      "Epoch : 1079 train_loss : 24437.52333984375 Val loss:  38196.56578125\n",
      "Epoch : 1080 train_loss : 24468.93850097656 Val loss:  38404.717421875\n",
      "Epoch : 1081 train_loss : 24048.68857421875 Val loss:  38361.81508300781\n",
      "Epoch : 1082 train_loss : 24292.02138671875 Val loss:  38333.44635253906\n",
      "Epoch : 1083 train_loss : 24382.959594726562 Val loss:  38195.13474121094\n",
      "Epoch : 1084 train_loss : 24272.03791503906 Val loss:  38336.622324218755\n",
      "Epoch : 1085 train_loss : 24295.587622070314 Val loss:  38379.80961914062\n",
      "Epoch : 1086 train_loss : 24470.521606445312 Val loss:  38287.173125\n",
      "Epoch : 1087 train_loss : 24410.21320800781 Val loss:  38392.07211425781\n",
      "Epoch : 1088 train_loss : 24587.294970703126 Val loss:  38313.933100585935\n",
      "Epoch : 1089 train_loss : 24558.971875 Val loss:  38260.529013671876\n",
      "Epoch : 1090 train_loss : 24297.599169921876 Val loss:  38221.444316406254\n",
      "Epoch : 1091 train_loss : 24299.7001953125 Val loss:  38187.3462890625\n",
      "Model replaced\n",
      "Epoch : 1092 train_loss : 24244.49611816406 Val loss:  37997.61043457031\n",
      "Epoch : 1093 train_loss : 24290.369921875 Val loss:  38146.39251464844\n",
      "Epoch : 1094 train_loss : 24202.148803710938 Val loss:  38471.1262890625\n",
      "Epoch : 1095 train_loss : 24236.3080078125 Val loss:  38538.068115234375\n",
      "Epoch : 1096 train_loss : 24168.961865234374 Val loss:  38416.01537597656\n",
      "Epoch : 1097 train_loss : 24311.626171875 Val loss:  38370.89922363281\n",
      "Epoch : 1098 train_loss : 24335.197973632814 Val loss:  38291.88511230469\n",
      "Epoch : 1099 train_loss : 23828.8267578125 Val loss:  38033.391845703125\n",
      "Epoch : 1100 train_loss : 24278.315307617188 Val loss:  38381.85930175781\n",
      "Epoch : 1101 train_loss : 24113.954541015624 Val loss:  38117.874257812495\n",
      "Epoch : 1102 train_loss : 24308.09609375 Val loss:  38090.193803710936\n",
      "Epoch : 1103 train_loss : 24243.662060546874 Val loss:  38252.58265625\n",
      "Epoch : 1104 train_loss : 24362.505126953125 Val loss:  38233.088657226566\n",
      "Epoch : 1105 train_loss : 24166.671606445314 Val loss:  38346.49018554688\n",
      "Epoch : 1106 train_loss : 24097.453491210938 Val loss:  38270.19159667969\n",
      "Epoch : 1107 train_loss : 24287.164477539063 Val loss:  38518.984306640625\n",
      "Epoch : 1108 train_loss : 24159.043188476564 Val loss:  38128.577680664064\n",
      "Epoch : 1109 train_loss : 23983.549560546875 Val loss:  38413.08002441406\n",
      "Epoch : 1110 train_loss : 24228.34326171875 Val loss:  38140.66196777344\n",
      "Epoch : 1111 train_loss : 24171.85078125 Val loss:  38326.538569335935\n",
      "Epoch : 1112 train_loss : 24226.113623046876 Val loss:  37999.25092773438\n",
      "Epoch : 1113 train_loss : 24161.323193359374 Val loss:  38367.85216796875\n",
      "Epoch : 1114 train_loss : 24228.659912109375 Val loss:  38220.80506347657\n",
      "Epoch : 1115 train_loss : 24235.288427734376 Val loss:  38111.96420410156\n",
      "Epoch : 1116 train_loss : 24173.20266113281 Val loss:  38164.09178222656\n",
      "Epoch : 1117 train_loss : 24318.777880859376 Val loss:  38394.938222656245\n",
      "Epoch : 1118 train_loss : 24455.492895507814 Val loss:  38116.64810058594\n",
      "Epoch : 1119 train_loss : 24338.245263671874 Val loss:  38400.65953613281\n",
      "Epoch : 1120 train_loss : 23947.42822265625 Val loss:  38225.84477539062\n",
      "Epoch : 1121 train_loss : 24263.815625 Val loss:  38200.038554687504\n",
      "Model replaced\n",
      "Epoch : 1122 train_loss : 24078.619970703126 Val loss:  37997.40709960937\n",
      "Epoch : 1123 train_loss : 23819.39365234375 Val loss:  38375.00463378906\n",
      "Epoch : 1124 train_loss : 24161.992309570312 Val loss:  38270.4524609375\n",
      "Epoch : 1125 train_loss : 23983.228881835938 Val loss:  38423.43875\n",
      "Epoch : 1126 train_loss : 24065.903881835937 Val loss:  38199.43399902344\n",
      "Model replaced\n",
      "Epoch : 1127 train_loss : 24082.262548828126 Val loss:  37973.88823242187\n",
      "Epoch : 1128 train_loss : 24126.860473632812 Val loss:  38356.966625976565\n",
      "Epoch : 1129 train_loss : 24154.236572265625 Val loss:  38192.230498046876\n",
      "Epoch : 1130 train_loss : 24057.94826660156 Val loss:  38097.77579589844\n",
      "Epoch : 1131 train_loss : 24245.007446289062 Val loss:  37974.800234375\n",
      "Epoch : 1132 train_loss : 24181.783422851564 Val loss:  38093.30852050781\n",
      "Epoch : 1133 train_loss : 24373.235205078126 Val loss:  38160.02527832032\n",
      "Epoch : 1134 train_loss : 24119.46110839844 Val loss:  38326.158471679686\n",
      "Epoch : 1135 train_loss : 24232.197216796874 Val loss:  38246.28583984375\n",
      "Epoch : 1136 train_loss : 24026.14143066406 Val loss:  38201.91546875\n",
      "Epoch : 1137 train_loss : 24333.954638671876 Val loss:  38179.865141601564\n",
      "Epoch : 1138 train_loss : 24001.517456054688 Val loss:  38094.51359375\n",
      "Epoch : 1139 train_loss : 23984.032983398436 Val loss:  38189.31459472656\n",
      "Epoch : 1140 train_loss : 24232.89228515625 Val loss:  38196.93108886719\n",
      "Epoch : 1141 train_loss : 23815.818017578124 Val loss:  38136.412626953126\n",
      "Epoch : 1142 train_loss : 24057.02883300781 Val loss:  38091.03170410156\n",
      "Epoch : 1143 train_loss : 24078.553784179687 Val loss:  38121.71282714844\n",
      "Epoch : 1144 train_loss : 24381.543212890625 Val loss:  38239.089047851565\n",
      "Epoch : 1145 train_loss : 24229.67998046875 Val loss:  38151.49769042969\n",
      "Epoch : 1146 train_loss : 24069.946655273438 Val loss:  38139.395190429685\n",
      "Epoch : 1147 train_loss : 23893.045288085938 Val loss:  38066.59837402344\n",
      "Epoch : 1148 train_loss : 24028.40817871094 Val loss:  38111.987324218746\n",
      "Epoch : 1149 train_loss : 24172.89052734375 Val loss:  38396.58250976562\n",
      "Epoch : 1150 train_loss : 24240.827392578125 Val loss:  38066.02666503906\n",
      "Epoch : 1151 train_loss : 24167.01921386719 Val loss:  38144.51026367188\n",
      "Epoch : 1152 train_loss : 24242.038696289062 Val loss:  38179.97059082032\n",
      "Epoch : 1153 train_loss : 24274.956298828125 Val loss:  38016.9508984375\n",
      "Model replaced\n",
      "Epoch : 1154 train_loss : 24031.423876953126 Val loss:  37964.47062011719\n",
      "Epoch : 1155 train_loss : 24027.70114746094 Val loss:  38053.177290039064\n",
      "Epoch : 1156 train_loss : 23969.560424804688 Val loss:  38241.29436035156\n",
      "Epoch : 1157 train_loss : 23917.651928710937 Val loss:  38153.58065429687\n",
      "Epoch : 1158 train_loss : 24373.993286132812 Val loss:  38234.520903320314\n",
      "Model replaced\n",
      "Epoch : 1159 train_loss : 23931.347216796876 Val loss:  37863.278364257814\n",
      "Epoch : 1160 train_loss : 24346.049926757812 Val loss:  38003.99091796875\n",
      "Epoch : 1161 train_loss : 24110.980590820312 Val loss:  37934.44239746094\n",
      "Epoch : 1162 train_loss : 24131.799194335938 Val loss:  37933.947573242185\n",
      "Epoch : 1163 train_loss : 24161.58249511719 Val loss:  38207.54934082031\n",
      "Epoch : 1164 train_loss : 24126.573486328125 Val loss:  38288.97215332031\n",
      "Epoch : 1165 train_loss : 23854.32956542969 Val loss:  38213.40503417969\n",
      "Epoch : 1166 train_loss : 23926.67106933594 Val loss:  38106.21409179688\n",
      "Epoch : 1167 train_loss : 24175.60075683594 Val loss:  38025.02270019531\n",
      "Epoch : 1168 train_loss : 23919.5251953125 Val loss:  38339.782744140626\n",
      "Epoch : 1169 train_loss : 24072.64140625 Val loss:  38104.294101562504\n",
      "Epoch : 1170 train_loss : 24046.75791015625 Val loss:  37927.02232421875\n",
      "Epoch : 1171 train_loss : 24136.38349609375 Val loss:  38198.302944335934\n",
      "Epoch : 1172 train_loss : 23937.61477050781 Val loss:  38181.61705566406\n",
      "Epoch : 1173 train_loss : 24074.11171875 Val loss:  38196.098950195315\n",
      "Epoch : 1174 train_loss : 24402.227465820313 Val loss:  37947.780292968746\n",
      "Epoch : 1175 train_loss : 24257.567749023438 Val loss:  37989.65083007813\n",
      "Epoch : 1176 train_loss : 23799.095288085937 Val loss:  37893.52634277344\n",
      "Epoch : 1177 train_loss : 24049.81984863281 Val loss:  38056.377207031255\n",
      "Epoch : 1178 train_loss : 24153.844482421875 Val loss:  38026.46813476562\n",
      "Epoch : 1179 train_loss : 23881.913452148438 Val loss:  38139.955986328125\n",
      "Epoch : 1180 train_loss : 24045.622485351563 Val loss:  38045.70764648438\n",
      "Epoch : 1181 train_loss : 23872.158447265625 Val loss:  38191.67983398437\n",
      "Epoch : 1182 train_loss : 23886.100341796875 Val loss:  38163.22276855468\n",
      "Epoch : 1183 train_loss : 23865.038696289062 Val loss:  38110.38032226563\n",
      "Epoch : 1184 train_loss : 24207.06916503906 Val loss:  37903.08078125\n",
      "Epoch : 1185 train_loss : 23900.485791015624 Val loss:  38044.41038574219\n",
      "Epoch : 1186 train_loss : 23816.028686523438 Val loss:  38108.326953125\n",
      "Epoch : 1187 train_loss : 23757.167700195314 Val loss:  38362.03593261719\n",
      "Epoch : 1188 train_loss : 23998.61826171875 Val loss:  38112.76256347656\n",
      "Epoch : 1189 train_loss : 23962.95114746094 Val loss:  38394.71706054687\n",
      "Epoch : 1190 train_loss : 24246.99641113281 Val loss:  38074.69403320312\n",
      "Epoch : 1191 train_loss : 23968.235791015624 Val loss:  38005.91255859375\n",
      "Epoch : 1192 train_loss : 23524.70148925781 Val loss:  38047.993208007814\n",
      "Epoch : 1193 train_loss : 24052.34865722656 Val loss:  38033.31712402344\n",
      "Epoch : 1194 train_loss : 23861.8224609375 Val loss:  38223.76319335938\n",
      "Epoch : 1195 train_loss : 24106.957885742188 Val loss:  38134.21864746093\n",
      "Epoch : 1196 train_loss : 23950.391040039063 Val loss:  38162.307934570315\n",
      "Model replaced\n",
      "Epoch : 1197 train_loss : 24028.15478515625 Val loss:  37838.47234375\n",
      "Epoch : 1198 train_loss : 23909.874780273436 Val loss:  38217.260649414064\n",
      "Epoch : 1199 train_loss : 24125.554296875 Val loss:  37959.85680664062\n",
      "Epoch : 1200 train_loss : 23861.608032226562 Val loss:  38004.99953613281\n",
      "Epoch : 1201 train_loss : 24026.144799804686 Val loss:  37969.795927734376\n",
      "Epoch : 1202 train_loss : 23934.20009765625 Val loss:  38057.46329589844\n",
      "Epoch : 1203 train_loss : 24073.785913085936 Val loss:  37894.291997070315\n",
      "Epoch : 1204 train_loss : 24182.7361328125 Val loss:  38047.51520019531\n",
      "Epoch : 1205 train_loss : 24041.014575195313 Val loss:  38125.40965820312\n",
      "Epoch : 1206 train_loss : 23754.527880859376 Val loss:  37944.89290039062\n",
      "Epoch : 1207 train_loss : 23849.059423828126 Val loss:  38185.43846191406\n",
      "Epoch : 1208 train_loss : 23871.06689453125 Val loss:  38162.08653808593\n",
      "Epoch : 1209 train_loss : 24292.69304199219 Val loss:  38105.956210937504\n",
      "Epoch : 1210 train_loss : 24187.412329101564 Val loss:  38040.49399414063\n",
      "Epoch : 1211 train_loss : 23951.491137695313 Val loss:  37894.76521972656\n",
      "Epoch : 1212 train_loss : 24086.521215820314 Val loss:  38069.20683105469\n",
      "Epoch : 1213 train_loss : 23851.078247070312 Val loss:  38011.64625488281\n",
      "Epoch : 1214 train_loss : 23615.24658203125 Val loss:  37957.499116210936\n",
      "Epoch : 1215 train_loss : 24228.955493164063 Val loss:  37945.41538574219\n",
      "Epoch : 1216 train_loss : 23814.25637207031 Val loss:  37972.475693359374\n",
      "Epoch : 1217 train_loss : 23899.221801757812 Val loss:  38152.37571777344\n",
      "Epoch : 1218 train_loss : 24491.538696289062 Val loss:  38036.84656738282\n",
      "Epoch : 1219 train_loss : 23735.64436035156 Val loss:  37932.08146484375\n",
      "Epoch : 1220 train_loss : 24138.466552734375 Val loss:  38040.892578125\n",
      "Epoch : 1221 train_loss : 24053.627001953126 Val loss:  38169.99748535156\n",
      "Epoch : 1222 train_loss : 23864.88996582031 Val loss:  38090.970170898436\n",
      "Epoch : 1223 train_loss : 24078.02443847656 Val loss:  38209.26332519531\n",
      "Epoch : 1224 train_loss : 23678.28024902344 Val loss:  38200.94379394531\n",
      "Epoch : 1225 train_loss : 23754.660595703124 Val loss:  38175.87852050782\n",
      "Epoch : 1226 train_loss : 23847.898315429688 Val loss:  38058.07037597656\n",
      "Epoch : 1227 train_loss : 24207.85419921875 Val loss:  37895.27973144531\n",
      "Epoch : 1228 train_loss : 23943.053784179687 Val loss:  37938.38072265625\n",
      "Epoch : 1229 train_loss : 23949.19013671875 Val loss:  38095.52181152344\n",
      "Epoch : 1230 train_loss : 23425.728247070314 Val loss:  37954.90515136719\n",
      "Epoch : 1231 train_loss : 23819.400610351564 Val loss:  38031.71264160156\n",
      "Epoch : 1232 train_loss : 23698.328833007814 Val loss:  38149.46545898438\n",
      "Epoch : 1233 train_loss : 23720.34599609375 Val loss:  37964.51752929688\n",
      "Epoch : 1234 train_loss : 23725.841162109376 Val loss:  38016.01879394531\n",
      "Epoch : 1235 train_loss : 23621.25 Val loss:  38037.94117675781\n",
      "Epoch : 1236 train_loss : 23960.81135253906 Val loss:  37870.78630859375\n",
      "Epoch : 1237 train_loss : 23963.512280273437 Val loss:  38209.24398925781\n",
      "Epoch : 1238 train_loss : 23628.86037597656 Val loss:  38069.26376708985\n",
      "Epoch : 1239 train_loss : 23963.308715820312 Val loss:  38311.78525878907\n",
      "Epoch : 1240 train_loss : 24086.187768554686 Val loss:  38045.39559570312\n",
      "Epoch : 1241 train_loss : 23766.53232421875 Val loss:  37984.76630859375\n",
      "Epoch : 1242 train_loss : 23784.48212890625 Val loss:  38000.23912109375\n",
      "Epoch : 1243 train_loss : 23952.89755859375 Val loss:  37962.476958007814\n",
      "Model replaced\n",
      "Epoch : 1244 train_loss : 23874.4205078125 Val loss:  37795.15618652344\n",
      "Epoch : 1245 train_loss : 23798.18425292969 Val loss:  37941.77575683594\n",
      "Epoch : 1246 train_loss : 23861.655639648438 Val loss:  38038.1491015625\n",
      "Model replaced\n",
      "Epoch : 1247 train_loss : 24075.822021484375 Val loss:  37751.58137695312\n",
      "Epoch : 1248 train_loss : 23718.643896484376 Val loss:  38079.82776855469\n",
      "Epoch : 1249 train_loss : 24018.027758789063 Val loss:  37933.89291503906\n",
      "Epoch : 1250 train_loss : 23916.59992675781 Val loss:  37887.723164062496\n",
      "Epoch : 1251 train_loss : 23814.119189453126 Val loss:  37977.526572265626\n",
      "Epoch : 1252 train_loss : 24124.64140625 Val loss:  37939.49114746094\n",
      "Epoch : 1253 train_loss : 23825.276000976562 Val loss:  38103.56734375\n",
      "Epoch : 1254 train_loss : 23836.94521484375 Val loss:  38051.69886230469\n",
      "Epoch : 1255 train_loss : 23699.313208007814 Val loss:  38015.48390136719\n",
      "Epoch : 1256 train_loss : 23888.206201171874 Val loss:  37915.84719238281\n",
      "Epoch : 1257 train_loss : 23582.973266601562 Val loss:  38039.38125\n",
      "Epoch : 1258 train_loss : 23843.9462890625 Val loss:  38133.43690917968\n",
      "Epoch : 1259 train_loss : 23903.014868164064 Val loss:  37957.88848144531\n",
      "Epoch : 1260 train_loss : 23823.120703125 Val loss:  37974.77952636719\n",
      "Epoch : 1261 train_loss : 24069.585571289062 Val loss:  38270.64444335938\n",
      "Epoch : 1262 train_loss : 23800.12939453125 Val loss:  38326.00571777344\n",
      "Epoch : 1263 train_loss : 23808.445751953124 Val loss:  38161.37389648437\n",
      "Epoch : 1264 train_loss : 23623.828759765624 Val loss:  37926.32858886719\n",
      "Epoch : 1265 train_loss : 23982.981494140626 Val loss:  37849.669101562504\n",
      "Epoch : 1266 train_loss : 23924.239111328126 Val loss:  38034.92274902343\n",
      "Epoch : 1267 train_loss : 23601.269287109375 Val loss:  37928.92154785156\n",
      "Epoch : 1268 train_loss : 23818.09377441406 Val loss:  37868.0836328125\n",
      "Epoch : 1269 train_loss : 23611.692114257814 Val loss:  37785.046806640625\n",
      "Epoch : 1270 train_loss : 23766.729370117188 Val loss:  38176.6732421875\n",
      "Epoch : 1271 train_loss : 23776.99138183594 Val loss:  37877.52785644531\n",
      "Epoch : 1272 train_loss : 23844.7703125 Val loss:  37777.64174804687\n",
      "Epoch : 1273 train_loss : 23702.54978027344 Val loss:  38192.58937011719\n",
      "Epoch : 1274 train_loss : 23916.23762207031 Val loss:  37975.44397949219\n",
      "Model replaced\n",
      "Epoch : 1275 train_loss : 24046.9794921875 Val loss:  37708.513671875\n",
      "Epoch : 1276 train_loss : 23641.590771484374 Val loss:  37894.708989257815\n",
      "Epoch : 1277 train_loss : 24034.796459960937 Val loss:  37797.742880859376\n",
      "Epoch : 1278 train_loss : 23849.215063476564 Val loss:  37953.79232910156\n",
      "Epoch : 1279 train_loss : 23480.427172851563 Val loss:  37907.26015136718\n",
      "Epoch : 1280 train_loss : 23708.936791992186 Val loss:  37835.957734375\n",
      "Epoch : 1281 train_loss : 23694.847387695314 Val loss:  37989.22497558594\n",
      "Epoch : 1282 train_loss : 24018.921166992186 Val loss:  37882.35700683594\n",
      "Epoch : 1283 train_loss : 23719.0267578125 Val loss:  37724.820107421874\n",
      "Epoch : 1284 train_loss : 24039.510986328125 Val loss:  38021.5237109375\n",
      "Epoch : 1285 train_loss : 23261.679443359375 Val loss:  37903.414760742184\n",
      "Epoch : 1286 train_loss : 23800.643359375 Val loss:  37864.460478515626\n",
      "Epoch : 1287 train_loss : 23747.84406738281 Val loss:  37746.00532226563\n",
      "Epoch : 1288 train_loss : 23931.979077148437 Val loss:  37875.35987304688\n",
      "Epoch : 1289 train_loss : 24065.375048828126 Val loss:  37984.70688476563\n",
      "Epoch : 1290 train_loss : 23676.97604980469 Val loss:  37957.817763671876\n",
      "Epoch : 1291 train_loss : 23869.211767578126 Val loss:  37800.60772460938\n",
      "Epoch : 1292 train_loss : 23577.300146484376 Val loss:  37993.640444335935\n",
      "Epoch : 1293 train_loss : 24032.001879882813 Val loss:  38090.852749023434\n",
      "Epoch : 1294 train_loss : 23650.8580078125 Val loss:  37780.983642578125\n",
      "Epoch : 1295 train_loss : 23627.12490234375 Val loss:  37756.007480468754\n",
      "Epoch : 1296 train_loss : 23825.893603515626 Val loss:  37716.365903320315\n",
      "Epoch : 1297 train_loss : 24060.069750976563 Val loss:  37928.550400390624\n",
      "Epoch : 1298 train_loss : 23946.09699707031 Val loss:  38054.55678710937\n",
      "Epoch : 1299 train_loss : 23919.732666015625 Val loss:  37889.109453125\n",
      "Epoch : 1300 train_loss : 23739.157421875 Val loss:  37872.83364746094\n",
      "Epoch : 1301 train_loss : 23897.7775390625 Val loss:  38007.31379882812\n",
      "Epoch : 1302 train_loss : 23833.847241210937 Val loss:  37892.98835449219\n",
      "Epoch : 1303 train_loss : 23916.332739257814 Val loss:  37918.56144042969\n",
      "Epoch : 1304 train_loss : 23656.5359375 Val loss:  38074.988486328126\n",
      "Model replaced\n",
      "Epoch : 1305 train_loss : 23919.872631835937 Val loss:  37661.151899414064\n",
      "Epoch : 1306 train_loss : 23884.999609375 Val loss:  38068.0362109375\n",
      "Epoch : 1307 train_loss : 23601.703564453124 Val loss:  37930.7294140625\n",
      "Epoch : 1308 train_loss : 23912.57990722656 Val loss:  38064.11832519531\n",
      "Epoch : 1309 train_loss : 23807.067114257814 Val loss:  37972.469394531254\n",
      "Epoch : 1310 train_loss : 23885.251416015624 Val loss:  37874.467001953126\n",
      "Epoch : 1311 train_loss : 23690.30319824219 Val loss:  37724.30549804687\n",
      "Epoch : 1312 train_loss : 23926.65185546875 Val loss:  38198.20654296875\n",
      "Epoch : 1313 train_loss : 23636.814501953126 Val loss:  37738.05991699219\n",
      "Epoch : 1314 train_loss : 24099.68308105469 Val loss:  37681.37368164062\n",
      "Epoch : 1315 train_loss : 24030.574096679688 Val loss:  37770.62818847656\n",
      "Epoch : 1316 train_loss : 23803.178295898437 Val loss:  37898.51109375\n",
      "Epoch : 1317 train_loss : 23580.19580078125 Val loss:  37849.86143066407\n",
      "Epoch : 1318 train_loss : 23561.91926269531 Val loss:  37991.94681640625\n",
      "Epoch : 1319 train_loss : 23869.564599609374 Val loss:  37972.732026367186\n",
      "Epoch : 1320 train_loss : 23943.293798828126 Val loss:  37999.684350585936\n",
      "Epoch : 1321 train_loss : 23695.448510742186 Val loss:  37842.57015136719\n",
      "Epoch : 1322 train_loss : 23474.25974121094 Val loss:  37977.862773437504\n",
      "Epoch : 1323 train_loss : 23852.5330078125 Val loss:  37782.62053222656\n",
      "Epoch : 1324 train_loss : 23622.45212402344 Val loss:  37829.061528320315\n",
      "Epoch : 1325 train_loss : 23910.876586914062 Val loss:  38075.815151367184\n",
      "Epoch : 1326 train_loss : 23628.12941894531 Val loss:  37842.913041992186\n",
      "Epoch : 1327 train_loss : 23773.470361328124 Val loss:  37751.99552246094\n",
      "Epoch : 1328 train_loss : 23652.466381835937 Val loss:  37815.549008789065\n",
      "Epoch : 1329 train_loss : 23534.38542480469 Val loss:  38036.28686035156\n",
      "Epoch : 1330 train_loss : 23764.2904296875 Val loss:  37765.27290039063\n",
      "Epoch : 1331 train_loss : 23681.277978515624 Val loss:  37955.98708984375\n",
      "Model replaced\n",
      "Epoch : 1332 train_loss : 23842.82001953125 Val loss:  37553.93053222656\n",
      "Epoch : 1333 train_loss : 23532.382177734376 Val loss:  37885.321499023434\n",
      "Epoch : 1334 train_loss : 23719.31022949219 Val loss:  37969.15784179688\n",
      "Epoch : 1335 train_loss : 23820.99431152344 Val loss:  37805.402651367185\n",
      "Epoch : 1336 train_loss : 23461.171826171874 Val loss:  37929.5563671875\n",
      "Epoch : 1337 train_loss : 23922.619287109374 Val loss:  37688.87224609375\n",
      "Epoch : 1338 train_loss : 23824.949096679688 Val loss:  37953.03404785156\n",
      "Epoch : 1339 train_loss : 23534.140087890624 Val loss:  37769.76772460937\n",
      "Epoch : 1340 train_loss : 23860.067163085936 Val loss:  37959.76061523437\n",
      "Epoch : 1341 train_loss : 23623.835083007812 Val loss:  37745.77361328125\n",
      "Epoch : 1342 train_loss : 23748.057836914064 Val loss:  37961.59607910157\n",
      "Epoch : 1343 train_loss : 23642.715893554687 Val loss:  38046.927226562504\n",
      "Epoch : 1344 train_loss : 23536.25632324219 Val loss:  37902.31779296875\n",
      "Epoch : 1345 train_loss : 23452.237548828125 Val loss:  37795.430454101566\n",
      "Epoch : 1346 train_loss : 23589.87775878906 Val loss:  37756.659575195314\n",
      "Epoch : 1347 train_loss : 23931.50107421875 Val loss:  38024.57053710938\n",
      "Epoch : 1348 train_loss : 23781.11865234375 Val loss:  37931.95056640625\n",
      "Epoch : 1349 train_loss : 23483.7693359375 Val loss:  37878.51880371094\n",
      "Epoch : 1350 train_loss : 23768.376586914062 Val loss:  37885.95020507813\n",
      "Epoch : 1351 train_loss : 23581.284545898438 Val loss:  37750.971860351565\n",
      "Epoch : 1352 train_loss : 23688.735205078126 Val loss:  37715.298515625\n",
      "Epoch : 1353 train_loss : 23792.60417480469 Val loss:  37757.746625976564\n",
      "Epoch : 1354 train_loss : 23706.327368164064 Val loss:  37746.35817382812\n",
      "Epoch : 1355 train_loss : 23847.268823242186 Val loss:  38071.016108398435\n",
      "Epoch : 1356 train_loss : 23831.321142578126 Val loss:  38159.01567382812\n",
      "Epoch : 1357 train_loss : 23480.9787109375 Val loss:  37754.72312011719\n",
      "Epoch : 1358 train_loss : 23747.665893554688 Val loss:  37889.31724609375\n",
      "Epoch : 1359 train_loss : 23727.327783203124 Val loss:  37978.49313964844\n",
      "Epoch : 1360 train_loss : 23786.41806640625 Val loss:  37719.870786132815\n",
      "Epoch : 1361 train_loss : 23550.893896484376 Val loss:  38004.959013671876\n",
      "Epoch : 1362 train_loss : 23510.75146484375 Val loss:  38066.243134765624\n",
      "Epoch : 1363 train_loss : 23740.230834960938 Val loss:  37914.09009277344\n",
      "Epoch : 1364 train_loss : 23938.19970703125 Val loss:  37734.01890136719\n",
      "Epoch : 1365 train_loss : 23780.46865234375 Val loss:  37833.37876953125\n",
      "Epoch : 1366 train_loss : 23742.230834960938 Val loss:  37942.81715332031\n",
      "Epoch : 1367 train_loss : 23343.103735351564 Val loss:  37991.388188476565\n",
      "Epoch : 1368 train_loss : 23455.644384765626 Val loss:  37959.655180664064\n",
      "Epoch : 1369 train_loss : 23878.1279296875 Val loss:  37659.61022460937\n",
      "Epoch : 1370 train_loss : 23652.26748046875 Val loss:  37926.528427734374\n",
      "Epoch : 1371 train_loss : 23452.97802734375 Val loss:  37741.59487792969\n",
      "Epoch : 1372 train_loss : 23925.80537109375 Val loss:  37733.65406738281\n",
      "Epoch : 1373 train_loss : 23817.10153808594 Val loss:  37800.605312499996\n",
      "Epoch : 1374 train_loss : 23704.05458984375 Val loss:  37613.162353515625\n",
      "Epoch : 1375 train_loss : 23658.959545898437 Val loss:  37890.945781250004\n",
      "Epoch : 1376 train_loss : 23637.740112304688 Val loss:  37649.536225585936\n",
      "Epoch : 1377 train_loss : 23759.805297851562 Val loss:  37675.32337402344\n",
      "Epoch : 1378 train_loss : 23472.505102539064 Val loss:  37929.60599121094\n",
      "Epoch : 1379 train_loss : 23792.329711914062 Val loss:  37922.12264648437\n",
      "Epoch : 1380 train_loss : 23469.208935546874 Val loss:  37710.292172851565\n",
      "Epoch : 1381 train_loss : 23853.747680664062 Val loss:  37753.76484863281\n",
      "Epoch : 1382 train_loss : 24107.019653320312 Val loss:  37945.313408203125\n",
      "Epoch : 1383 train_loss : 23622.95361328125 Val loss:  38108.56199707031\n",
      "Epoch : 1384 train_loss : 23444.62741699219 Val loss:  37926.13430175781\n",
      "Epoch : 1385 train_loss : 23658.775170898436 Val loss:  37992.02610351563\n",
      "Epoch : 1386 train_loss : 23411.28664550781 Val loss:  37755.120273437504\n",
      "Epoch : 1387 train_loss : 23796.2470703125 Val loss:  37833.44994628906\n",
      "Epoch : 1388 train_loss : 23643.657299804687 Val loss:  37665.6722265625\n",
      "Epoch : 1389 train_loss : 23584.90146484375 Val loss:  37640.51062011719\n",
      "Epoch : 1390 train_loss : 23576.187939453124 Val loss:  37807.68101074219\n",
      "Epoch : 1391 train_loss : 23411.590869140626 Val loss:  37987.07265625\n",
      "Epoch : 1392 train_loss : 23471.170776367188 Val loss:  37793.74597167969\n",
      "Epoch : 1393 train_loss : 23732.981640625 Val loss:  37811.09185058594\n",
      "Epoch : 1394 train_loss : 23698.355810546876 Val loss:  37689.443940429686\n",
      "Epoch : 1395 train_loss : 23538.361450195312 Val loss:  37950.09160644531\n",
      "Epoch : 1396 train_loss : 23943.245532226563 Val loss:  37811.46461425781\n",
      "Epoch : 1397 train_loss : 23490.87724609375 Val loss:  37631.819843749996\n",
      "Epoch : 1398 train_loss : 23633.111254882813 Val loss:  37748.740000000005\n",
      "Epoch : 1399 train_loss : 23551.352905273438 Val loss:  37943.485078125\n",
      "Epoch : 1400 train_loss : 23577.64553222656 Val loss:  37697.25712402344\n",
      "Epoch : 1401 train_loss : 24003.242797851562 Val loss:  37737.83237792969\n",
      "Epoch : 1402 train_loss : 23263.054467773436 Val loss:  37897.1581640625\n",
      "Epoch : 1403 train_loss : 23312.515771484374 Val loss:  37684.50556152344\n",
      "Model replaced\n",
      "Epoch : 1404 train_loss : 23656.406640625 Val loss:  37514.639052734376\n",
      "Epoch : 1405 train_loss : 23728.4779296875 Val loss:  37848.90179199219\n",
      "Epoch : 1406 train_loss : 23414.61667480469 Val loss:  37700.68427734375\n",
      "Epoch : 1407 train_loss : 23662.514404296875 Val loss:  37766.01459960938\n",
      "Epoch : 1408 train_loss : 23572.79460449219 Val loss:  37634.01586425781\n",
      "Epoch : 1409 train_loss : 23687.21955566406 Val loss:  37731.69759277344\n",
      "Epoch : 1410 train_loss : 23800.27102050781 Val loss:  37627.354746093755\n",
      "Epoch : 1411 train_loss : 23295.246630859376 Val loss:  37596.02034667969\n",
      "Epoch : 1412 train_loss : 23430.346875 Val loss:  37882.12180664063\n",
      "Epoch : 1413 train_loss : 23690.957421875 Val loss:  37996.85168945313\n",
      "Epoch : 1414 train_loss : 23540.60202636719 Val loss:  37910.678603515626\n",
      "Epoch : 1415 train_loss : 23584.301196289063 Val loss:  37664.77366699219\n",
      "Epoch : 1416 train_loss : 23654.9423828125 Val loss:  37570.04807617188\n",
      "Epoch : 1417 train_loss : 23241.22380371094 Val loss:  37810.162578125004\n",
      "Epoch : 1418 train_loss : 23814.553100585938 Val loss:  37587.051787109376\n",
      "Epoch : 1419 train_loss : 23604.428833007812 Val loss:  37699.44470703125\n",
      "Epoch : 1420 train_loss : 23412.307690429687 Val loss:  37559.070595703124\n",
      "Epoch : 1421 train_loss : 23700.059448242188 Val loss:  37527.22327148438\n",
      "Epoch : 1422 train_loss : 23284.25 Val loss:  37723.23380371094\n",
      "Epoch : 1423 train_loss : 23256.8673828125 Val loss:  37818.53403808594\n",
      "Epoch : 1424 train_loss : 23836.83583984375 Val loss:  37705.552226562504\n",
      "Model replaced\n",
      "Epoch : 1425 train_loss : 23416.711059570312 Val loss:  37504.48949707031\n",
      "Epoch : 1426 train_loss : 23561.20341796875 Val loss:  37625.79813964844\n",
      "Epoch : 1427 train_loss : 23814.54523925781 Val loss:  37719.62529785156\n",
      "Epoch : 1428 train_loss : 23612.97902832031 Val loss:  37666.019311523436\n",
      "Epoch : 1429 train_loss : 23381.49318847656 Val loss:  37667.370073242186\n",
      "Epoch : 1430 train_loss : 23921.322875976562 Val loss:  37882.49717285157\n",
      "Epoch : 1431 train_loss : 23784.09182128906 Val loss:  37879.0199609375\n",
      "Epoch : 1432 train_loss : 23382.231567382812 Val loss:  37685.56687988281\n",
      "Epoch : 1433 train_loss : 23320.12810058594 Val loss:  37510.91370117188\n",
      "Epoch : 1434 train_loss : 23691.37014160156 Val loss:  37757.40442871094\n",
      "Model replaced\n",
      "Epoch : 1435 train_loss : 23605.553662109374 Val loss:  37462.407055664065\n",
      "Epoch : 1436 train_loss : 23321.91142578125 Val loss:  37786.756328125004\n",
      "Epoch : 1437 train_loss : 23770.55632324219 Val loss:  37721.89370605469\n",
      "Epoch : 1438 train_loss : 23545.178930664064 Val loss:  37665.39939941406\n",
      "Epoch : 1439 train_loss : 23648.99118652344 Val loss:  37654.18325683594\n",
      "Epoch : 1440 train_loss : 23563.1966796875 Val loss:  37838.865278320314\n",
      "Epoch : 1441 train_loss : 23490.490625 Val loss:  37674.730400390625\n",
      "Epoch : 1442 train_loss : 23765.928100585938 Val loss:  37906.317314453125\n",
      "Epoch : 1443 train_loss : 23399.845092773438 Val loss:  37878.661411132816\n",
      "Epoch : 1444 train_loss : 23535.8056640625 Val loss:  37503.70848144531\n",
      "Epoch : 1445 train_loss : 23565.272802734376 Val loss:  37705.35923339844\n",
      "Epoch : 1446 train_loss : 23522.112524414064 Val loss:  37671.55633789062\n",
      "Epoch : 1447 train_loss : 23583.780029296875 Val loss:  37871.90020019531\n",
      "Epoch : 1448 train_loss : 23264.2244140625 Val loss:  37754.60994628906\n",
      "Epoch : 1449 train_loss : 23656.72939453125 Val loss:  37656.23974609375\n",
      "Epoch : 1450 train_loss : 23615.481201171875 Val loss:  37541.419702148436\n",
      "Epoch : 1451 train_loss : 24008.26806640625 Val loss:  37578.325688476565\n",
      "Model replaced\n",
      "Epoch : 1452 train_loss : 23730.019287109375 Val loss:  37355.189946289065\n",
      "Epoch : 1453 train_loss : 23691.02248535156 Val loss:  37804.497714843754\n",
      "Epoch : 1454 train_loss : 23559.963671875 Val loss:  38061.99795898438\n",
      "Epoch : 1455 train_loss : 23427.327075195313 Val loss:  37816.45928222656\n",
      "Epoch : 1456 train_loss : 23781.66403808594 Val loss:  37855.300473632815\n",
      "Epoch : 1457 train_loss : 23690.872119140626 Val loss:  37649.33037109375\n",
      "Epoch : 1458 train_loss : 23654.03828125 Val loss:  37664.77164550781\n",
      "Epoch : 1459 train_loss : 23184.944677734376 Val loss:  37805.89433105469\n",
      "Epoch : 1460 train_loss : 23194.157275390626 Val loss:  37708.17301757813\n",
      "Epoch : 1461 train_loss : 23564.7208984375 Val loss:  37703.74905761719\n",
      "Epoch : 1462 train_loss : 23484.83674316406 Val loss:  37683.790947265625\n",
      "Epoch : 1463 train_loss : 23294.64992675781 Val loss:  37742.22127929687\n",
      "Epoch : 1464 train_loss : 23623.48505859375 Val loss:  37793.77400878906\n",
      "Epoch : 1465 train_loss : 23462.46083984375 Val loss:  37797.73625488281\n",
      "Epoch : 1466 train_loss : 23655.922729492188 Val loss:  37467.406040039066\n",
      "Epoch : 1467 train_loss : 23273.22158203125 Val loss:  37718.14618164062\n",
      "Epoch : 1468 train_loss : 23573.70458984375 Val loss:  37691.45474121094\n",
      "Epoch : 1469 train_loss : 23469.604370117188 Val loss:  37646.576704101564\n",
      "Epoch : 1470 train_loss : 23315.62893066406 Val loss:  37643.61219238282\n",
      "Epoch : 1471 train_loss : 23328.66892089844 Val loss:  37638.85831542969\n",
      "Epoch : 1472 train_loss : 23492.297290039063 Val loss:  37711.96072265625\n",
      "Epoch : 1473 train_loss : 23414.568627929686 Val loss:  37679.26054199219\n",
      "Epoch : 1474 train_loss : 23467.021362304688 Val loss:  37534.71469238281\n",
      "Epoch : 1475 train_loss : 23615.141455078126 Val loss:  37730.38107421875\n",
      "Epoch : 1476 train_loss : 23420.9146484375 Val loss:  37560.86864257812\n",
      "Epoch : 1477 train_loss : 23106.268017578124 Val loss:  37644.758081054686\n",
      "Epoch : 1478 train_loss : 23650.484643554686 Val loss:  37709.56739746094\n",
      "Epoch : 1479 train_loss : 23478.91408691406 Val loss:  37522.008994140626\n",
      "Epoch : 1480 train_loss : 23323.56735839844 Val loss:  37841.094545898435\n",
      "Epoch : 1481 train_loss : 22961.115673828124 Val loss:  37857.99565917969\n",
      "Epoch : 1482 train_loss : 23320.40593261719 Val loss:  37673.548120117186\n",
      "Epoch : 1483 train_loss : 23448.089477539062 Val loss:  37423.637875976565\n",
      "Epoch : 1484 train_loss : 23256.08395996094 Val loss:  37734.4854296875\n",
      "Epoch : 1485 train_loss : 23338.418798828126 Val loss:  37685.69758789062\n",
      "Epoch : 1486 train_loss : 23669.79294433594 Val loss:  37599.841791992185\n",
      "Epoch : 1487 train_loss : 23511.77666015625 Val loss:  37641.26672363281\n",
      "Epoch : 1488 train_loss : 23640.508935546874 Val loss:  37374.29113769531\n",
      "Epoch : 1489 train_loss : 23439.19677734375 Val loss:  37667.57969238282\n",
      "Epoch : 1490 train_loss : 23495.30192871094 Val loss:  37675.25394042969\n",
      "Epoch : 1491 train_loss : 23538.15908203125 Val loss:  37598.392583007815\n",
      "Epoch : 1492 train_loss : 23422.000073242187 Val loss:  37722.191650390625\n",
      "Epoch : 1493 train_loss : 23449.0568359375 Val loss:  37614.348603515624\n",
      "Epoch : 1494 train_loss : 23034.339965820312 Val loss:  37546.16379882813\n",
      "Epoch : 1495 train_loss : 23443.648315429688 Val loss:  37709.76744140625\n",
      "Epoch : 1496 train_loss : 23502.882202148438 Val loss:  37855.70176269532\n",
      "Epoch : 1497 train_loss : 23489.901293945313 Val loss:  37592.279326171876\n",
      "Epoch : 1498 train_loss : 23435.576782226562 Val loss:  37483.04016601563\n",
      "Epoch : 1499 train_loss : 23444.0638671875 Val loss:  37614.584628906254\n",
      "Epoch : 1500 train_loss : 23581.693505859374 Val loss:  37576.35645507813\n",
      "Epoch : 1501 train_loss : 23320.645288085936 Val loss:  37663.17213867187\n",
      "Epoch : 1502 train_loss : 23451.59658203125 Val loss:  37798.395600585936\n",
      "Epoch : 1503 train_loss : 23309.09853515625 Val loss:  37531.41355957031\n",
      "Epoch : 1504 train_loss : 23359.207861328126 Val loss:  37598.60510742188\n",
      "Epoch : 1505 train_loss : 23391.640625 Val loss:  37539.41951660156\n",
      "Epoch : 1506 train_loss : 23221.862841796876 Val loss:  37754.443666992185\n",
      "Epoch : 1507 train_loss : 23653.188891601563 Val loss:  37674.082548828126\n",
      "Epoch : 1508 train_loss : 23186.25002441406 Val loss:  37663.50706054688\n",
      "Epoch : 1509 train_loss : 23412.3150390625 Val loss:  37690.17415039062\n",
      "Epoch : 1510 train_loss : 23110.743505859376 Val loss:  37494.563271484374\n",
      "Epoch : 1511 train_loss : 23158.341528320314 Val loss:  37404.04508789063\n",
      "Epoch : 1512 train_loss : 23306.61428222656 Val loss:  37741.60393066406\n",
      "Epoch : 1513 train_loss : 23897.433984375 Val loss:  37614.509873046874\n",
      "Model replaced\n",
      "Epoch : 1514 train_loss : 23279.363720703124 Val loss:  37330.31977539063\n",
      "Epoch : 1515 train_loss : 23395.686108398437 Val loss:  37867.946772460935\n",
      "Epoch : 1516 train_loss : 23522.03371582031 Val loss:  37502.1087890625\n",
      "Epoch : 1517 train_loss : 23513.98273925781 Val loss:  37652.09754394532\n",
      "Epoch : 1518 train_loss : 23572.70703125 Val loss:  37683.83271484375\n",
      "Epoch : 1519 train_loss : 23338.038940429688 Val loss:  37588.790322265624\n",
      "Epoch : 1520 train_loss : 23433.1771484375 Val loss:  37471.29604980469\n",
      "Epoch : 1521 train_loss : 23446.83449707031 Val loss:  37628.988515624995\n",
      "Epoch : 1522 train_loss : 23355.204809570314 Val loss:  37635.91636230469\n",
      "Epoch : 1523 train_loss : 23571.59357910156 Val loss:  37638.14186523437\n",
      "Epoch : 1524 train_loss : 23273.692919921876 Val loss:  37618.83857910156\n",
      "Epoch : 1525 train_loss : 23188.44353027344 Val loss:  37466.308974609376\n",
      "Epoch : 1526 train_loss : 23426.268603515626 Val loss:  37833.921669921874\n",
      "Epoch : 1527 train_loss : 23604.203247070312 Val loss:  37805.82357910156\n",
      "Epoch : 1528 train_loss : 23347.915234375 Val loss:  37829.95906738281\n",
      "Epoch : 1529 train_loss : 23830.451782226562 Val loss:  37679.80688964844\n",
      "Epoch : 1530 train_loss : 23269.97958984375 Val loss:  37331.157924804684\n",
      "Epoch : 1531 train_loss : 23435.47019042969 Val loss:  37736.716791992185\n",
      "Epoch : 1532 train_loss : 23265.819213867188 Val loss:  37601.964077148434\n",
      "Epoch : 1533 train_loss : 23370.046997070312 Val loss:  37743.854184570315\n",
      "Epoch : 1534 train_loss : 23457.34765625 Val loss:  37590.52329589844\n",
      "Epoch : 1535 train_loss : 23409.64143066406 Val loss:  37595.67236328125\n",
      "Epoch : 1536 train_loss : 23520.40322265625 Val loss:  37445.66230957031\n",
      "Epoch : 1537 train_loss : 23269.111767578124 Val loss:  37738.98055175781\n",
      "Epoch : 1538 train_loss : 23476.461572265624 Val loss:  37463.854272460936\n",
      "Epoch : 1539 train_loss : 23583.656689453124 Val loss:  37419.06895996093\n",
      "Epoch : 1540 train_loss : 23487.88542480469 Val loss:  37440.77481933594\n",
      "Model replaced\n",
      "Epoch : 1541 train_loss : 23310.430810546874 Val loss:  37304.916796875\n",
      "Epoch : 1542 train_loss : 23611.64794921875 Val loss:  37556.76588867187\n",
      "Epoch : 1543 train_loss : 23492.98818359375 Val loss:  37450.06836914063\n",
      "Epoch : 1544 train_loss : 23560.545483398437 Val loss:  37573.07842285156\n",
      "Epoch : 1545 train_loss : 23272.200610351563 Val loss:  37668.85671875\n",
      "Model replaced\n",
      "Epoch : 1546 train_loss : 23265.524291992188 Val loss:  37300.78848632813\n",
      "Epoch : 1547 train_loss : 23265.76223144531 Val loss:  37329.262114257814\n",
      "Epoch : 1548 train_loss : 23569.513916015625 Val loss:  37725.630888671876\n",
      "Epoch : 1549 train_loss : 23303.832592773437 Val loss:  37739.70963378906\n",
      "Epoch : 1550 train_loss : 23519.226928710938 Val loss:  37462.91328125\n",
      "Epoch : 1551 train_loss : 23379.772094726562 Val loss:  37659.231538085936\n",
      "Epoch : 1552 train_loss : 23223.984497070312 Val loss:  37569.507592773436\n",
      "Epoch : 1553 train_loss : 23420.19306640625 Val loss:  37402.76002929687\n",
      "Epoch : 1554 train_loss : 23402.7716796875 Val loss:  37530.3623828125\n",
      "Epoch : 1555 train_loss : 23195.799462890624 Val loss:  37825.266997070314\n",
      "Epoch : 1556 train_loss : 23227.299682617188 Val loss:  37736.261674804686\n",
      "Epoch : 1557 train_loss : 23728.153588867186 Val loss:  37550.199462890625\n",
      "Epoch : 1558 train_loss : 23406.490234375 Val loss:  37832.09778808594\n",
      "Epoch : 1559 train_loss : 23607.16110839844 Val loss:  37585.36147949219\n",
      "Epoch : 1560 train_loss : 23428.97646484375 Val loss:  37416.26835449219\n",
      "Epoch : 1561 train_loss : 23105.922924804687 Val loss:  37467.935756835934\n",
      "Epoch : 1562 train_loss : 23477.06623535156 Val loss:  37567.31367675781\n",
      "Model replaced\n",
      "Epoch : 1563 train_loss : 23304.231665039064 Val loss:  37257.44721191406\n",
      "Epoch : 1564 train_loss : 23252.25712890625 Val loss:  37582.1685546875\n",
      "Epoch : 1565 train_loss : 23166.681494140626 Val loss:  37483.36466308594\n",
      "Epoch : 1566 train_loss : 23470.077587890624 Val loss:  37354.93291259765\n",
      "Epoch : 1567 train_loss : 23231.552807617187 Val loss:  37436.01643554687\n",
      "Epoch : 1568 train_loss : 23241.91640625 Val loss:  37751.666059570314\n",
      "Epoch : 1569 train_loss : 23545.640747070312 Val loss:  37621.550463867185\n",
      "Epoch : 1570 train_loss : 23426.752880859374 Val loss:  37567.69763183594\n",
      "Epoch : 1571 train_loss : 23279.395874023438 Val loss:  37446.8961328125\n",
      "Epoch : 1572 train_loss : 23240.61862792969 Val loss:  37537.8451171875\n",
      "Epoch : 1573 train_loss : 23190.819262695313 Val loss:  37319.51479980469\n",
      "Epoch : 1574 train_loss : 23313.13720703125 Val loss:  37493.0689453125\n",
      "Epoch : 1575 train_loss : 23354.82717285156 Val loss:  37587.79116699219\n",
      "Epoch : 1576 train_loss : 23497.920068359374 Val loss:  37585.62873046875\n",
      "Epoch : 1577 train_loss : 23485.506884765626 Val loss:  37544.109594726564\n",
      "Epoch : 1578 train_loss : 23430.01433105469 Val loss:  37425.30608886719\n",
      "Epoch : 1579 train_loss : 23845.403735351563 Val loss:  37427.13916992188\n",
      "Epoch : 1580 train_loss : 23401.446362304687 Val loss:  37534.79120117187\n",
      "Epoch : 1581 train_loss : 23082.674243164063 Val loss:  37429.19778808594\n",
      "Epoch : 1582 train_loss : 23540.40720214844 Val loss:  37459.059301757814\n",
      "Epoch : 1583 train_loss : 23311.681103515624 Val loss:  37709.20896972656\n",
      "Epoch : 1584 train_loss : 23587.569921875 Val loss:  37831.55951171875\n",
      "Epoch : 1585 train_loss : 23620.55827636719 Val loss:  37479.56017089843\n",
      "Epoch : 1586 train_loss : 23621.7072265625 Val loss:  37456.85803710938\n",
      "Epoch : 1587 train_loss : 23443.158764648437 Val loss:  37701.970390625\n",
      "Epoch : 1588 train_loss : 23227.22736816406 Val loss:  37401.460766601565\n",
      "Epoch : 1589 train_loss : 23306.859448242187 Val loss:  37684.08410644531\n",
      "Epoch : 1590 train_loss : 23371.31916503906 Val loss:  37571.38530273437\n",
      "Epoch : 1591 train_loss : 23203.6228515625 Val loss:  37591.99331542969\n",
      "Epoch : 1592 train_loss : 23601.13493652344 Val loss:  37605.20406738281\n",
      "Epoch : 1593 train_loss : 23489.045141601564 Val loss:  37567.82971679688\n",
      "Epoch : 1594 train_loss : 23417.696337890626 Val loss:  37688.41030273437\n",
      "Epoch : 1595 train_loss : 23016.8451171875 Val loss:  37564.36753417969\n",
      "Epoch : 1596 train_loss : 23522.45400390625 Val loss:  37674.936064453126\n",
      "Epoch : 1597 train_loss : 23501.46843261719 Val loss:  37640.93930664063\n",
      "Epoch : 1598 train_loss : 23367.01220703125 Val loss:  37460.962133789064\n",
      "Epoch : 1599 train_loss : 23444.767846679686 Val loss:  37450.00893554687\n",
      "Epoch : 1600 train_loss : 23096.20419921875 Val loss:  37616.937705078126\n",
      "Epoch : 1601 train_loss : 23314.765209960937 Val loss:  37457.54014160157\n",
      "Epoch : 1602 train_loss : 23149.17937011719 Val loss:  37420.10260253906\n",
      "Epoch : 1603 train_loss : 23174.471337890624 Val loss:  37257.79608398437\n",
      "Epoch : 1604 train_loss : 23246.783276367187 Val loss:  37639.895791015624\n",
      "Epoch : 1605 train_loss : 23382.025268554688 Val loss:  37514.84769042969\n",
      "Epoch : 1606 train_loss : 23433.735009765624 Val loss:  37510.40528808594\n",
      "Epoch : 1607 train_loss : 23451.39470214844 Val loss:  37411.295239257815\n",
      "Epoch : 1608 train_loss : 23051.826318359374 Val loss:  37628.31982421875\n",
      "Epoch : 1609 train_loss : 23288.4228515625 Val loss:  37324.98868164063\n",
      "Epoch : 1610 train_loss : 23119.770776367186 Val loss:  37536.08697753906\n",
      "Epoch : 1611 train_loss : 23537.2615234375 Val loss:  37536.375483398435\n",
      "Epoch : 1612 train_loss : 23148.193481445312 Val loss:  37305.210625\n",
      "Epoch : 1613 train_loss : 23099.311889648438 Val loss:  37353.18698730469\n",
      "Epoch : 1614 train_loss : 23080.383544921875 Val loss:  37452.39469726563\n",
      "Epoch : 1615 train_loss : 23046.851977539063 Val loss:  37445.365078124996\n",
      "Epoch : 1616 train_loss : 23363.23371582031 Val loss:  37494.47716308593\n",
      "Epoch : 1617 train_loss : 23092.127587890624 Val loss:  37481.21931640625\n",
      "Epoch : 1618 train_loss : 23587.630029296874 Val loss:  37395.919155273434\n",
      "Epoch : 1619 train_loss : 23303.007763671874 Val loss:  37321.02310058594\n",
      "Epoch : 1620 train_loss : 23490.180883789064 Val loss:  37347.04890136719\n",
      "Epoch : 1621 train_loss : 23479.468969726564 Val loss:  37701.83170410156\n",
      "Epoch : 1622 train_loss : 23154.989892578124 Val loss:  37547.756103515625\n",
      "Epoch : 1623 train_loss : 23287.598779296874 Val loss:  37491.126230468755\n",
      "Epoch : 1624 train_loss : 23166.46110839844 Val loss:  37493.38907226563\n",
      "Epoch : 1625 train_loss : 23183.4455078125 Val loss:  37427.25836425781\n",
      "Epoch : 1626 train_loss : 23458.453857421875 Val loss:  37266.83921875\n",
      "Epoch : 1627 train_loss : 23313.246337890625 Val loss:  37492.44350585937\n",
      "Epoch : 1628 train_loss : 23466.60419921875 Val loss:  37435.839121093755\n",
      "Epoch : 1629 train_loss : 23593.574633789063 Val loss:  37399.43756347656\n",
      "Epoch : 1630 train_loss : 23754.667138671874 Val loss:  37437.182221679686\n",
      "Epoch : 1631 train_loss : 22913.02292480469 Val loss:  37379.91515625\n",
      "Epoch : 1632 train_loss : 23193.92353515625 Val loss:  37471.18574707031\n",
      "Epoch : 1633 train_loss : 23210.345092773438 Val loss:  37278.106137695315\n",
      "Epoch : 1634 train_loss : 23093.927587890626 Val loss:  37311.47544921875\n",
      "Epoch : 1635 train_loss : 23577.2892578125 Val loss:  37555.208012695315\n",
      "Epoch : 1636 train_loss : 23304.921118164064 Val loss:  37286.10790039062\n",
      "Epoch : 1637 train_loss : 23395.03935546875 Val loss:  37273.52750488281\n",
      "Epoch : 1638 train_loss : 23263.049438476562 Val loss:  37293.44219238281\n",
      "Epoch : 1639 train_loss : 23403.967651367188 Val loss:  37488.17217285156\n",
      "Epoch : 1640 train_loss : 23310.867749023437 Val loss:  37397.472548828126\n",
      "Epoch : 1641 train_loss : 23273.236059570314 Val loss:  37747.95737304688\n",
      "Epoch : 1642 train_loss : 23329.1990234375 Val loss:  37580.74695800782\n",
      "Epoch : 1643 train_loss : 23344.407836914062 Val loss:  37301.23766113281\n",
      "Epoch : 1644 train_loss : 23255.693090820314 Val loss:  37997.759545898436\n",
      "Epoch : 1645 train_loss : 23137.16484375 Val loss:  37536.71318359375\n",
      "Epoch : 1646 train_loss : 23231.66501464844 Val loss:  37304.81266113281\n",
      "Epoch : 1647 train_loss : 23313.3068359375 Val loss:  37475.390932617185\n",
      "Epoch : 1648 train_loss : 23597.331665039062 Val loss:  37647.15823730469\n",
      "Epoch : 1649 train_loss : 23599.003833007813 Val loss:  37532.94532226563\n",
      "Epoch : 1650 train_loss : 23207.400756835938 Val loss:  37623.27347167969\n",
      "Epoch : 1651 train_loss : 23253.867309570312 Val loss:  37359.759985351564\n",
      "Epoch : 1652 train_loss : 23078.842919921874 Val loss:  37484.75926269531\n",
      "Epoch : 1653 train_loss : 23444.451513671876 Val loss:  37488.592539062505\n",
      "Epoch : 1654 train_loss : 23281.679345703124 Val loss:  37373.39212890625\n",
      "Epoch : 1655 train_loss : 23416.74111328125 Val loss:  37451.48020996094\n",
      "Epoch : 1656 train_loss : 23044.494287109374 Val loss:  37361.145239257814\n",
      "Epoch : 1657 train_loss : 23143.178588867188 Val loss:  37294.6195703125\n",
      "Epoch : 1658 train_loss : 23344.78107910156 Val loss:  37362.963613281245\n",
      "Epoch : 1659 train_loss : 23222.558251953124 Val loss:  37494.67186035156\n",
      "Epoch : 1660 train_loss : 23236.190014648437 Val loss:  37291.775659179686\n",
      "Epoch : 1661 train_loss : 23206.947534179686 Val loss:  37444.41125488281\n",
      "Epoch : 1662 train_loss : 23246.8189453125 Val loss:  37350.99791992187\n",
      "Epoch : 1663 train_loss : 23222.809985351563 Val loss:  37577.8751171875\n",
      "Model replaced\n",
      "Epoch : 1664 train_loss : 23112.356713867186 Val loss:  37235.47122558594\n",
      "Epoch : 1665 train_loss : 23065.382421875 Val loss:  37554.378886718754\n",
      "Epoch : 1666 train_loss : 23254.724682617187 Val loss:  37561.40147949218\n",
      "Epoch : 1667 train_loss : 23048.38395996094 Val loss:  37338.69341308594\n",
      "Epoch : 1668 train_loss : 23285.9603515625 Val loss:  37308.93974121094\n",
      "Epoch : 1669 train_loss : 22969.140405273436 Val loss:  37399.6879296875\n",
      "Epoch : 1670 train_loss : 22909.7107421875 Val loss:  37386.237548828125\n",
      "Epoch : 1671 train_loss : 23115.37888183594 Val loss:  37540.681635742185\n",
      "Epoch : 1672 train_loss : 23556.42121582031 Val loss:  37446.946821289064\n",
      "Epoch : 1673 train_loss : 23215.696826171876 Val loss:  37362.802978515625\n",
      "Epoch : 1674 train_loss : 23536.256469726562 Val loss:  37456.64131347656\n",
      "Epoch : 1675 train_loss : 23241.284912109375 Val loss:  37516.748359375\n",
      "Epoch : 1676 train_loss : 23208.643969726563 Val loss:  37507.92907226562\n",
      "Epoch : 1677 train_loss : 23406.859155273436 Val loss:  37549.26263671875\n",
      "Epoch : 1678 train_loss : 22920.59719238281 Val loss:  37427.28486328125\n",
      "Epoch : 1679 train_loss : 23078.708276367186 Val loss:  37568.695493164065\n",
      "Epoch : 1680 train_loss : 23200.4138671875 Val loss:  37655.9867578125\n",
      "Epoch : 1681 train_loss : 23425.122509765624 Val loss:  37462.102568359376\n",
      "Epoch : 1682 train_loss : 23576.8447265625 Val loss:  37523.57456054688\n",
      "Epoch : 1683 train_loss : 23462.643408203126 Val loss:  37596.00814941406\n",
      "Model replaced\n",
      "Epoch : 1684 train_loss : 23185.73273925781 Val loss:  37208.24367675781\n",
      "Epoch : 1685 train_loss : 22959.19953613281 Val loss:  37351.708037109376\n",
      "Model replaced\n",
      "Epoch : 1686 train_loss : 23194.68161621094 Val loss:  37132.26812011719\n",
      "Epoch : 1687 train_loss : 23279.711499023437 Val loss:  37306.53695800781\n",
      "Epoch : 1688 train_loss : 23101.38330078125 Val loss:  37339.40379882812\n",
      "Epoch : 1689 train_loss : 23508.28505859375 Val loss:  37265.27464355469\n",
      "Epoch : 1690 train_loss : 23128.70810546875 Val loss:  37396.25835449219\n",
      "Epoch : 1691 train_loss : 23241.022680664064 Val loss:  37297.37071777343\n",
      "Epoch : 1692 train_loss : 23203.488671875 Val loss:  37472.95042480469\n",
      "Epoch : 1693 train_loss : 23163.78974609375 Val loss:  37481.4216796875\n",
      "Epoch : 1694 train_loss : 23093.195654296876 Val loss:  37376.48432617188\n",
      "Epoch : 1695 train_loss : 23154.016870117186 Val loss:  37197.51127929687\n",
      "Epoch : 1696 train_loss : 23026.431713867187 Val loss:  37405.826870117184\n",
      "Epoch : 1697 train_loss : 23155.808251953124 Val loss:  37691.08443359375\n",
      "Epoch : 1698 train_loss : 23373.59384765625 Val loss:  37288.05967285157\n",
      "Epoch : 1699 train_loss : 23197.763549804688 Val loss:  37504.941313476564\n",
      "Epoch : 1700 train_loss : 23253.18752441406 Val loss:  37641.1462890625\n",
      "Epoch : 1701 train_loss : 23351.991625976563 Val loss:  37427.858857421874\n",
      "Epoch : 1702 train_loss : 23340.137255859376 Val loss:  37310.87103027344\n",
      "Epoch : 1703 train_loss : 23195.893139648437 Val loss:  37666.938686523434\n",
      "Epoch : 1704 train_loss : 23462.80458984375 Val loss:  37832.83001953125\n",
      "Epoch : 1705 train_loss : 23188.575830078124 Val loss:  37442.85336425781\n",
      "Epoch : 1706 train_loss : 23008.26853027344 Val loss:  37473.09547363281\n",
      "Epoch : 1707 train_loss : 22976.95 Val loss:  37501.41291992187\n",
      "Epoch : 1708 train_loss : 23083.003149414064 Val loss:  37501.89154785156\n",
      "Epoch : 1709 train_loss : 23173.6876953125 Val loss:  37549.091689453126\n",
      "Epoch : 1710 train_loss : 23517.654907226562 Val loss:  37415.922807617186\n",
      "Epoch : 1711 train_loss : 23111.11721191406 Val loss:  37395.10262695312\n",
      "Epoch : 1712 train_loss : 23045.740966796875 Val loss:  37411.10859863281\n",
      "Epoch : 1713 train_loss : 23365.030859375 Val loss:  37344.70344726562\n",
      "Epoch : 1714 train_loss : 22765.83251953125 Val loss:  37321.088374023435\n",
      "Epoch : 1715 train_loss : 22681.710400390624 Val loss:  37569.17319335938\n",
      "Epoch : 1716 train_loss : 23240.03828125 Val loss:  37341.69963378906\n",
      "Epoch : 1717 train_loss : 22904.55710449219 Val loss:  37555.35205078125\n",
      "Epoch : 1718 train_loss : 23050.502026367187 Val loss:  37507.288193359374\n",
      "Epoch : 1719 train_loss : 23041.621875 Val loss:  37226.687592773436\n",
      "Epoch : 1720 train_loss : 23238.716455078124 Val loss:  37445.822197265625\n",
      "Model replaced\n",
      "Epoch : 1721 train_loss : 23018.212817382813 Val loss:  37027.3887524414\n",
      "Epoch : 1722 train_loss : 23381.108544921874 Val loss:  37432.20136230469\n",
      "Epoch : 1723 train_loss : 23011.34226074219 Val loss:  37430.10741210937\n",
      "Epoch : 1724 train_loss : 22973.6939453125 Val loss:  37291.29108886719\n",
      "Epoch : 1725 train_loss : 23229.72265625 Val loss:  37538.362998046876\n",
      "Epoch : 1726 train_loss : 23186.992749023437 Val loss:  37272.17897460937\n",
      "Epoch : 1727 train_loss : 23321.039916992188 Val loss:  37346.7737890625\n",
      "Epoch : 1728 train_loss : 23118.405981445314 Val loss:  37698.63359375\n",
      "Epoch : 1729 train_loss : 22981.105029296876 Val loss:  37358.14008300781\n",
      "Epoch : 1730 train_loss : 23210.57858886719 Val loss:  37411.45847167969\n",
      "Epoch : 1731 train_loss : 23211.1486328125 Val loss:  37275.958242187495\n",
      "Epoch : 1732 train_loss : 23148.317333984374 Val loss:  37375.150668945316\n",
      "Epoch : 1733 train_loss : 23379.673754882813 Val loss:  37304.78678710938\n",
      "Epoch : 1734 train_loss : 23298.25095214844 Val loss:  37379.6305078125\n",
      "Epoch : 1735 train_loss : 22779.067333984374 Val loss:  37340.349389648436\n",
      "Epoch : 1736 train_loss : 23228.287670898437 Val loss:  37383.94648925781\n",
      "Epoch : 1737 train_loss : 23115.256127929686 Val loss:  37385.98496582032\n",
      "Epoch : 1738 train_loss : 23052.78828125 Val loss:  37465.90228515625\n",
      "Epoch : 1739 train_loss : 23049.200122070313 Val loss:  37417.450405273434\n",
      "Epoch : 1740 train_loss : 22755.16276855469 Val loss:  37503.84245117188\n",
      "Epoch : 1741 train_loss : 23107.69089355469 Val loss:  37199.14674804687\n",
      "Epoch : 1742 train_loss : 23181.09323730469 Val loss:  37330.81171386719\n",
      "Epoch : 1743 train_loss : 23230.861181640626 Val loss:  37111.32269042969\n",
      "Epoch : 1744 train_loss : 23490.278198242188 Val loss:  37553.099604492185\n",
      "Epoch : 1745 train_loss : 23297.536743164062 Val loss:  37443.58330078125\n",
      "Epoch : 1746 train_loss : 23759.056274414062 Val loss:  37282.97577636719\n",
      "Epoch : 1747 train_loss : 23222.512890625 Val loss:  37392.56782226563\n",
      "Epoch : 1748 train_loss : 23226.184155273437 Val loss:  37558.74962402343\n",
      "Epoch : 1749 train_loss : 23519.26787109375 Val loss:  37598.43716308594\n",
      "Epoch : 1750 train_loss : 23291.99885253906 Val loss:  37463.43929199219\n",
      "Epoch : 1751 train_loss : 23463.558154296876 Val loss:  37567.42990234375\n",
      "Epoch : 1752 train_loss : 23129.218212890624 Val loss:  37463.22051269531\n",
      "Epoch : 1753 train_loss : 23015.22673339844 Val loss:  37248.543300781246\n",
      "Epoch : 1754 train_loss : 23250.428100585938 Val loss:  37269.180429687505\n",
      "Model replaced\n",
      "Epoch : 1755 train_loss : 23380.886962890625 Val loss:  36964.14505371094\n",
      "Epoch : 1756 train_loss : 23066.457788085936 Val loss:  37292.62227050781\n",
      "Epoch : 1757 train_loss : 22980.328759765624 Val loss:  37253.39831542969\n",
      "Epoch : 1758 train_loss : 23292.7041015625 Val loss:  37365.013076171876\n",
      "Epoch : 1759 train_loss : 23514.407446289064 Val loss:  37078.1926953125\n",
      "Epoch : 1760 train_loss : 23052.780615234376 Val loss:  37218.02666992188\n",
      "Epoch : 1761 train_loss : 23144.816455078126 Val loss:  37440.92954589844\n",
      "Epoch : 1762 train_loss : 23075.87971191406 Val loss:  37093.05177246094\n",
      "Epoch : 1763 train_loss : 23415.001806640626 Val loss:  37316.09153320313\n",
      "Epoch : 1764 train_loss : 23087.14306640625 Val loss:  37192.27741699219\n",
      "Epoch : 1765 train_loss : 23155.062353515626 Val loss:  37291.843671875\n",
      "Epoch : 1766 train_loss : 23482.385302734376 Val loss:  37382.81206054687\n",
      "Epoch : 1767 train_loss : 23273.013720703126 Val loss:  37399.60315429688\n",
      "Epoch : 1768 train_loss : 23100.137475585936 Val loss:  37225.78922363281\n",
      "Epoch : 1769 train_loss : 23391.12565917969 Val loss:  37294.260083007815\n",
      "Epoch : 1770 train_loss : 23203.63154296875 Val loss:  37353.77705078125\n",
      "Epoch : 1771 train_loss : 23020.572631835938 Val loss:  37064.88651855469\n",
      "Epoch : 1772 train_loss : 23285.388549804688 Val loss:  37302.278388671875\n",
      "Epoch : 1773 train_loss : 23290.51057128906 Val loss:  37192.75171386719\n",
      "Epoch : 1774 train_loss : 23151.984643554686 Val loss:  37191.322333984375\n",
      "Epoch : 1775 train_loss : 22948.429760742187 Val loss:  37164.61568359375\n",
      "Epoch : 1776 train_loss : 23129.09833984375 Val loss:  37104.28475097656\n",
      "Epoch : 1777 train_loss : 23043.791796875 Val loss:  37393.79406738281\n",
      "Epoch : 1778 train_loss : 23016.06005859375 Val loss:  37182.496513671875\n",
      "Epoch : 1779 train_loss : 23283.262426757814 Val loss:  37237.13123535157\n",
      "Epoch : 1780 train_loss : 23175.544506835937 Val loss:  37328.38158691406\n",
      "Epoch : 1781 train_loss : 22819.2103515625 Val loss:  37379.43879882812\n",
      "Epoch : 1782 train_loss : 23098.09748535156 Val loss:  37220.604799804685\n",
      "Epoch : 1783 train_loss : 23114.112939453124 Val loss:  37411.243559570314\n",
      "Epoch : 1784 train_loss : 23447.57990722656 Val loss:  37446.06258789062\n",
      "Epoch : 1785 train_loss : 23466.25065917969 Val loss:  37402.63051757812\n",
      "Epoch : 1786 train_loss : 23127.369091796874 Val loss:  37464.93713867188\n",
      "Epoch : 1787 train_loss : 23224.711791992188 Val loss:  37298.24161621094\n",
      "Epoch : 1788 train_loss : 23141.52119140625 Val loss:  37447.350629882814\n",
      "Epoch : 1789 train_loss : 23003.5375 Val loss:  37356.77366699219\n",
      "Epoch : 1790 train_loss : 23225.93603515625 Val loss:  37248.998979492186\n",
      "Epoch : 1791 train_loss : 23501.530810546876 Val loss:  37152.80088378907\n",
      "Epoch : 1792 train_loss : 23342.19221191406 Val loss:  37325.21267578125\n",
      "Epoch : 1793 train_loss : 23118.787744140624 Val loss:  37141.602607421875\n",
      "Epoch : 1794 train_loss : 23144.61589355469 Val loss:  37162.51216796875\n",
      "Epoch : 1795 train_loss : 22868.870361328125 Val loss:  37265.8309765625\n",
      "Epoch : 1796 train_loss : 23311.729638671874 Val loss:  37188.039833984374\n",
      "Epoch : 1797 train_loss : 23253.073388671874 Val loss:  37083.54080078125\n",
      "Epoch : 1798 train_loss : 23321.293383789063 Val loss:  37317.68609863281\n",
      "Epoch : 1799 train_loss : 23087.7486328125 Val loss:  37108.08375488281\n",
      "Epoch : 1800 train_loss : 23090.395458984374 Val loss:  37307.5928515625\n",
      "Epoch : 1801 train_loss : 23075.84538574219 Val loss:  37281.84959960937\n",
      "Epoch : 1802 train_loss : 23125.737084960936 Val loss:  37364.66881835937\n",
      "Epoch : 1803 train_loss : 23053.877294921876 Val loss:  37490.873364257815\n",
      "Epoch : 1804 train_loss : 23383.139770507812 Val loss:  37418.74182617188\n",
      "Epoch : 1805 train_loss : 22936.539819335936 Val loss:  37134.3832421875\n",
      "Epoch : 1806 train_loss : 22988.85068359375 Val loss:  37187.330122070314\n",
      "Model replaced\n",
      "Epoch : 1807 train_loss : 23271.41484375 Val loss:  36932.32276367188\n",
      "Epoch : 1808 train_loss : 23062.81904296875 Val loss:  37371.316313476564\n",
      "Epoch : 1809 train_loss : 22851.006689453126 Val loss:  37298.48079589844\n",
      "Epoch : 1810 train_loss : 23544.858203125 Val loss:  36960.822797851564\n",
      "Epoch : 1811 train_loss : 23257.36923828125 Val loss:  37413.69456054688\n",
      "Epoch : 1812 train_loss : 23360.91896972656 Val loss:  37228.86234375\n",
      "Epoch : 1813 train_loss : 22887.0640625 Val loss:  37274.45399902343\n",
      "Epoch : 1814 train_loss : 23419.853759765625 Val loss:  37106.124091796875\n",
      "Epoch : 1815 train_loss : 22755.6873046875 Val loss:  37344.986499023435\n",
      "Epoch : 1816 train_loss : 23019.059716796874 Val loss:  37630.965312500004\n",
      "Epoch : 1817 train_loss : 23120.25827636719 Val loss:  37469.69140625\n",
      "Epoch : 1818 train_loss : 22869.25712890625 Val loss:  37247.063046875\n",
      "Epoch : 1819 train_loss : 23336.428369140624 Val loss:  37353.67669921875\n",
      "Epoch : 1820 train_loss : 23168.236059570314 Val loss:  37136.924038085934\n",
      "Epoch : 1821 train_loss : 23117.15 Val loss:  37345.49114746094\n",
      "Epoch : 1822 train_loss : 23227.90676269531 Val loss:  37365.06727050782\n",
      "Epoch : 1823 train_loss : 23132.694458007812 Val loss:  37188.988124999996\n",
      "Epoch : 1824 train_loss : 23063.513549804688 Val loss:  37122.98257324219\n",
      "Epoch : 1825 train_loss : 23113.787646484376 Val loss:  37240.49010253906\n",
      "Epoch : 1826 train_loss : 23316.784790039062 Val loss:  37125.89747558594\n",
      "Epoch : 1827 train_loss : 22970.636669921874 Val loss:  37245.490566406246\n",
      "Epoch : 1828 train_loss : 23210.157763671876 Val loss:  37308.283232421876\n",
      "Epoch : 1829 train_loss : 22820.1662109375 Val loss:  37041.65275878906\n",
      "Model replaced\n",
      "Epoch : 1830 train_loss : 23066.892456054688 Val loss:  36851.183598632815\n",
      "Epoch : 1831 train_loss : 22821.594653320313 Val loss:  37195.628598632815\n",
      "Epoch : 1832 train_loss : 22891.015087890624 Val loss:  37171.612265625\n",
      "Epoch : 1833 train_loss : 23247.6916015625 Val loss:  37326.99866210938\n",
      "Epoch : 1834 train_loss : 23306.141357421875 Val loss:  37276.066850585936\n",
      "Epoch : 1835 train_loss : 23236.112719726563 Val loss:  37127.9130859375\n",
      "Epoch : 1836 train_loss : 22808.685498046874 Val loss:  37072.91551269531\n",
      "Epoch : 1837 train_loss : 23166.65920410156 Val loss:  37087.2637109375\n",
      "Epoch : 1838 train_loss : 22705.883666992188 Val loss:  37078.549833984376\n",
      "Epoch : 1839 train_loss : 22972.449169921874 Val loss:  37285.94287109375\n",
      "Epoch : 1840 train_loss : 22820.97312011719 Val loss:  36858.15546875\n",
      "Epoch : 1841 train_loss : 23184.496801757814 Val loss:  37283.59311523438\n",
      "Epoch : 1842 train_loss : 22936.965283203124 Val loss:  37134.44837402344\n",
      "Epoch : 1843 train_loss : 23032.15048828125 Val loss:  37308.78112792969\n",
      "Epoch : 1844 train_loss : 22843.78596191406 Val loss:  37146.02267578125\n",
      "Epoch : 1845 train_loss : 22921.48420410156 Val loss:  37093.198461914064\n",
      "Epoch : 1846 train_loss : 22918.573168945313 Val loss:  37049.69776367188\n",
      "Epoch : 1847 train_loss : 22947.76591796875 Val loss:  37204.55171875\n",
      "Epoch : 1848 train_loss : 22943.78984375 Val loss:  37105.33309570312\n",
      "Epoch : 1849 train_loss : 22878.455151367187 Val loss:  37337.55019042968\n",
      "Epoch : 1850 train_loss : 22814.07648925781 Val loss:  37002.412363281255\n",
      "Epoch : 1851 train_loss : 23008.656787109376 Val loss:  37105.155590820315\n",
      "Epoch : 1852 train_loss : 22957.05146484375 Val loss:  36978.94265625\n",
      "Epoch : 1853 train_loss : 23056.230126953124 Val loss:  37219.403500976565\n",
      "Epoch : 1854 train_loss : 22932.47512207031 Val loss:  37135.36827636718\n",
      "Epoch : 1855 train_loss : 23356.75615234375 Val loss:  36977.157646484375\n",
      "Epoch : 1856 train_loss : 23074.515063476563 Val loss:  37224.48446289062\n",
      "Epoch : 1857 train_loss : 23320.58889160156 Val loss:  37192.90366210938\n",
      "Epoch : 1858 train_loss : 23203.2990234375 Val loss:  37384.216791992185\n",
      "Epoch : 1859 train_loss : 22917.567919921876 Val loss:  37002.81138671875\n",
      "Epoch : 1860 train_loss : 23221.320727539063 Val loss:  37201.41731933594\n",
      "Epoch : 1861 train_loss : 23109.727099609376 Val loss:  37181.040283203125\n",
      "Epoch : 1862 train_loss : 23059.43166503906 Val loss:  37172.171879882815\n",
      "Epoch : 1863 train_loss : 23166.33591308594 Val loss:  37237.89330566406\n",
      "Epoch : 1864 train_loss : 23264.37763671875 Val loss:  37385.063017578126\n",
      "Epoch : 1865 train_loss : 23043.82907714844 Val loss:  37304.866030273435\n",
      "Epoch : 1866 train_loss : 22822.70927734375 Val loss:  37161.70570800781\n",
      "Epoch : 1867 train_loss : 23182.07548828125 Val loss:  37069.817451171875\n",
      "Epoch : 1868 train_loss : 22915.226489257813 Val loss:  37229.95931152344\n",
      "Epoch : 1869 train_loss : 22984.390014648438 Val loss:  37163.37929199218\n",
      "Epoch : 1870 train_loss : 23426.2095703125 Val loss:  37136.4512109375\n",
      "Epoch : 1871 train_loss : 23081.916015625 Val loss:  37187.931083984375\n",
      "Epoch : 1872 train_loss : 23003.105737304686 Val loss:  37156.118134765624\n",
      "Epoch : 1873 train_loss : 23055.485009765624 Val loss:  37248.45493652344\n",
      "Epoch : 1874 train_loss : 23303.272094726562 Val loss:  37108.64476074219\n",
      "Epoch : 1875 train_loss : 23421.516650390626 Val loss:  37059.65224121093\n",
      "Epoch : 1876 train_loss : 22924.532348632812 Val loss:  37180.03778808594\n",
      "Epoch : 1877 train_loss : 23118.875732421875 Val loss:  37103.3290234375\n",
      "Epoch : 1878 train_loss : 22969.032763671876 Val loss:  37229.15246582031\n",
      "Epoch : 1879 train_loss : 23060.868994140626 Val loss:  37369.35798339844\n",
      "Epoch : 1880 train_loss : 23062.79948730469 Val loss:  37291.345859375004\n",
      "Epoch : 1881 train_loss : 22826.582299804686 Val loss:  36989.33048339844\n",
      "Epoch : 1882 train_loss : 23428.495874023436 Val loss:  36977.3641796875\n",
      "Epoch : 1883 train_loss : 22694.827099609374 Val loss:  37229.238276367185\n",
      "Epoch : 1884 train_loss : 22936.040893554688 Val loss:  37127.240502929686\n",
      "Epoch : 1885 train_loss : 23037.73259277344 Val loss:  37287.779316406246\n",
      "Epoch : 1886 train_loss : 22909.38603515625 Val loss:  37085.75530761719\n",
      "Epoch : 1887 train_loss : 22629.235302734374 Val loss:  37211.59075683594\n",
      "Epoch : 1888 train_loss : 22920.20615234375 Val loss:  37359.905932617185\n",
      "Epoch : 1889 train_loss : 22535.25224609375 Val loss:  37416.75601074219\n",
      "Epoch : 1890 train_loss : 23137.730249023436 Val loss:  37264.115629882814\n",
      "Epoch : 1891 train_loss : 23082.73828125 Val loss:  37126.517670898436\n",
      "Epoch : 1892 train_loss : 23170.033813476562 Val loss:  37025.92552246094\n",
      "Epoch : 1893 train_loss : 23171.002197265625 Val loss:  37172.907070312496\n",
      "Epoch : 1894 train_loss : 23120.53857421875 Val loss:  36926.3007421875\n",
      "Epoch : 1895 train_loss : 23164.926342773437 Val loss:  37450.098139648435\n",
      "Epoch : 1896 train_loss : 23231.161694335937 Val loss:  37058.3534765625\n",
      "Epoch : 1897 train_loss : 22955.82600097656 Val loss:  37352.72155761719\n",
      "Epoch : 1898 train_loss : 22922.680126953124 Val loss:  37184.196020507814\n",
      "Epoch : 1899 train_loss : 23071.528173828126 Val loss:  37055.055283203124\n",
      "Epoch : 1900 train_loss : 22987.72067871094 Val loss:  37154.60922851563\n",
      "Epoch : 1901 train_loss : 23127.024633789064 Val loss:  36890.65385742187\n",
      "Epoch : 1902 train_loss : 23261.23879394531 Val loss:  37133.284902343745\n",
      "Epoch : 1903 train_loss : 22819.469775390626 Val loss:  36994.414331054686\n",
      "Epoch : 1904 train_loss : 23364.564697265625 Val loss:  36921.447436523435\n",
      "Epoch : 1905 train_loss : 23163.608764648438 Val loss:  37089.61876464843\n",
      "Epoch : 1906 train_loss : 23393.3654296875 Val loss:  37041.14326660156\n",
      "Epoch : 1907 train_loss : 23101.1625 Val loss:  37128.536928710935\n",
      "Epoch : 1908 train_loss : 23139.323095703126 Val loss:  37213.01379882813\n",
      "Epoch : 1909 train_loss : 23206.64045410156 Val loss:  37145.637363281254\n",
      "Epoch : 1910 train_loss : 23086.794970703126 Val loss:  37309.56974609375\n",
      "Epoch : 1911 train_loss : 23011.961157226564 Val loss:  37081.07798828125\n",
      "Epoch : 1912 train_loss : 23078.139111328124 Val loss:  36974.99586425781\n",
      "Epoch : 1913 train_loss : 23222.29521484375 Val loss:  37361.681860351564\n",
      "Epoch : 1914 train_loss : 23119.159252929687 Val loss:  37207.155966796876\n",
      "Epoch : 1915 train_loss : 23095.12216796875 Val loss:  37080.05094238281\n",
      "Epoch : 1916 train_loss : 22991.818115234375 Val loss:  37031.910864257814\n",
      "Epoch : 1917 train_loss : 22855.30095214844 Val loss:  37123.194853515626\n",
      "Epoch : 1918 train_loss : 23143.234252929688 Val loss:  37189.57485351562\n",
      "Epoch : 1919 train_loss : 23210.268017578124 Val loss:  37173.3108203125\n",
      "Epoch : 1920 train_loss : 22875.46162109375 Val loss:  37285.696596679685\n",
      "Epoch : 1921 train_loss : 23169.117749023437 Val loss:  37360.12887207031\n",
      "Epoch : 1922 train_loss : 23158.242919921875 Val loss:  37301.99142578125\n",
      "Epoch : 1923 train_loss : 22837.649682617186 Val loss:  37239.5983203125\n",
      "Epoch : 1924 train_loss : 22785.55517578125 Val loss:  37219.967929687504\n",
      "Epoch : 1925 train_loss : 23112.593823242187 Val loss:  37007.35985351562\n",
      "Epoch : 1926 train_loss : 23226.35612792969 Val loss:  37005.30278808594\n",
      "Epoch : 1927 train_loss : 22931.440380859374 Val loss:  37271.83479980469\n",
      "Epoch : 1928 train_loss : 23170.6189453125 Val loss:  37286.15319824219\n",
      "Epoch : 1929 train_loss : 22939.31875 Val loss:  37137.09486816406\n",
      "Epoch : 1930 train_loss : 22979.12041015625 Val loss:  37007.880859375\n",
      "Epoch : 1931 train_loss : 22587.666918945313 Val loss:  37320.97829101562\n",
      "Epoch : 1932 train_loss : 23053.465698242188 Val loss:  37088.2881640625\n",
      "Epoch : 1933 train_loss : 23053.224877929686 Val loss:  36870.28012207031\n",
      "Epoch : 1934 train_loss : 23079.13249511719 Val loss:  37253.5209375\n",
      "Epoch : 1935 train_loss : 22933.514868164064 Val loss:  37156.20130371094\n",
      "Epoch : 1936 train_loss : 22717.458081054687 Val loss:  36998.09923339843\n",
      "Epoch : 1937 train_loss : 23248.248486328124 Val loss:  37055.50807617187\n",
      "Model replaced\n",
      "Epoch : 1938 train_loss : 22779.280200195313 Val loss:  36829.8350390625\n",
      "Epoch : 1939 train_loss : 22978.802587890626 Val loss:  37104.4027734375\n",
      "Epoch : 1940 train_loss : 23304.88654785156 Val loss:  36920.85750976562\n",
      "Epoch : 1941 train_loss : 22900.461474609376 Val loss:  36877.471835937504\n",
      "Epoch : 1942 train_loss : 22701.3078125 Val loss:  37216.414453125\n",
      "Epoch : 1943 train_loss : 23072.8697265625 Val loss:  37079.79626953125\n",
      "Epoch : 1944 train_loss : 22933.542822265626 Val loss:  36931.63642578125\n",
      "Epoch : 1945 train_loss : 22932.73977050781 Val loss:  37452.974877929686\n",
      "Epoch : 1946 train_loss : 23066.29501953125 Val loss:  36862.181323242185\n",
      "Epoch : 1947 train_loss : 22795.7630859375 Val loss:  37020.62071777343\n",
      "Epoch : 1948 train_loss : 23185.543383789063 Val loss:  37041.01103515625\n",
      "Epoch : 1949 train_loss : 22772.55732421875 Val loss:  36963.941225585935\n",
      "Epoch : 1950 train_loss : 23024.49411621094 Val loss:  37095.22829101562\n",
      "Epoch : 1951 train_loss : 22815.344287109376 Val loss:  37294.47102539062\n",
      "Epoch : 1952 train_loss : 22842.106518554687 Val loss:  37203.373706054685\n",
      "Epoch : 1953 train_loss : 22785.51008300781 Val loss:  37124.22689941406\n",
      "Epoch : 1954 train_loss : 23318.8630859375 Val loss:  37060.65003417969\n",
      "Epoch : 1955 train_loss : 22764.628637695314 Val loss:  36992.712070312504\n",
      "Epoch : 1956 train_loss : 22501.66618652344 Val loss:  37039.22730957031\n",
      "Epoch : 1957 train_loss : 22928.171801757813 Val loss:  37131.03140136719\n",
      "Epoch : 1958 train_loss : 23323.681372070314 Val loss:  37037.19025390625\n",
      "Epoch : 1959 train_loss : 22722.808227539062 Val loss:  37463.284335937504\n",
      "Epoch : 1960 train_loss : 22921.093798828126 Val loss:  37000.36948242188\n",
      "Epoch : 1961 train_loss : 22915.433715820312 Val loss:  37205.70004882813\n",
      "Epoch : 1962 train_loss : 23038.911328125 Val loss:  37250.827368164064\n",
      "Epoch : 1963 train_loss : 22809.934619140626 Val loss:  37110.579482421876\n",
      "Epoch : 1964 train_loss : 22910.04035644531 Val loss:  37039.49913574218\n",
      "Epoch : 1965 train_loss : 22706.098071289063 Val loss:  37345.326567382814\n",
      "Epoch : 1966 train_loss : 23113.194970703124 Val loss:  36849.75424804688\n",
      "Epoch : 1967 train_loss : 22915.20720214844 Val loss:  36948.214150390624\n",
      "Model replaced\n",
      "Epoch : 1968 train_loss : 22835.895849609376 Val loss:  36813.568354492185\n",
      "Epoch : 1969 train_loss : 23075.211669921875 Val loss:  37052.98158691406\n",
      "Epoch : 1970 train_loss : 22767.430249023437 Val loss:  37281.06896484375\n",
      "Epoch : 1971 train_loss : 23029.275146484375 Val loss:  37249.29500976562\n",
      "Epoch : 1972 train_loss : 22796.00546875 Val loss:  36977.723125000004\n",
      "Epoch : 1973 train_loss : 22828.305786132812 Val loss:  37014.110629882816\n",
      "Epoch : 1974 train_loss : 22840.65947265625 Val loss:  36963.11734863281\n",
      "Epoch : 1975 train_loss : 23022.6767578125 Val loss:  37315.100629882814\n",
      "Epoch : 1976 train_loss : 23024.35886230469 Val loss:  37257.508022460934\n",
      "Epoch : 1977 train_loss : 22710.58610839844 Val loss:  37094.03551269531\n",
      "Epoch : 1978 train_loss : 22905.982055664062 Val loss:  37080.30455566406\n",
      "Epoch : 1979 train_loss : 22756.700927734375 Val loss:  36903.48500976562\n",
      "Epoch : 1980 train_loss : 22819.61591796875 Val loss:  36968.159462890624\n",
      "Epoch : 1981 train_loss : 22832.220068359376 Val loss:  37238.293613281254\n",
      "Epoch : 1982 train_loss : 22708.91513671875 Val loss:  37022.83846679687\n",
      "Epoch : 1983 train_loss : 23029.386938476564 Val loss:  37012.405205078125\n",
      "Epoch : 1984 train_loss : 22948.33347167969 Val loss:  37095.701816406254\n",
      "Epoch : 1985 train_loss : 22918.93879394531 Val loss:  37158.63922363281\n",
      "Epoch : 1986 train_loss : 22889.113403320312 Val loss:  37079.558413085935\n",
      "Epoch : 1987 train_loss : 22853.017919921876 Val loss:  37256.762026367185\n",
      "Epoch : 1988 train_loss : 22674.807885742186 Val loss:  37000.568613281255\n",
      "Epoch : 1989 train_loss : 22880.253295898438 Val loss:  37086.701479492185\n",
      "Epoch : 1990 train_loss : 23184.20400390625 Val loss:  36948.8134765625\n",
      "Epoch : 1991 train_loss : 22954.268994140624 Val loss:  36874.666298828124\n",
      "Epoch : 1992 train_loss : 22784.841796875 Val loss:  37121.06689453125\n",
      "Epoch : 1993 train_loss : 22787.203735351562 Val loss:  37044.68711425782\n",
      "Epoch : 1994 train_loss : 22861.930590820313 Val loss:  36890.25137695313\n",
      "Epoch : 1995 train_loss : 22679.161499023438 Val loss:  37009.99848144531\n",
      "Epoch : 1996 train_loss : 23120.119213867187 Val loss:  36863.019921875\n",
      "Epoch : 1997 train_loss : 22951.197021484375 Val loss:  36977.74570800782\n",
      "Epoch : 1998 train_loss : 22848.29609375 Val loss:  37120.51766601562\n",
      "Epoch : 1999 train_loss : 22909.14169921875 Val loss:  37102.83668457031\n"
     ]
    }
   ],
   "source": [
    "#print(model)\n",
    "epochs = 2000\n",
    "total_epochs+=epochs\n",
    "\n",
    "model.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss_1 = 0\n",
    "    val_loss_sum = 0\n",
    "    \n",
    "    for i in range(len(train_batch)):\n",
    "        \n",
    "        output = model(train_batch[i])\n",
    "        loss = criterion(output, label_batch[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for j in range(len(val_batch)):\n",
    "                \n",
    "                val_output = model(val_batch[j])\n",
    "                val_loss =  criterion(val_output, val_label_batch[j])\n",
    "                val_loss_1+=val_loss.item()\n",
    "        val_loss_sum=val_loss_1/len(val_batch)\n",
    "        \n",
    "    # saving best model\n",
    "    val_loss_divided = val_loss_sum/len(val_batch)\n",
    "    if best_val_loss is None or val_loss_divided < best_val_loss:\n",
    "        print('Model replaced')\n",
    "        best_val_loss = val_loss_divided\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(\"Epoch :\", e, \"train_loss :\", train_loss/len(train_batch), \"Val loss: \", val_loss_divided)    \n",
    "    val_losses.append(val_loss_divided)    \n",
    "    train_losses.append(train_loss/len(train_batch))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc4c10a-dd76-40ac-8ab0-3b6021a86f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cdc2e9df40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frm=10 # does not \n",
    "plt.plot(train_losses[frm:], label='Training loss')\n",
    "plt.plot(val_losses[frm:], label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093fa5ae-5313-47be-a636-036d92d21e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# correct=0\n",
    "# i=0\n",
    "# res=[]\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_batch :\n",
    "#         for j in range(len(batch)):\n",
    "#             x = model(batch[j])\n",
    "#             #print(round(x.item()))\n",
    "#             res.append(round(x.item()))\n",
    "\n",
    "# true_labels= list(test[\"cnt\"])\n",
    "\n",
    "# for i in range(len(res)):\n",
    "#     if res[i]==int(true_labels[i]):\n",
    "#         correct+=1\n",
    "        \n",
    "# print(\"Accuracy:\", 100*(correct/len(res)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcd68f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dfa8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "325\n",
      "325\n",
      "\n",
      "325\n",
      "650\n",
      "\n",
      "325\n",
      "975\n",
      "\n",
      "325\n",
      "1300\n",
      "\n",
      "325\n",
      "1625\n",
      "\n",
      "325\n",
      "1950\n",
      "\n",
      "325\n",
      "2275\n",
      "\n",
      "325\n",
      "2600\n",
      "\n",
      "325\n",
      "2925\n",
      "\n",
      "325\n",
      "3250\n",
      "\n",
      "325\n",
      "3575\n",
      "\n",
      "325\n",
      "3900\n",
      "\n",
      "325\n",
      "4225\n",
      "\n",
      "324\n",
      "4549\n",
      "\n",
      "324\n",
      "4873\n",
      "\n",
      "324\n",
      "5197\n",
      "\n",
      "324\n",
      "5521\n",
      "\n",
      "324\n",
      "5845\n",
      "\n",
      "324\n",
      "6169\n",
      "\n",
      "324\n",
      "6493\n"
     ]
    }
   ],
   "source": [
    "test_outputs = []\n",
    "for j in range(len(test_batch)):\n",
    "    print()\n",
    "    test_output = model(test_batch[j])\n",
    "    print(len(test_output.unsqueeze(dim=1)))\n",
    "    for value in test_output:\n",
    "        test_outputs.append(value)\n",
    "    print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6110904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b330534c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([90.8901], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.2021], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.3647], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.9300], grad_fn=<UnbindBackward0>),\n",
       " tensor([32.5785], grad_fn=<UnbindBackward0>),\n",
       " tensor([71.5987], grad_fn=<UnbindBackward0>),\n",
       " tensor([54.2160], grad_fn=<UnbindBackward0>),\n",
       " tensor([94.7721], grad_fn=<UnbindBackward0>),\n",
       " tensor([107.0843], grad_fn=<UnbindBackward0>),\n",
       " tensor([97.0038], grad_fn=<UnbindBackward0>),\n",
       " tensor([173.6839], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.6544], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.5834], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.4189], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.6580], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.3485], grad_fn=<UnbindBackward0>),\n",
       " tensor([22.9464], grad_fn=<UnbindBackward0>),\n",
       " tensor([138.3977], grad_fn=<UnbindBackward0>),\n",
       " tensor([196.2789], grad_fn=<UnbindBackward0>),\n",
       " tensor([97.9635], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.6938], grad_fn=<UnbindBackward0>),\n",
       " tensor([206.0084], grad_fn=<UnbindBackward0>),\n",
       " tensor([172.8056], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.9038], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.1330], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.6562], grad_fn=<UnbindBackward0>),\n",
       " tensor([6.9995], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.7278], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.0627], grad_fn=<UnbindBackward0>),\n",
       " tensor([36.2574], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.4489], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.3421], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.9149], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.0891], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.7146], grad_fn=<UnbindBackward0>),\n",
       " tensor([56.9916], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.0873], grad_fn=<UnbindBackward0>),\n",
       " tensor([202.1279], grad_fn=<UnbindBackward0>),\n",
       " tensor([140.7351], grad_fn=<UnbindBackward0>),\n",
       " tensor([90.1973], grad_fn=<UnbindBackward0>),\n",
       " tensor([149.4274], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.1591], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.8579], grad_fn=<UnbindBackward0>),\n",
       " tensor([93.3121], grad_fn=<UnbindBackward0>),\n",
       " tensor([120.8748], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.1357], grad_fn=<UnbindBackward0>),\n",
       " tensor([69.2996], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.6574], grad_fn=<UnbindBackward0>),\n",
       " tensor([71.1524], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.8557], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.1395], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.8997], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.6132], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.8491], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.2016], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.4541], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.7620], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.0360], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.2426], grad_fn=<UnbindBackward0>),\n",
       " tensor([114.4477], grad_fn=<UnbindBackward0>),\n",
       " tensor([168.2441], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.6833], grad_fn=<UnbindBackward0>),\n",
       " tensor([175.0276], grad_fn=<UnbindBackward0>),\n",
       " tensor([69.4815], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.7883], grad_fn=<UnbindBackward0>),\n",
       " tensor([103.5727], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.4528], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.6611], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.2376], grad_fn=<UnbindBackward0>),\n",
       " tensor([130.7820], grad_fn=<UnbindBackward0>),\n",
       " tensor([294.5571], grad_fn=<UnbindBackward0>),\n",
       " tensor([21.4977], grad_fn=<UnbindBackward0>),\n",
       " tensor([0.], grad_fn=<UnbindBackward0>),\n",
       " tensor([12.6177], grad_fn=<UnbindBackward0>),\n",
       " tensor([54.1229], grad_fn=<UnbindBackward0>),\n",
       " tensor([12.3342], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.7404], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.6095], grad_fn=<UnbindBackward0>),\n",
       " tensor([26.9469], grad_fn=<UnbindBackward0>),\n",
       " tensor([87.9823], grad_fn=<UnbindBackward0>),\n",
       " tensor([126.5061], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.4256], grad_fn=<UnbindBackward0>),\n",
       " tensor([23.6075], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.7807], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.0868], grad_fn=<UnbindBackward0>),\n",
       " tensor([140.9392], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.8378], grad_fn=<UnbindBackward0>),\n",
       " tensor([102.1422], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.5643], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.0275], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.7427], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.1709], grad_fn=<UnbindBackward0>),\n",
       " tensor([131.9712], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.3583], grad_fn=<UnbindBackward0>),\n",
       " tensor([56.3817], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.2394], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.7913], grad_fn=<UnbindBackward0>),\n",
       " tensor([23.6676], grad_fn=<UnbindBackward0>),\n",
       " tensor([30.0211], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.3991], grad_fn=<UnbindBackward0>),\n",
       " tensor([32.7688], grad_fn=<UnbindBackward0>),\n",
       " tensor([77.9177], grad_fn=<UnbindBackward0>),\n",
       " tensor([69.8445], grad_fn=<UnbindBackward0>),\n",
       " tensor([71.0156], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.7522], grad_fn=<UnbindBackward0>),\n",
       " tensor([114.1851], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.3505], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.9881], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.1034], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.9880], grad_fn=<UnbindBackward0>),\n",
       " tensor([70.7314], grad_fn=<UnbindBackward0>),\n",
       " tensor([149.8236], grad_fn=<UnbindBackward0>),\n",
       " tensor([117.5512], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.2813], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.8373], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.8646], grad_fn=<UnbindBackward0>),\n",
       " tensor([38.1090], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.3888], grad_fn=<UnbindBackward0>),\n",
       " tensor([39.7800], grad_fn=<UnbindBackward0>),\n",
       " tensor([13.5344], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.4168], grad_fn=<UnbindBackward0>),\n",
       " tensor([44.6989], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.4802], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.3008], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.0212], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.6738], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.3105], grad_fn=<UnbindBackward0>),\n",
       " tensor([124.3378], grad_fn=<UnbindBackward0>),\n",
       " tensor([104.1085], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.8424], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.2794], grad_fn=<UnbindBackward0>),\n",
       " tensor([177.1488], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.0138], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.6928], grad_fn=<UnbindBackward0>),\n",
       " tensor([212.1886], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.7537], grad_fn=<UnbindBackward0>),\n",
       " tensor([168.4516], grad_fn=<UnbindBackward0>),\n",
       " tensor([70.3833], grad_fn=<UnbindBackward0>),\n",
       " tensor([166.9333], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.0131], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.2777], grad_fn=<UnbindBackward0>),\n",
       " tensor([8.6339], grad_fn=<UnbindBackward0>),\n",
       " tensor([39.4125], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.9739], grad_fn=<UnbindBackward0>),\n",
       " tensor([69.4286], grad_fn=<UnbindBackward0>),\n",
       " tensor([20.7752], grad_fn=<UnbindBackward0>),\n",
       " tensor([1.4924], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.0883], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.1736], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.9532], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.8689], grad_fn=<UnbindBackward0>),\n",
       " tensor([34.2594], grad_fn=<UnbindBackward0>),\n",
       " tensor([31.9440], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.1314], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.9408], grad_fn=<UnbindBackward0>),\n",
       " tensor([168.9394], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.7208], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.2334], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.5484], grad_fn=<UnbindBackward0>),\n",
       " tensor([185.2612], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.6021], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.9711], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.1864], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.3721], grad_fn=<UnbindBackward0>),\n",
       " tensor([78.6270], grad_fn=<UnbindBackward0>),\n",
       " tensor([5.2016], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.1258], grad_fn=<UnbindBackward0>),\n",
       " tensor([6.1373], grad_fn=<UnbindBackward0>),\n",
       " tensor([35.6117], grad_fn=<UnbindBackward0>),\n",
       " tensor([52.2253], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.5035], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.8680], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.9611], grad_fn=<UnbindBackward0>),\n",
       " tensor([48.6476], grad_fn=<UnbindBackward0>),\n",
       " tensor([24.9868], grad_fn=<UnbindBackward0>),\n",
       " tensor([56.4447], grad_fn=<UnbindBackward0>),\n",
       " tensor([30.9884], grad_fn=<UnbindBackward0>),\n",
       " tensor([48.1057], grad_fn=<UnbindBackward0>),\n",
       " tensor([64.5186], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.5890], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.1933], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.0990], grad_fn=<UnbindBackward0>),\n",
       " tensor([108.8428], grad_fn=<UnbindBackward0>),\n",
       " tensor([235.3599], grad_fn=<UnbindBackward0>),\n",
       " tensor([178.4240], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.8816], grad_fn=<UnbindBackward0>),\n",
       " tensor([236.7974], grad_fn=<UnbindBackward0>),\n",
       " tensor([83.9809], grad_fn=<UnbindBackward0>),\n",
       " tensor([20.9852], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.3515], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.9963], grad_fn=<UnbindBackward0>),\n",
       " tensor([10.2129], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.6380], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.6443], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.7839], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.6885], grad_fn=<UnbindBackward0>),\n",
       " tensor([77.4704], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.3847], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.7332], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.7170], grad_fn=<UnbindBackward0>),\n",
       " tensor([72.7247], grad_fn=<UnbindBackward0>),\n",
       " tensor([139.2133], grad_fn=<UnbindBackward0>),\n",
       " tensor([64.6877], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.0003], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.8857], grad_fn=<UnbindBackward0>),\n",
       " tensor([89.9230], grad_fn=<UnbindBackward0>),\n",
       " tensor([100.4504], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.6760], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.3637], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.8617], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.1983], grad_fn=<UnbindBackward0>),\n",
       " tensor([29.6642], grad_fn=<UnbindBackward0>),\n",
       " tensor([35.3410], grad_fn=<UnbindBackward0>),\n",
       " tensor([12.8537], grad_fn=<UnbindBackward0>),\n",
       " tensor([0.], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.0020], grad_fn=<UnbindBackward0>),\n",
       " tensor([23.7536], grad_fn=<UnbindBackward0>),\n",
       " tensor([24.2070], grad_fn=<UnbindBackward0>),\n",
       " tensor([31.6207], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.3523], grad_fn=<UnbindBackward0>),\n",
       " tensor([77.9709], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.3580], grad_fn=<UnbindBackward0>),\n",
       " tensor([36.7979], grad_fn=<UnbindBackward0>),\n",
       " tensor([157.2090], grad_fn=<UnbindBackward0>),\n",
       " tensor([41.9825], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.7571], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.7749], grad_fn=<UnbindBackward0>),\n",
       " tensor([178.1998], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.4944], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.1241], grad_fn=<UnbindBackward0>),\n",
       " tensor([243.0632], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.5032], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.6100], grad_fn=<UnbindBackward0>),\n",
       " tensor([114.1666], grad_fn=<UnbindBackward0>),\n",
       " tensor([25.0197], grad_fn=<UnbindBackward0>),\n",
       " tensor([26.5622], grad_fn=<UnbindBackward0>),\n",
       " tensor([26.6546], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.0631], grad_fn=<UnbindBackward0>),\n",
       " tensor([37.9365], grad_fn=<UnbindBackward0>),\n",
       " tensor([52.0795], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.4917], grad_fn=<UnbindBackward0>),\n",
       " tensor([56.3154], grad_fn=<UnbindBackward0>),\n",
       " tensor([77.9407], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.8070], grad_fn=<UnbindBackward0>),\n",
       " tensor([26.8833], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.0306], grad_fn=<UnbindBackward0>),\n",
       " tensor([25.1015], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.0068], grad_fn=<UnbindBackward0>),\n",
       " tensor([94.2815], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.3592], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.2784], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.8976], grad_fn=<UnbindBackward0>),\n",
       " tensor([93.8029], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.4514], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.2781], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.6141], grad_fn=<UnbindBackward0>),\n",
       " tensor([102.1895], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.1644], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.6591], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.1843], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.8333], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.1635], grad_fn=<UnbindBackward0>),\n",
       " tensor([87.0108], grad_fn=<UnbindBackward0>),\n",
       " tensor([39.1751], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.8782], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.1752], grad_fn=<UnbindBackward0>),\n",
       " tensor([107.4437], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.9469], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.0977], grad_fn=<UnbindBackward0>),\n",
       " tensor([86.0942], grad_fn=<UnbindBackward0>),\n",
       " tensor([144.1972], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.8736], grad_fn=<UnbindBackward0>),\n",
       " tensor([188.6119], grad_fn=<UnbindBackward0>),\n",
       " tensor([172.1765], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.6610], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.2034], grad_fn=<UnbindBackward0>),\n",
       " tensor([130.5885], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.9336], grad_fn=<UnbindBackward0>),\n",
       " tensor([129.3194], grad_fn=<UnbindBackward0>),\n",
       " tensor([197.9087], grad_fn=<UnbindBackward0>),\n",
       " tensor([83.6838], grad_fn=<UnbindBackward0>),\n",
       " tensor([2.0186], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.8646], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.0528], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.6846], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.4634], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.2101], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.9817], grad_fn=<UnbindBackward0>),\n",
       " tensor([95.0530], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.1657], grad_fn=<UnbindBackward0>),\n",
       " tensor([139.7063], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.4919], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.1150], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.1092], grad_fn=<UnbindBackward0>),\n",
       " tensor([86.4466], grad_fn=<UnbindBackward0>),\n",
       " tensor([95.0094], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.2279], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.1775], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.3210], grad_fn=<UnbindBackward0>),\n",
       " tensor([213.4545], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.4687], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.8648], grad_fn=<UnbindBackward0>),\n",
       " tensor([141.6552], grad_fn=<UnbindBackward0>),\n",
       " tensor([93.2465], grad_fn=<UnbindBackward0>),\n",
       " tensor([26.5377], grad_fn=<UnbindBackward0>),\n",
       " tensor([19.8924], grad_fn=<UnbindBackward0>),\n",
       " tensor([37.7027], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.2377], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.6589], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.9609], grad_fn=<UnbindBackward0>),\n",
       " tensor([64.7695], grad_fn=<UnbindBackward0>),\n",
       " tensor([108.6770], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.3781], grad_fn=<UnbindBackward0>),\n",
       " tensor([180.8546], grad_fn=<UnbindBackward0>),\n",
       " tensor([150.5470], grad_fn=<UnbindBackward0>),\n",
       " tensor([90.1118], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.7520], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.0489], grad_fn=<UnbindBackward0>),\n",
       " tensor([256.1227], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.2929], grad_fn=<UnbindBackward0>),\n",
       " tensor([190.2136], grad_fn=<UnbindBackward0>),\n",
       " tensor([135.6671], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.0315], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.3847], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.3935], grad_fn=<UnbindBackward0>),\n",
       " tensor([36.2866], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.5363], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.3478], grad_fn=<UnbindBackward0>),\n",
       " tensor([33.2106], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.0745], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.6383], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.6050], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.5667], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.3299], grad_fn=<UnbindBackward0>),\n",
       " tensor([149.6704], grad_fn=<UnbindBackward0>),\n",
       " tensor([70.5654], grad_fn=<UnbindBackward0>),\n",
       " tensor([193.9245], grad_fn=<UnbindBackward0>),\n",
       " tensor([130.7973], grad_fn=<UnbindBackward0>),\n",
       " tensor([165.4543], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.8472], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.5115], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.7472], grad_fn=<UnbindBackward0>),\n",
       " tensor([24.1956], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.3104], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.4595], grad_fn=<UnbindBackward0>),\n",
       " tensor([5.7774], grad_fn=<UnbindBackward0>),\n",
       " tensor([21.7111], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.9172], grad_fn=<UnbindBackward0>),\n",
       " tensor([41.0501], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.1448], grad_fn=<UnbindBackward0>),\n",
       " tensor([87.5887], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.8005], grad_fn=<UnbindBackward0>),\n",
       " tensor([48.4327], grad_fn=<UnbindBackward0>),\n",
       " tensor([65.7948], grad_fn=<UnbindBackward0>),\n",
       " tensor([165.1645], grad_fn=<UnbindBackward0>),\n",
       " tensor([131.7793], grad_fn=<UnbindBackward0>),\n",
       " tensor([200.0659], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.3631], grad_fn=<UnbindBackward0>),\n",
       " tensor([152.3160], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.6444], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.8364], grad_fn=<UnbindBackward0>),\n",
       " tensor([225.1992], grad_fn=<UnbindBackward0>),\n",
       " tensor([202.8418], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.9386], grad_fn=<UnbindBackward0>),\n",
       " tensor([119.1154], grad_fn=<UnbindBackward0>),\n",
       " tensor([181.9302], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.8704], grad_fn=<UnbindBackward0>),\n",
       " tensor([191.3489], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.6429], grad_fn=<UnbindBackward0>),\n",
       " tensor([10.2816], grad_fn=<UnbindBackward0>),\n",
       " tensor([14.4911], grad_fn=<UnbindBackward0>),\n",
       " tensor([54.4393], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.4967], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.8024], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.2692], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.7230], grad_fn=<UnbindBackward0>),\n",
       " tensor([33.6688], grad_fn=<UnbindBackward0>),\n",
       " tensor([101.0858], grad_fn=<UnbindBackward0>),\n",
       " tensor([172.5451], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.5278], grad_fn=<UnbindBackward0>),\n",
       " tensor([144.4910], grad_fn=<UnbindBackward0>),\n",
       " tensor([172.8190], grad_fn=<UnbindBackward0>),\n",
       " tensor([203.5986], grad_fn=<UnbindBackward0>),\n",
       " tensor([172.2703], grad_fn=<UnbindBackward0>),\n",
       " tensor([144.3173], grad_fn=<UnbindBackward0>),\n",
       " tensor([220.7873], grad_fn=<UnbindBackward0>),\n",
       " tensor([97.1144], grad_fn=<UnbindBackward0>),\n",
       " tensor([216.9954], grad_fn=<UnbindBackward0>),\n",
       " tensor([54.5279], grad_fn=<UnbindBackward0>),\n",
       " tensor([236.3561], grad_fn=<UnbindBackward0>),\n",
       " tensor([161.0728], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.8890], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.3289], grad_fn=<UnbindBackward0>),\n",
       " tensor([72.1435], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.3903], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.4239], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.7359], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.7927], grad_fn=<UnbindBackward0>),\n",
       " tensor([90.3594], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.3663], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.7211], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.3730], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.4770], grad_fn=<UnbindBackward0>),\n",
       " tensor([129.8374], grad_fn=<UnbindBackward0>),\n",
       " tensor([143.4406], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.0448], grad_fn=<UnbindBackward0>),\n",
       " tensor([142.1013], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.1747], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.5974], grad_fn=<UnbindBackward0>),\n",
       " tensor([146.7470], grad_fn=<UnbindBackward0>),\n",
       " tensor([204.3468], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.3404], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.3957], grad_fn=<UnbindBackward0>),\n",
       " tensor([119.4937], grad_fn=<UnbindBackward0>),\n",
       " tensor([160.4281], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.9806], grad_fn=<UnbindBackward0>),\n",
       " tensor([23.0831], grad_fn=<UnbindBackward0>),\n",
       " tensor([0.], grad_fn=<UnbindBackward0>),\n",
       " tensor([22.7220], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.6719], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.8304], grad_fn=<UnbindBackward0>),\n",
       " tensor([89.3629], grad_fn=<UnbindBackward0>),\n",
       " tensor([117.1479], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.7023], grad_fn=<UnbindBackward0>),\n",
       " tensor([38.8656], grad_fn=<UnbindBackward0>),\n",
       " tensor([101.1709], grad_fn=<UnbindBackward0>),\n",
       " tensor([152.3788], grad_fn=<UnbindBackward0>),\n",
       " tensor([185.3086], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.1773], grad_fn=<UnbindBackward0>),\n",
       " tensor([156.8431], grad_fn=<UnbindBackward0>),\n",
       " tensor([168.6145], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.6369], grad_fn=<UnbindBackward0>),\n",
       " tensor([261.6451], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.3343], grad_fn=<UnbindBackward0>),\n",
       " tensor([230.2178], grad_fn=<UnbindBackward0>),\n",
       " tensor([260.1410], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.4808], grad_fn=<UnbindBackward0>),\n",
       " tensor([247.4825], grad_fn=<UnbindBackward0>),\n",
       " tensor([39.9087], grad_fn=<UnbindBackward0>),\n",
       " tensor([0.], grad_fn=<UnbindBackward0>),\n",
       " tensor([9.8139], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.9059], grad_fn=<UnbindBackward0>),\n",
       " tensor([41.3053], grad_fn=<UnbindBackward0>),\n",
       " tensor([64.7167], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.5276], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.9896], grad_fn=<UnbindBackward0>),\n",
       " tensor([153.4864], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.8474], grad_fn=<UnbindBackward0>),\n",
       " tensor([148.5131], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.7022], grad_fn=<UnbindBackward0>),\n",
       " tensor([140.4129], grad_fn=<UnbindBackward0>),\n",
       " tensor([236.0948], grad_fn=<UnbindBackward0>),\n",
       " tensor([97.2937], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.9648], grad_fn=<UnbindBackward0>),\n",
       " tensor([199.8902], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.0861], grad_fn=<UnbindBackward0>),\n",
       " tensor([212.5098], grad_fn=<UnbindBackward0>),\n",
       " tensor([135.6795], grad_fn=<UnbindBackward0>),\n",
       " tensor([68.8960], grad_fn=<UnbindBackward0>),\n",
       " tensor([167.2678], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.1991], grad_fn=<UnbindBackward0>),\n",
       " tensor([52.6403], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.8431], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.2910], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.5091], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.8453], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.3473], grad_fn=<UnbindBackward0>),\n",
       " tensor([100.6633], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.3308], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.5676], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.7005], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.4454], grad_fn=<UnbindBackward0>),\n",
       " tensor([93.6205], grad_fn=<UnbindBackward0>),\n",
       " tensor([182.6690], grad_fn=<UnbindBackward0>),\n",
       " tensor([124.9308], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.9150], grad_fn=<UnbindBackward0>),\n",
       " tensor([175.6160], grad_fn=<UnbindBackward0>),\n",
       " tensor([261.5100], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.3170], grad_fn=<UnbindBackward0>),\n",
       " tensor([217.7249], grad_fn=<UnbindBackward0>),\n",
       " tensor([197.9100], grad_fn=<UnbindBackward0>),\n",
       " tensor([247.3982], grad_fn=<UnbindBackward0>),\n",
       " tensor([72.7873], grad_fn=<UnbindBackward0>),\n",
       " tensor([108.9330], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.9200], grad_fn=<UnbindBackward0>),\n",
       " tensor([61.7118], grad_fn=<UnbindBackward0>),\n",
       " tensor([44.2157], grad_fn=<UnbindBackward0>),\n",
       " tensor([61.6566], grad_fn=<UnbindBackward0>),\n",
       " tensor([114.1662], grad_fn=<UnbindBackward0>),\n",
       " tensor([107.9304], grad_fn=<UnbindBackward0>),\n",
       " tensor([37.4929], grad_fn=<UnbindBackward0>),\n",
       " tensor([93.3627], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.7710], grad_fn=<UnbindBackward0>),\n",
       " tensor([150.4541], grad_fn=<UnbindBackward0>),\n",
       " tensor([142.3260], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.5064], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.3230], grad_fn=<UnbindBackward0>),\n",
       " tensor([264.3715], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.6796], grad_fn=<UnbindBackward0>),\n",
       " tensor([216.7988], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.4176], grad_fn=<UnbindBackward0>),\n",
       " tensor([182.9696], grad_fn=<UnbindBackward0>),\n",
       " tensor([245.0690], grad_fn=<UnbindBackward0>),\n",
       " tensor([184.7751], grad_fn=<UnbindBackward0>),\n",
       " tensor([130.1584], grad_fn=<UnbindBackward0>),\n",
       " tensor([211.1413], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.0305], grad_fn=<UnbindBackward0>),\n",
       " tensor([35.0822], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.4252], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.5742], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.0320], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.8059], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.3781], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.7745], grad_fn=<UnbindBackward0>),\n",
       " tensor([70.6081], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.7431], grad_fn=<UnbindBackward0>),\n",
       " tensor([52.0227], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.2622], grad_fn=<UnbindBackward0>),\n",
       " tensor([205.7892], grad_fn=<UnbindBackward0>),\n",
       " tensor([188.5390], grad_fn=<UnbindBackward0>),\n",
       " tensor([153.1713], grad_fn=<UnbindBackward0>),\n",
       " tensor([205.3668], grad_fn=<UnbindBackward0>),\n",
       " tensor([234.6807], grad_fn=<UnbindBackward0>),\n",
       " tensor([183.1294], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.5448], grad_fn=<UnbindBackward0>),\n",
       " tensor([200.2303], grad_fn=<UnbindBackward0>),\n",
       " tensor([214.5818], grad_fn=<UnbindBackward0>),\n",
       " tensor([253.4162], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.9768], grad_fn=<UnbindBackward0>),\n",
       " tensor([297.8692], grad_fn=<UnbindBackward0>),\n",
       " tensor([210.6680], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.5471], grad_fn=<UnbindBackward0>),\n",
       " tensor([7.7485], grad_fn=<UnbindBackward0>),\n",
       " tensor([90.4968], grad_fn=<UnbindBackward0>),\n",
       " tensor([7.1958], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.1031], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.9337], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.3142], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.3052], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.2879], grad_fn=<UnbindBackward0>),\n",
       " tensor([131.8204], grad_fn=<UnbindBackward0>),\n",
       " tensor([78.0955], grad_fn=<UnbindBackward0>),\n",
       " tensor([123.8118], grad_fn=<UnbindBackward0>),\n",
       " tensor([34.0428], grad_fn=<UnbindBackward0>),\n",
       " tensor([110.1763], grad_fn=<UnbindBackward0>),\n",
       " tensor([139.1240], grad_fn=<UnbindBackward0>),\n",
       " tensor([188.1666], grad_fn=<UnbindBackward0>),\n",
       " tensor([99.3799], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.4158], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.5203], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.4598], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.3143], grad_fn=<UnbindBackward0>),\n",
       " tensor([78.7609], grad_fn=<UnbindBackward0>),\n",
       " tensor([287.2417], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.6085], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.5313], grad_fn=<UnbindBackward0>),\n",
       " tensor([42.0767], grad_fn=<UnbindBackward0>),\n",
       " tensor([17.2626], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.3111], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.5504], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.8554], grad_fn=<UnbindBackward0>),\n",
       " tensor([100.6713], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.5018], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.2992], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.5897], grad_fn=<UnbindBackward0>),\n",
       " tensor([77.4240], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.1968], grad_fn=<UnbindBackward0>),\n",
       " tensor([131.4903], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.0470], grad_fn=<UnbindBackward0>),\n",
       " tensor([213.9101], grad_fn=<UnbindBackward0>),\n",
       " tensor([105.1920], grad_fn=<UnbindBackward0>),\n",
       " tensor([175.4377], grad_fn=<UnbindBackward0>),\n",
       " tensor([250.0492], grad_fn=<UnbindBackward0>),\n",
       " tensor([173.6486], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.1618], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.8609], grad_fn=<UnbindBackward0>),\n",
       " tensor([186.2966], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.1236], grad_fn=<UnbindBackward0>),\n",
       " tensor([105.2924], grad_fn=<UnbindBackward0>),\n",
       " tensor([11.8756], grad_fn=<UnbindBackward0>),\n",
       " tensor([25.4947], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.8451], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.7483], grad_fn=<UnbindBackward0>),\n",
       " tensor([71.4906], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.8405], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.5306], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.9784], grad_fn=<UnbindBackward0>),\n",
       " tensor([83.9332], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.9743], grad_fn=<UnbindBackward0>),\n",
       " tensor([208.9116], grad_fn=<UnbindBackward0>),\n",
       " tensor([68.6284], grad_fn=<UnbindBackward0>),\n",
       " tensor([39.8662], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.6613], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.6294], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.2586], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.4596], grad_fn=<UnbindBackward0>),\n",
       " tensor([199.0929], grad_fn=<UnbindBackward0>),\n",
       " tensor([213.0989], grad_fn=<UnbindBackward0>),\n",
       " tensor([162.4208], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.2373], grad_fn=<UnbindBackward0>),\n",
       " tensor([208.1835], grad_fn=<UnbindBackward0>),\n",
       " tensor([290.8988], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.1275], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.1987], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.5660], grad_fn=<UnbindBackward0>),\n",
       " tensor([53.8587], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.1076], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.2351], grad_fn=<UnbindBackward0>),\n",
       " tensor([68.6016], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.4196], grad_fn=<UnbindBackward0>),\n",
       " tensor([122.8331], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.0674], grad_fn=<UnbindBackward0>),\n",
       " tensor([160.5498], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.2725], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.7831], grad_fn=<UnbindBackward0>),\n",
       " tensor([204.1341], grad_fn=<UnbindBackward0>),\n",
       " tensor([110.6331], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.3295], grad_fn=<UnbindBackward0>),\n",
       " tensor([203.2337], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.8453], grad_fn=<UnbindBackward0>),\n",
       " tensor([167.5445], grad_fn=<UnbindBackward0>),\n",
       " tensor([186.2388], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.0909], grad_fn=<UnbindBackward0>),\n",
       " tensor([225.4109], grad_fn=<UnbindBackward0>),\n",
       " tensor([170.9512], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.3763], grad_fn=<UnbindBackward0>),\n",
       " tensor([94.2971], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.2852], grad_fn=<UnbindBackward0>),\n",
       " tensor([62.8788], grad_fn=<UnbindBackward0>),\n",
       " tensor([4.4272], grad_fn=<UnbindBackward0>),\n",
       " tensor([18.8867], grad_fn=<UnbindBackward0>),\n",
       " tensor([29.4741], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.3207], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.6563], grad_fn=<UnbindBackward0>),\n",
       " tensor([148.3523], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.2708], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.4026], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.7143], grad_fn=<UnbindBackward0>),\n",
       " tensor([61.9142], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.6755], grad_fn=<UnbindBackward0>),\n",
       " tensor([92.0568], grad_fn=<UnbindBackward0>),\n",
       " tensor([74.6055], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.4389], grad_fn=<UnbindBackward0>),\n",
       " tensor([130.9817], grad_fn=<UnbindBackward0>),\n",
       " tensor([123.0400], grad_fn=<UnbindBackward0>),\n",
       " tensor([83.5566], grad_fn=<UnbindBackward0>),\n",
       " tensor([49.8305], grad_fn=<UnbindBackward0>),\n",
       " tensor([97.0951], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.9197], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.2141], grad_fn=<UnbindBackward0>),\n",
       " tensor([33.8255], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.9535], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.8460], grad_fn=<UnbindBackward0>),\n",
       " tensor([89.2458], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.6709], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.1095], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.6119], grad_fn=<UnbindBackward0>),\n",
       " tensor([82.5332], grad_fn=<UnbindBackward0>),\n",
       " tensor([68.2977], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.1332], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.5876], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.4125], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.4684], grad_fn=<UnbindBackward0>),\n",
       " tensor([174.3640], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.2045], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.8711], grad_fn=<UnbindBackward0>),\n",
       " tensor([175.6712], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.6865], grad_fn=<UnbindBackward0>),\n",
       " tensor([240.9068], grad_fn=<UnbindBackward0>),\n",
       " tensor([211.8643], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.2381], grad_fn=<UnbindBackward0>),\n",
       " tensor([192.3157], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.4436], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.7636], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.7326], grad_fn=<UnbindBackward0>),\n",
       " tensor([60.1808], grad_fn=<UnbindBackward0>),\n",
       " tensor([25.2543], grad_fn=<UnbindBackward0>),\n",
       " tensor([108.3366], grad_fn=<UnbindBackward0>),\n",
       " tensor([112.9715], grad_fn=<UnbindBackward0>),\n",
       " tensor([107.0318], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.1600], grad_fn=<UnbindBackward0>),\n",
       " tensor([121.8712], grad_fn=<UnbindBackward0>),\n",
       " tensor([195.1102], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.6168], grad_fn=<UnbindBackward0>),\n",
       " tensor([202.7610], grad_fn=<UnbindBackward0>),\n",
       " tensor([203.5729], grad_fn=<UnbindBackward0>),\n",
       " tensor([75.3307], grad_fn=<UnbindBackward0>),\n",
       " tensor([205.1337], grad_fn=<UnbindBackward0>),\n",
       " tensor([206.2291], grad_fn=<UnbindBackward0>),\n",
       " tensor([163.5020], grad_fn=<UnbindBackward0>),\n",
       " tensor([220.0051], grad_fn=<UnbindBackward0>),\n",
       " tensor([297.6015], grad_fn=<UnbindBackward0>),\n",
       " tensor([264.5714], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.5234], grad_fn=<UnbindBackward0>),\n",
       " tensor([218.6377], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.2214], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.7666], grad_fn=<UnbindBackward0>),\n",
       " tensor([18.5709], grad_fn=<UnbindBackward0>),\n",
       " tensor([14.3428], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.2024], grad_fn=<UnbindBackward0>),\n",
       " tensor([17.8891], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.0492], grad_fn=<UnbindBackward0>),\n",
       " tensor([29.6389], grad_fn=<UnbindBackward0>),\n",
       " tensor([114.2864], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.1392], grad_fn=<UnbindBackward0>),\n",
       " tensor([123.8759], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.8560], grad_fn=<UnbindBackward0>),\n",
       " tensor([148.5629], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.6798], grad_fn=<UnbindBackward0>),\n",
       " tensor([129.0324], grad_fn=<UnbindBackward0>),\n",
       " tensor([119.1215], grad_fn=<UnbindBackward0>),\n",
       " tensor([103.9313], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.0359], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.1261], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.6194], grad_fn=<UnbindBackward0>),\n",
       " tensor([70.2309], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.3038], grad_fn=<UnbindBackward0>),\n",
       " tensor([182.1840], grad_fn=<UnbindBackward0>),\n",
       " tensor([235.4805], grad_fn=<UnbindBackward0>),\n",
       " tensor([36.3705], grad_fn=<UnbindBackward0>),\n",
       " tensor([124.4242], grad_fn=<UnbindBackward0>),\n",
       " tensor([9.0977], grad_fn=<UnbindBackward0>),\n",
       " tensor([28.8976], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.6476], grad_fn=<UnbindBackward0>),\n",
       " tensor([0.], grad_fn=<UnbindBackward0>),\n",
       " tensor([89.6980], grad_fn=<UnbindBackward0>),\n",
       " tensor([37.1585], grad_fn=<UnbindBackward0>),\n",
       " tensor([51.5934], grad_fn=<UnbindBackward0>),\n",
       " tensor([57.3309], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.2168], grad_fn=<UnbindBackward0>),\n",
       " tensor([59.3424], grad_fn=<UnbindBackward0>),\n",
       " tensor([82.5133], grad_fn=<UnbindBackward0>),\n",
       " tensor([118.5914], grad_fn=<UnbindBackward0>),\n",
       " tensor([22.6045], grad_fn=<UnbindBackward0>),\n",
       " tensor([143.2472], grad_fn=<UnbindBackward0>),\n",
       " tensor([144.2801], grad_fn=<UnbindBackward0>),\n",
       " tensor([175.8905], grad_fn=<UnbindBackward0>),\n",
       " tensor([90.9697], grad_fn=<UnbindBackward0>),\n",
       " tensor([217.4198], grad_fn=<UnbindBackward0>),\n",
       " tensor([148.2704], grad_fn=<UnbindBackward0>),\n",
       " tensor([162.1622], grad_fn=<UnbindBackward0>),\n",
       " tensor([103.2665], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.9636], grad_fn=<UnbindBackward0>),\n",
       " tensor([43.8261], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.6159], grad_fn=<UnbindBackward0>),\n",
       " tensor([13.7570], grad_fn=<UnbindBackward0>),\n",
       " tensor([31.6698], grad_fn=<UnbindBackward0>),\n",
       " tensor([52.7360], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.1051], grad_fn=<UnbindBackward0>),\n",
       " tensor([86.5648], grad_fn=<UnbindBackward0>),\n",
       " tensor([83.5956], grad_fn=<UnbindBackward0>),\n",
       " tensor([67.6557], grad_fn=<UnbindBackward0>),\n",
       " tensor([185.5233], grad_fn=<UnbindBackward0>),\n",
       " tensor([150.3930], grad_fn=<UnbindBackward0>),\n",
       " tensor([219.9777], grad_fn=<UnbindBackward0>),\n",
       " tensor([215.4809], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.0005], grad_fn=<UnbindBackward0>),\n",
       " tensor([197.5851], grad_fn=<UnbindBackward0>),\n",
       " tensor([233.8287], grad_fn=<UnbindBackward0>),\n",
       " tensor([248.3529], grad_fn=<UnbindBackward0>),\n",
       " tensor([177.9400], grad_fn=<UnbindBackward0>),\n",
       " tensor([41.4894], grad_fn=<UnbindBackward0>),\n",
       " tensor([367.2873], grad_fn=<UnbindBackward0>),\n",
       " tensor([242.9807], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.2222], grad_fn=<UnbindBackward0>),\n",
       " tensor([361.0471], grad_fn=<UnbindBackward0>),\n",
       " tensor([173.1326], grad_fn=<UnbindBackward0>),\n",
       " tensor([235.9957], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.4491], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.9647], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.5754], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.0981], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.2026], grad_fn=<UnbindBackward0>),\n",
       " tensor([105.0909], grad_fn=<UnbindBackward0>),\n",
       " tensor([100.3951], grad_fn=<UnbindBackward0>),\n",
       " tensor([140.6164], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.6700], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.1863], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.7375], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.7062], grad_fn=<UnbindBackward0>),\n",
       " tensor([44.8182], grad_fn=<UnbindBackward0>),\n",
       " tensor([178.0513], grad_fn=<UnbindBackward0>),\n",
       " tensor([209.7038], grad_fn=<UnbindBackward0>),\n",
       " tensor([201.7283], grad_fn=<UnbindBackward0>),\n",
       " tensor([246.1805], grad_fn=<UnbindBackward0>),\n",
       " tensor([129.6046], grad_fn=<UnbindBackward0>),\n",
       " tensor([191.3908], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.2766], grad_fn=<UnbindBackward0>),\n",
       " tensor([228.0297], grad_fn=<UnbindBackward0>),\n",
       " tensor([182.9001], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.5890], grad_fn=<UnbindBackward0>),\n",
       " tensor([258.0880], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.1601], grad_fn=<UnbindBackward0>),\n",
       " tensor([46.5969], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.3550], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.8988], grad_fn=<UnbindBackward0>),\n",
       " tensor([37.4868], grad_fn=<UnbindBackward0>),\n",
       " tensor([79.9713], grad_fn=<UnbindBackward0>),\n",
       " tensor([154.2640], grad_fn=<UnbindBackward0>),\n",
       " tensor([106.4463], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.5000], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.8382], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.1402], grad_fn=<UnbindBackward0>),\n",
       " tensor([104.2437], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.9896], grad_fn=<UnbindBackward0>),\n",
       " tensor([133.7231], grad_fn=<UnbindBackward0>),\n",
       " tensor([84.0593], grad_fn=<UnbindBackward0>),\n",
       " tensor([38.0875], grad_fn=<UnbindBackward0>),\n",
       " tensor([135.7722], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.2979], grad_fn=<UnbindBackward0>),\n",
       " tensor([143.3834], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.6046], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.8057], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.2496], grad_fn=<UnbindBackward0>),\n",
       " tensor([180.5465], grad_fn=<UnbindBackward0>),\n",
       " tensor([78.8851], grad_fn=<UnbindBackward0>),\n",
       " tensor([108.0665], grad_fn=<UnbindBackward0>),\n",
       " tensor([12.3397], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.6148], grad_fn=<UnbindBackward0>),\n",
       " tensor([23.8276], grad_fn=<UnbindBackward0>),\n",
       " tensor([8.2777], grad_fn=<UnbindBackward0>),\n",
       " tensor([41.9588], grad_fn=<UnbindBackward0>),\n",
       " tensor([48.9065], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.5297], grad_fn=<UnbindBackward0>),\n",
       " tensor([21.5825], grad_fn=<UnbindBackward0>),\n",
       " tensor([162.1464], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.9412], grad_fn=<UnbindBackward0>),\n",
       " tensor([115.6684], grad_fn=<UnbindBackward0>),\n",
       " tensor([167.4553], grad_fn=<UnbindBackward0>),\n",
       " tensor([166.7237], grad_fn=<UnbindBackward0>),\n",
       " tensor([164.2769], grad_fn=<UnbindBackward0>),\n",
       " tensor([203.4603], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.7352], grad_fn=<UnbindBackward0>),\n",
       " tensor([258.6334], grad_fn=<UnbindBackward0>),\n",
       " tensor([252.4140], grad_fn=<UnbindBackward0>),\n",
       " tensor([21.7910], grad_fn=<UnbindBackward0>),\n",
       " tensor([191.1618], grad_fn=<UnbindBackward0>),\n",
       " tensor([206.8801], grad_fn=<UnbindBackward0>),\n",
       " tensor([241.2720], grad_fn=<UnbindBackward0>),\n",
       " tensor([195.7853], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.3534], grad_fn=<UnbindBackward0>),\n",
       " tensor([105.3038], grad_fn=<UnbindBackward0>),\n",
       " tensor([71.4136], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.7814], grad_fn=<UnbindBackward0>),\n",
       " tensor([81.6364], grad_fn=<UnbindBackward0>),\n",
       " tensor([116.2958], grad_fn=<UnbindBackward0>),\n",
       " tensor([48.1636], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.3570], grad_fn=<UnbindBackward0>),\n",
       " tensor([186.9451], grad_fn=<UnbindBackward0>),\n",
       " tensor([160.9636], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.1195], grad_fn=<UnbindBackward0>),\n",
       " tensor([134.7509], grad_fn=<UnbindBackward0>),\n",
       " tensor([143.6752], grad_fn=<UnbindBackward0>),\n",
       " tensor([238.5780], grad_fn=<UnbindBackward0>),\n",
       " tensor([239.7356], grad_fn=<UnbindBackward0>),\n",
       " tensor([181.7490], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.5009], grad_fn=<UnbindBackward0>),\n",
       " tensor([47.5242], grad_fn=<UnbindBackward0>),\n",
       " tensor([169.5019], grad_fn=<UnbindBackward0>),\n",
       " tensor([165.0031], grad_fn=<UnbindBackward0>),\n",
       " tensor([320.6379], grad_fn=<UnbindBackward0>),\n",
       " tensor([160.8873], grad_fn=<UnbindBackward0>),\n",
       " tensor([27.2485], grad_fn=<UnbindBackward0>),\n",
       " tensor([54.4955], grad_fn=<UnbindBackward0>),\n",
       " tensor([40.5363], grad_fn=<UnbindBackward0>),\n",
       " tensor([188.3983], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.9368], grad_fn=<UnbindBackward0>),\n",
       " tensor([24.2703], grad_fn=<UnbindBackward0>),\n",
       " tensor([136.0490], grad_fn=<UnbindBackward0>),\n",
       " tensor([82.3840], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.3545], grad_fn=<UnbindBackward0>),\n",
       " tensor([55.2689], grad_fn=<UnbindBackward0>),\n",
       " tensor([98.6790], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.4272], grad_fn=<UnbindBackward0>),\n",
       " tensor([117.6024], grad_fn=<UnbindBackward0>),\n",
       " tensor([159.9012], grad_fn=<UnbindBackward0>),\n",
       " tensor([148.4145], grad_fn=<UnbindBackward0>),\n",
       " tensor([217.0165], grad_fn=<UnbindBackward0>),\n",
       " tensor([188.7310], grad_fn=<UnbindBackward0>),\n",
       " tensor([185.6342], grad_fn=<UnbindBackward0>),\n",
       " tensor([307.8606], grad_fn=<UnbindBackward0>),\n",
       " tensor([235.0570], grad_fn=<UnbindBackward0>),\n",
       " tensor([236.9590], grad_fn=<UnbindBackward0>),\n",
       " tensor([208.8130], grad_fn=<UnbindBackward0>),\n",
       " tensor([167.6070], grad_fn=<UnbindBackward0>),\n",
       " tensor([255.6189], grad_fn=<UnbindBackward0>),\n",
       " tensor([203.4108], grad_fn=<UnbindBackward0>),\n",
       " tensor([123.4547], grad_fn=<UnbindBackward0>),\n",
       " tensor([111.5222], grad_fn=<UnbindBackward0>),\n",
       " tensor([190.2098], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.2533], grad_fn=<UnbindBackward0>),\n",
       " tensor([91.6610], grad_fn=<UnbindBackward0>),\n",
       " tensor([103.4159], grad_fn=<UnbindBackward0>),\n",
       " tensor([63.1612], grad_fn=<UnbindBackward0>),\n",
       " tensor([78.3066], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.3225], grad_fn=<UnbindBackward0>),\n",
       " tensor([214.6779], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.9315], grad_fn=<UnbindBackward0>),\n",
       " tensor([213.1644], grad_fn=<UnbindBackward0>),\n",
       " tensor([204.0580], grad_fn=<UnbindBackward0>),\n",
       " tensor([253.1024], grad_fn=<UnbindBackward0>),\n",
       " tensor([215.2777], grad_fn=<UnbindBackward0>),\n",
       " tensor([151.7111], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.8866], grad_fn=<UnbindBackward0>),\n",
       " tensor([232.5086], grad_fn=<UnbindBackward0>),\n",
       " tensor([227.5970], grad_fn=<UnbindBackward0>),\n",
       " tensor([230.6207], grad_fn=<UnbindBackward0>),\n",
       " tensor([196.7001], grad_fn=<UnbindBackward0>),\n",
       " tensor([277.5523], grad_fn=<UnbindBackward0>),\n",
       " tensor([207.5862], grad_fn=<UnbindBackward0>),\n",
       " tensor([228.7146], grad_fn=<UnbindBackward0>),\n",
       " tensor([229.5692], grad_fn=<UnbindBackward0>),\n",
       " tensor([220.6732], grad_fn=<UnbindBackward0>),\n",
       " tensor([110.7186], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.1246], grad_fn=<UnbindBackward0>),\n",
       " tensor([142.7889], grad_fn=<UnbindBackward0>),\n",
       " tensor([126.8919], grad_fn=<UnbindBackward0>),\n",
       " tensor([80.6001], grad_fn=<UnbindBackward0>),\n",
       " tensor([120.8213], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.3250], grad_fn=<UnbindBackward0>),\n",
       " tensor([96.2018], grad_fn=<UnbindBackward0>),\n",
       " tensor([146.0446], grad_fn=<UnbindBackward0>),\n",
       " tensor([113.1816], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.0938], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.2078], grad_fn=<UnbindBackward0>),\n",
       " tensor([105.8783], grad_fn=<UnbindBackward0>),\n",
       " tensor([155.4029], grad_fn=<UnbindBackward0>),\n",
       " tensor([183.8736], grad_fn=<UnbindBackward0>),\n",
       " tensor([259.5375], grad_fn=<UnbindBackward0>),\n",
       " tensor([131.8660], grad_fn=<UnbindBackward0>),\n",
       " tensor([228.2478], grad_fn=<UnbindBackward0>),\n",
       " tensor([204.0738], grad_fn=<UnbindBackward0>),\n",
       " tensor([177.5350], grad_fn=<UnbindBackward0>),\n",
       " tensor([147.2866], grad_fn=<UnbindBackward0>),\n",
       " tensor([145.1566], grad_fn=<UnbindBackward0>),\n",
       " tensor([261.8263], grad_fn=<UnbindBackward0>),\n",
       " tensor([86.7932], grad_fn=<UnbindBackward0>),\n",
       " tensor([87.4408], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.7364], grad_fn=<UnbindBackward0>),\n",
       " tensor([88.4778], grad_fn=<UnbindBackward0>),\n",
       " tensor([45.4073], grad_fn=<UnbindBackward0>),\n",
       " tensor([103.6827], grad_fn=<UnbindBackward0>),\n",
       " tensor([126.1013], grad_fn=<UnbindBackward0>),\n",
       " tensor([170.7143], grad_fn=<UnbindBackward0>),\n",
       " tensor([193.5305], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.8762], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.9486], grad_fn=<UnbindBackward0>),\n",
       " tensor([137.8880], grad_fn=<UnbindBackward0>),\n",
       " tensor([85.3014], grad_fn=<UnbindBackward0>),\n",
       " tensor([181.8857], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.5343], grad_fn=<UnbindBackward0>),\n",
       " tensor([234.2512], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.5872], grad_fn=<UnbindBackward0>),\n",
       " tensor([302.4437], grad_fn=<UnbindBackward0>),\n",
       " tensor([208.2997], grad_fn=<UnbindBackward0>),\n",
       " tensor([233.4603], grad_fn=<UnbindBackward0>),\n",
       " tensor([125.8837], grad_fn=<UnbindBackward0>),\n",
       " tensor([301.3579], grad_fn=<UnbindBackward0>),\n",
       " tensor([205.4288], grad_fn=<UnbindBackward0>),\n",
       " tensor([225.8071], grad_fn=<UnbindBackward0>),\n",
       " tensor([127.9146], grad_fn=<UnbindBackward0>),\n",
       " tensor([66.1448], grad_fn=<UnbindBackward0>),\n",
       " tensor([30.6948], grad_fn=<UnbindBackward0>),\n",
       " tensor([144.4508], grad_fn=<UnbindBackward0>),\n",
       " tensor([73.1996], grad_fn=<UnbindBackward0>),\n",
       " tensor([159.0663], grad_fn=<UnbindBackward0>),\n",
       " tensor([100.7280], grad_fn=<UnbindBackward0>),\n",
       " tensor([166.5957], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.5106], grad_fn=<UnbindBackward0>),\n",
       " tensor([224.7421], grad_fn=<UnbindBackward0>),\n",
       " tensor([212.6251], grad_fn=<UnbindBackward0>),\n",
       " tensor([171.7878], grad_fn=<UnbindBackward0>),\n",
       " tensor([194.6351], grad_fn=<UnbindBackward0>),\n",
       " tensor([195.2488], grad_fn=<UnbindBackward0>),\n",
       " tensor([216.4339], grad_fn=<UnbindBackward0>),\n",
       " tensor([185.2454], grad_fn=<UnbindBackward0>),\n",
       " tensor([228.0020], grad_fn=<UnbindBackward0>),\n",
       " tensor([248.8923], grad_fn=<UnbindBackward0>),\n",
       " tensor([293.9097], grad_fn=<UnbindBackward0>),\n",
       " tensor([179.2547], grad_fn=<UnbindBackward0>),\n",
       " tensor([260.2901], grad_fn=<UnbindBackward0>),\n",
       " tensor([232.3693], grad_fn=<UnbindBackward0>),\n",
       " tensor([192.3489], grad_fn=<UnbindBackward0>),\n",
       " tensor([284.6918], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.5602], grad_fn=<UnbindBackward0>),\n",
       " tensor([50.8606], grad_fn=<UnbindBackward0>),\n",
       " tensor([58.3938], grad_fn=<UnbindBackward0>),\n",
       " tensor([21.5130], grad_fn=<UnbindBackward0>),\n",
       " tensor([76.7623], grad_fn=<UnbindBackward0>),\n",
       " tensor([138.9817], grad_fn=<UnbindBackward0>),\n",
       " tensor([109.3030], grad_fn=<UnbindBackward0>),\n",
       " tensor([128.3228], grad_fn=<UnbindBackward0>),\n",
       " tensor([107.3073], grad_fn=<UnbindBackward0>),\n",
       " tensor([126.9660], grad_fn=<UnbindBackward0>),\n",
       " tensor([158.5783], grad_fn=<UnbindBackward0>),\n",
       " tensor([211.8211], grad_fn=<UnbindBackward0>),\n",
       " tensor([94.6761], grad_fn=<UnbindBackward0>),\n",
       " tensor([214.9845], grad_fn=<UnbindBackward0>),\n",
       " tensor([132.5180], grad_fn=<UnbindBackward0>),\n",
       " tensor([255.1114], grad_fn=<UnbindBackward0>),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1650b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT tensor([90.8901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.2021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.3647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.9300], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.5785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.5987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.2160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.7721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.0843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.0038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.6839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.5834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.4189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.6580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.3485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([22.9464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.3977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2789], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.9635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.6938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.0084], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8056], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.9038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.1330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.6562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([6.9995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.7278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.0627], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.2574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.4489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.3421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.9149], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.0891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.7146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.9916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.0873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.7351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.1973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.4274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.1591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.8579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.3121], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.8748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.1357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.2996], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.6574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.1524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.8557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.1395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.8997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.6132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.8491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.2016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.4541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.7620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.0360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.2426], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.4477], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.2441], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.6833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.0276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.4815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.7883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.5727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.6611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.2376], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.7820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.5571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.4977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([12.6177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.1229], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([12.3342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.7404], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.6095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.9469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.9823], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.5061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.4256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.6075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.7807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.0868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.9392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.8378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.1422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.5643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.0275], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.7427], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.1709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.9712], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.3583], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.3817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.2394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.7913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.6676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([30.0211], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.3991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.7688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.9177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.8445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.0156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.7522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.1851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.3505], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.9881], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.1034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.9880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.7314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.8236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.5512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.2813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.8373], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.8646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.1090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.3888], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.7800], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.5344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.4168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([44.6989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.4802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.3008], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.0212], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.6738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.3105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.3378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.1085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.8424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.2794], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.1488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.0138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.6928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.1886], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.7537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.4516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.3833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.9333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.2777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([8.6339], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.4125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.9739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.4286], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([20.7752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([1.4924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.0883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.1736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.9532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.8689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.2594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.9440], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.1314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.9408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.9394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.7208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.2334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.5484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.2612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.6021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.9711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.1864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.3721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.6270], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([5.2016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.1258], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([6.1373], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.6117], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.2253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.5035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.8680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.9611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.6476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.9868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.4447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([30.9884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.1057], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.5186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.5890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.1933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.0990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.8428], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.3599], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.4240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.8816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.7974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.9809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([20.9852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.3515], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.9963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([10.2129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.6380], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.6443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.7839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.6885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.4704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.7332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.7170], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.7247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.2133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.6877], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.0003], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.8857], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.9230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.4504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.6760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.3637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.8617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.1983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([29.6642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.3410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([12.8537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.0020], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.7536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.2070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.6207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.3523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.9709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.7979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.2090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.9825], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.7571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.7749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.1998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.4944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.1241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.0632], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.5032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.6100], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.1666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([25.0197], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.5622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.6546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.0631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.9365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.0795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.4917], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.3154], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.9407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.8070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.8833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.0306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([25.1015], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.0068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.2815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.3592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.2784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.8976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.8029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.2781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.6141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.1895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.1644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.6591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.8333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.1635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.0108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.1751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.8782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.1752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.4437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.9469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.0977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.0942], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.8736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.6119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.1765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.6610], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.2034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.5885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9336], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.3194], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.9087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.6838], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([2.0186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.8646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.0528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.6846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.4634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2101], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.9817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.0530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.1657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.7063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.4919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.1150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.1092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.4466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.0094], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.2279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.1775], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.3210], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.4545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.4687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.8648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.6552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.2465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.5377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([19.8924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.7027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.2377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.6589], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.9609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.7695], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.6770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.3781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.8546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.5470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.1118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.7520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.0489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.1227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.2929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.2136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.6671], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.0315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.3847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.3935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.2866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.5363], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.3478], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([33.2106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.0745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.6050], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.5667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.3299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.6704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.5654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.9245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.7973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.4543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.8472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.5115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.7472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.1956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.3104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.4595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([5.7774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.7111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.9172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.0501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.1448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.5887], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.8005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.4327], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.7948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.1645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.7793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.0659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.3631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.3160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6444], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.8364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.1992], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.8418], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.9386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.1154], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.9302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.8704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.6429], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([10.2816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([14.4911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.4393], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.4967], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.8024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.2692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.7230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([33.6688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.0858], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.5278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.4910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.5986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.2703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.3173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.7873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.1144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.9954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.5279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.3561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.0728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.8890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.3289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.1435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.3903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.4239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.7359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.7927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.3594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.3663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.7211], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.3730], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.4770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.8374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.4406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.0448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.1013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.1747], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.5974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.7470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.3468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.3404], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.3957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.4937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.4281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.9806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.0831], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([22.7220], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.6719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.8304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.3629], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.1479], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.7023], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.8656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.1709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.3788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.3086], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.1773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.8431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.6145], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.6369], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.6451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.3343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.2178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.1410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.4808], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.4825], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.9087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([9.8139], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.9059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.3053], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.7167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.5276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.9896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.4864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.5131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.7022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.4129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.0948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.2937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.9648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.8902], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.0861], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.5098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.6795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.8960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.2678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.1991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.6403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.8431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.2910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.5091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.8453], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.6633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.3308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.5676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.7005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.4454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.6205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.6690], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.9308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.9150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.6160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.5100], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.3170], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.7249], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.9100], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.3982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.7873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.9330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.9200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.7118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([44.2157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.6566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.1662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.9304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.4929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.3627], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.7710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.4541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.3260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.5064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.3230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.3715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.6796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.7988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.4176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.9696], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.0690], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.1584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.1413], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.0305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.0822], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.4252], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.5742], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.0320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.8059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.3781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.7745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.6081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.7431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.0227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.2622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.7892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.5390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.1713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.3668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.6807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.1294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.2303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.5818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.4162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.9768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.8692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.6680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.5471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([7.7485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.4968], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([7.1958], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.9337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.3142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.3052], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.2879], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.0955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.8118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.0428], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.1763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.1240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.1666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.3799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.4158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.5203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.4598], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.3143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.7609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.2417], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.6085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.5313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.0767], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([17.2626], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.3111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.5504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.8554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.6713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.5018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.2992], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.5897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.4240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.1968], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.4903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.9101], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.1920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.4377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.0492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.6486], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.1618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.8609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.2966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.1236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.2924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([11.8756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([25.4947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.8451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.7483], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.4906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.8405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.5306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.9332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.9743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.9116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.6284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.8662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.6613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.6294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.2586], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.0929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.0989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.4208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2373], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.1835], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.8988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.1275], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.5660], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.8587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.1076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.2351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.6016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.4196], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.8331], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.0674], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.5498], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.2725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.7831], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.1341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.6331], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.2337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.8453], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.5445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.2388], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.0909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.4109], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.9512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.3763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.2971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.2852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.8788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([4.4272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([18.8867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([29.4741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.3207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.6563], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.3523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.2708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.4026], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.7143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.9142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.6755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.0568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.6055], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.4389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.9817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.0400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.5566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.8305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.0951], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9197], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([33.8255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.9535], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.8460], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.2458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.6709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.1095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.6119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.5332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.2977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.1332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5876], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.4125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.4684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3640], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.2045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.8711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.6712], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.6865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.9068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.8643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.2381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.3157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.4436], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.7636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.7326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.1808], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([25.2543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.3366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.9715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.0318], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.8712], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.1102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.7610], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.5729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.3307], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.1337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.2291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.5020], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.6015], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.5714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.5234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.6377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.7666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([18.5709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([14.3428], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.2024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([17.8891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.0492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([29.6389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.2864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.1392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.8759], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.8560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.5629], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.6798], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.0324], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.1215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.9313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.0359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.6194], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.2309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.3038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.1840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.4805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.3705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.4242], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([9.0977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.8976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.6476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.6980], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.1585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.5934], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.3309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.3424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.5133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.5914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([22.6045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.2472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.2801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.8905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.9697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.4198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.2704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.1622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.2665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.8261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.7570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.6698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.7360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.1051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.5648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.5956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.6557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.5233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.3930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.9777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.4809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.5851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.8287], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.3529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.9400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.4894], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.2873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2222], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.0471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.1326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.9957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.4491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.9647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.0981], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.2026], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.0909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.3951], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.6164], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.7375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.7062], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([44.8182], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.0513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.7038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.7283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.1805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.6046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3908], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.0297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.9001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.5890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.0880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.1601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.5969], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.3550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.8988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.4868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.9713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2640], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.4463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.5000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.8382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.1402], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.2437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.7231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.0593], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.0875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.7722], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.2979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.3834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.6046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.8057], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.2496], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.5465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.8851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.0665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([12.3397], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.6148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.8276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([8.2777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.9588], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.9065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.5297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.5825], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.1464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.6684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.4553], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.4603], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.7352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.6334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.4140], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.7910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.1618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.8801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.2720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.7853], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.3534], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.3038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.4136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.7814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.6364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.2958], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.1636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.3570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.9451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.9636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.1195], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.7509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.6752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5780], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.7356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.7490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5009], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.5242], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.0031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.6379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.8873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.2485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.4955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.5363], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.3983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.9368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.2703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.0490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.3840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.3545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.2689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.4272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.6024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.9012], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.4145], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.0165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.7310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.6342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.8606], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.0570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.9590], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.8130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.6070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.6189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.4108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.4547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.5222], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.2098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.2533], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.6610], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.4159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.1612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.3066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.3225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.6779], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.9315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.1644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.1024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.7111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.8866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.5086], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.5970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.6207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.5523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.5862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.7146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.5692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.6732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.7186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.1246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.8919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.6001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.8213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.3250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.2018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.0446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.1816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.2078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.8783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.5375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8660], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.2478], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.5350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.2866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.1566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.8263], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.7932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.4408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.7364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.4778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.4073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.6827], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.1013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.7143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.5305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.8762], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.9486], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.8880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.3014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.8857], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.5343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.2512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.5872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.4437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.2997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.4603], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.8837], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.3579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.4288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.8071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.9146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.1448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([30.6948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.4508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.1996], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.0663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.7280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.5957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.5106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.7421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.6251], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.7878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.6351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.2488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.4339], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.2454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.0020], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.8923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.9097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.2547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.2901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.3693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.3489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.6918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.5602], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.8606], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.3938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.5130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.7623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.9817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.3030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.3228], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.3073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.9660], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.5783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.8211], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.6761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.9845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.5180], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.3762], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.0927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.3798], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.5888], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.0896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.7085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.3572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.2672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.1520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.0830], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.4616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.4429], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.5701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.3425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.4856], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.7215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.2196], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.1000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.1061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.4131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.4178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3952], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.2997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.9530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.8987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.9648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.1079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.6171], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.3402], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.9409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.6774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.9446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.8942], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.0288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.5567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([12.2156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.4178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.7264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.9801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.9445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.3412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.7423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.9634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.5285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.2353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.3326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.8454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.5113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.6248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.6379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.2122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.0261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.7137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.2854], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.0693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.8468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.4743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.7550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.8651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.5576], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.1812], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.8071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.9949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.7091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.1340], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.0420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.9172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.5031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.2872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.4310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.4244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.8294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([316.9416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.9898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.1316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.3514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.4655], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.1991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.9402], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.3550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.2778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.1276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.9911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([11.3015], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.7889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.1184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.1018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.4723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.8017], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.4779], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.5114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.0114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.0726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.1724], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.0821], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.8763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.6045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.4559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.2403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.1836], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.0531], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.1143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.6869], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.0230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.6892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.2813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.6280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.4152], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.9064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.5084], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.0094], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.0332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.1099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.3945], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.3691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.3031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.8587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.3350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.7824], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.2766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.9032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.7584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.4618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.8755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.4794], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.0424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.8782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.1457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.9807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.8144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.8961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.1719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.7921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.2137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.9834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.3177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.8870], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.8312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.6299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.8952], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.4205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.1611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.1833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.2608], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.3336], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.8146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.8656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.3075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.1802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9062], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.0280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.9328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.1525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.2804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.8189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.1989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.7668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.1277], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.8991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.6443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.0203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.6601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.7253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.1725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.3657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.4236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.8069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.8943], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1436], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.7564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.3290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.9225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.5221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.3340], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.4071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.5703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.4634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.1269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.2381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.7796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.5694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.5634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.1937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.4711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.9264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.3951], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.0752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.5316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.4383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.3768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.8162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.5919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.4203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.9865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.1105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.7911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.8454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.1633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.1788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.4592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.7677], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.7818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.7288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.5630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.4816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.2229], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.5650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.7090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.0078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.4471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.6623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.2642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.4665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.3189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.1365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([4.0033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.8058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.4459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.7102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.7002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.2148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.1321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.9468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.9409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.4934], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.6391], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.0341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.9118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.3376], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.9906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.0893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7089], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.0736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.3995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.5763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.4286], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.7798], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.6190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.7890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.1672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.6817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.3648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.9331], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.8310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.6373], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.7104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.3287], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.6016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.8434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.7412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.4783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.3540], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.7085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.7567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.9771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.1886], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.7552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.9723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.8581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.3885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2266], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.5147], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.8902], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.7887], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.9615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.0989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.9991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9112], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.1557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.6713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.3072], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.4283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.0014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.3536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.8259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.0824], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.4365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.2315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.1733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.1929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.5823], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.0541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.7748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.6711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.5514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.2232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.5379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.1437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.3642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.0708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.5729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.5065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.2944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.4338], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.0009], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.0884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.9675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.0848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.0028], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.8426], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.4542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([381.2285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.3046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.3320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.0903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.4767], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.6988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.5664], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.4860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.5550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.3142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.3809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.6799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.7751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.5389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.1846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.3535], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.0897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.9595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.7591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.9280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.3150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.3898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([358.2155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.5820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.3099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.2209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.2778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.4858], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.0730], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.0373], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.3001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.5148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.3069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.6414], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.9624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.0784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.2019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.1451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.9763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.3190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.8491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.5408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.9021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.3713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.8566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.6582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([394.2115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.4001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.3228], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.8894], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.3770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.1234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.4185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.5724], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.0221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.3372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.6477], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.5253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.0878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.8666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.2424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.8457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.1411], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.4699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.8583], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.4410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.5726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.2815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.4415], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.8790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.9873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.6073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([407.5780], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.8759], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.8537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.7201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.4306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.3111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.0570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.8716], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.2004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.2884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.2208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.8212], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.0760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.8138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.4117], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.0528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.0956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.5951], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.0607], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.4424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.7432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.2163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.8719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.3130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.4383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.9070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.5684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.3905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.5965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.4580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.1880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.4489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.1568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.6254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.8580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.4031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.0737], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.2947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.9877], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.4122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.9259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.1626], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.3898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.1927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.8916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.1212], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.7019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.0520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.0897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.4130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.8168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.9829], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.5314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.2148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.6526], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.8583], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.9328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.9144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1149], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.9750], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.9862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.9735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.9184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.3598], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.1500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.5178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.3303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.6400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.3870], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.0991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.9193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.2761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.9342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.6848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.7613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.6785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.5031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4946], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.7119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.5199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.9176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4553], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.0291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.5208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.1915], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.8312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.5430], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.1425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.4984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.3233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2084], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.1638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.3734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.4441], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([44.8499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.4259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.5651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.8488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.7580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.7442], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.9858], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.5343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.2054], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.7397], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.8891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.4729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.3423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.8119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.2162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.8495], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.6406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.1095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([371.5596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.1217], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.5000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.8667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.7312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.1900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.7710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.3311], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.5954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.5549], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.3667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.6107], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.4568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.3227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.9523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.9887], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.4015], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.1421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.7294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.4051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.3503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.8793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.4480], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.6775], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.3040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([358.2327], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.5186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.7961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.1072], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.6400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.3995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.4357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.4935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.1085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.6031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.7390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.7305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.6294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.1387], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.8959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.8532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.4093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.8350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.6423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.8787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.2354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.1949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.8359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.0063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.2705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.0949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.6423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.7639], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.1528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.0130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.5947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.5936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.0994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.6799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.9977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.5198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.6937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.0769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.1768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.1802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.8910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.0132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([362.6963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.1594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.2132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.9351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.9556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.9340], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.4009], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.3140], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.9051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.6098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.1490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.9500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.8997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.2613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.0278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.4546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.3103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.4890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.4945], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.6568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.8130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.3835], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.9666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.3234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.1120], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.6954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.1543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.9572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.1104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.7973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.4926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.3098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.0410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.2598], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.3100], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.4752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.3815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.7296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.8318], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.4792], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.9389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.9264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.8045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.4500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.9167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.9376], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.0878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.0107], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.2173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.3559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.0179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([403.0267], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.4777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9563], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.9012], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.7769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.3735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.8469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.5450], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.2970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.8324], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1575], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.2632], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.9322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.7510], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.3690], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.5078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.3387], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.0206], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.6605], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.9049], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([391.5692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([324.6849], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.8986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.9266], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.2620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([393.5843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.2341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.6416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.5104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.8607], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.2848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.4521], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.2514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.2991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.1110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.8226], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.0643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.7791], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.4826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.7240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.3097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.8561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.9246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.9911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.4003], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.7328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.9937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.6454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.7122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.3395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.7481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.7994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.8200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.4000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.7637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.3533], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.6846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.6064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.1211], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.0322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.0963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.1540], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.7957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.5506], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.9591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.3119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.5872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.8472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.6989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.8661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.8640], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.9927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.3384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.6650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.7123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.7080], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.7219], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.2247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.8809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.5028], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.6347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.1643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.4262], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.0470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.9594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.6877], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.2883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.9296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.4191], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.5930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.7071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.8705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.3523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.9677], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.9172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.4104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.7861], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.8172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.3570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.5646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.4306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.9468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.7583], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.6529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.8635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.2336], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.1244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.8737], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.8421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.4064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.0066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.3518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.1256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.5152], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([406.7413], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.1073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.6153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.5425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.5643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.2638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.3060], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.2788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.2555], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.5106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.1179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.2892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.1248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.8931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.3615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.7699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.5912], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.8666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.9035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.6306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.7297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.7793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([348.1118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.7069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.5847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.1820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.0119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.4620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.0659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.8467], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.9655], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.7826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.6447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.5343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.9485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.6254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.0956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.5933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.6281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.1850], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.6061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.1551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.4783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.7926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.1768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.4985], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.2082], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.3360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.6326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.1482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1565], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.9167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.6893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.2508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2089], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7335], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.3162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.2213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.5818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.8804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.6491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.3666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.4297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.0799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.9270], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.3080], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.9016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.9491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.6349], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.1177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.8782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.5852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.5709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.4546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.3864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.1728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.3097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.3289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.3777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.2286], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.5625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.1040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.4173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.7480], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9391], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.2544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.9111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.8740], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.1400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.2525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.8836], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.9682], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.2083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.8670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.5147], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.5452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.2899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.2679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.3527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.7783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.1592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.6746], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.0663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.5624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.4642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.3539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.4534], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.1690], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.7052], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.6026], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.1649], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.7099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.3389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.9541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.0829], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.3620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.9895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.9995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([18.7896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.1246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.3382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.3537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3404], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.7132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.9645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.6880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.2419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.8860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.0521], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.3149], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.8712], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.8181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.3066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.1675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.3446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.9959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.9469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.2676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([376.7468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.2061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.6058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([30.2815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.4986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.1143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.4420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.6677], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.6782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.8321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.2787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.9051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.1350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.7504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.7329], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.2893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([345.1157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.4792], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.6097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.6459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.4204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.7423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.7171], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.0503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.9017], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.8246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.0397], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.8069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.3812], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.9400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.8478], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.6526], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.0380], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.2499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.2383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.3071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.2611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.5201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.9002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.4642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.9173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.9231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.4852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.9816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.8261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.1840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.6090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.6599], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.6532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.9018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.7551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.4013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.5644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.5251], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.6824], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.2781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.5538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.1036], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.5669], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.3810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.7815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.6966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.6894], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.5254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.0887], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.1246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.5717], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.2030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.5918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.3867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4887], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.7271], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.2792], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.8884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.5874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.1521], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.0643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.8556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.5652], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.5990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.0684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.4303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.4443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.2330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.5116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.8662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.3083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.3609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.6669], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.4974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.4065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.7130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.8971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.2394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.8786], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.4145], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.6754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.3020], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.5852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.4710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.8820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.0110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.8643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.5846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.1768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.4512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.9120], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.9267], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.3517], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.4212], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.2984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.0424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.2620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.5843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.9182], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.9313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.9733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.6566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.4966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.0179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.3770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.0629], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.4738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.8949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.8929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.5684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.4245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.8666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.5106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.0382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.5461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.8091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.1782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.3647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.0698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.4392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.0157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.7502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.3604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.2057], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.3747], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.5201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.4618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.6979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.5438], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.8671], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.1112], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.1809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.7473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.0370], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.4257], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.7146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.6726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.2818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.1232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.6122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.8858], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.8013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.1068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.7351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.3628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.3837], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.5934], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.8141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.3463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.5884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.8748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.6507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.5386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.8499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.3736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.5734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.2099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.4552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.2642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.8522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.8207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.8388], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.3491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.2473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.5359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.4303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.8492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.5991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.0602], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.6527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.4998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.8353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.5741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.2916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.8284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.8371], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.2867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.4908], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.4377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.8522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.9200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.0347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.5425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.3007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.3053], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.1079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.8899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.5845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.7398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.9378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.3121], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.4193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.6337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.2771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.2694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.5697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.8434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.3839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.1720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.1456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.8469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.8590], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.6833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.6245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.3667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.7878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.2000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.7359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.1221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.7800], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.9886], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.8481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.8459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.9070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.4928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.9933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.3444], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.7160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([14.2673], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.3676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.5123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([33.3102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.7287], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.0470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.2129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.4560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.1656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.8487], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.4345], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.0596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.9436], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.7897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.2361], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.9720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.6521], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.1913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.3909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.5872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.5709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.7227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.6530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.1476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.1310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.3789], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.0554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.0747], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.1687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.9609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.5090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.4458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.5156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.4061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.6928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.5772], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.0944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.7414], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.2360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.9634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.7899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.4366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.0390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.2614], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.5110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.7749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.2533], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.6826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.9111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.3720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.4396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.4201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.1926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.9013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.6039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.7191], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.1949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.0569], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.5677], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.5936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.6103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.7312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.0976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.6368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.0551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.9572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.5425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.0998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.9749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.8301], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.4339], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.5268], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.6900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.4092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.8182], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.6142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.6800], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.1975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.2999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.6285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.2872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.7552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.7014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.2255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.0135], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.4469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.7033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.9923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.5165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.8408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.9029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.2513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.5516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.8933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([19.8032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.5288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([9.3052], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.8246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.0895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.7262], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.7753], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.3504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.5217], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.4523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.4144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.6304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.6826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.3451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.2652], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.6773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.5250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([368.8805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.6880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.1341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.9965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.7006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.2926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.0580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.5705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.7035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.9187], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.5433], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.7045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.6401], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.7507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.9554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.7729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.9930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.5996], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.2101], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.7809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.4172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.4582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.0699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.9575], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.3241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.9586], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.8254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.6695], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.7379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.9692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.2518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.5411], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.6096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.4461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.1856], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.2321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.9645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.6653], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3426], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.0593], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.6597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.7803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.4019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.6330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.7395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.5099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.6711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.0309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.1773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.5267], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.0531], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.8033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.9551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.5914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.0391], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.8760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.1444], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.0889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.5815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7836], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.3916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.9613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.6415], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1497], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.7645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.2609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.7601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.3765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.0439], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.2181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.6180], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.2506], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.5647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.8803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.6468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.3243], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.0855], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.3045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.7392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.5115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.5093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.0051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.4874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.8771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.3870], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.3597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.1963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.9473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.7909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.9349], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.6867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([336.1236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.9388], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.9096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.9722], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.8503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.9935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.3997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.2852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.9701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.4229], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.8347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.1008], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.7932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.9312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.8047], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.2033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.8347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.7564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.5005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([371.1939], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.5122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.7523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.5181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.9409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([341.5999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.6354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.0514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.2103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.4941], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.2867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.0952], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.3493], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.4284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.3185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.2357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.9425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.0209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.2135], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.3487], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.7054], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.8176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.8279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.3475], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.6545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.7374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.6076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.7158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.5597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.9635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.9749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.2394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.6769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.2702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.2303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.7029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.5101], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.3150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.1190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.7605], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7267], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.8727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.1600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.5517], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.9115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.3896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.1788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.3300], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.8814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.5078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.1118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.9956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.0003], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.5340], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.5658], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.4707], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.6689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.2910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.1735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.2675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.4832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.7681], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.7587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.4767], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.8113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.0290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.9502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.5959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.4131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.0941], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.6125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.4978], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.8725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.9142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.9710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.1405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([16.7608], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.8727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.8118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.3731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.7107], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.9275], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.7265], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.8271], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.4191], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.2058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.9396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.5299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.8503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.4455], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.6091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.3437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.2047], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.1079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.0862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.9987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.3671], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.3280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.4901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.1199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.7370], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.2942], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.2199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.3841], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.0407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.6458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.0781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.0585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.5862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.7025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.7936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.0947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.6114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.8749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.4430], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.1115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.2259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.7935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.2866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.3157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.9085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.1604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.1458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.1421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.1619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.5452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.0679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.9310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.4237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.7918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.7497], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.2639], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.0762], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.8278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5273], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.8443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.2981], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.5691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.4321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.7654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.3215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.0424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.9314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.5315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.8113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.0956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.4447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.7249], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.5749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.8437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.2370], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.8523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.7447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.2193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.2411], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.1579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.6999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.9656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.2332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.4184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.7669], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.3175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.0204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.2972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.5593], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.2538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.5276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.5352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.9268], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.9546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.0804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.2104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.6970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.9532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.6717], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.5170], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.8036], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5427], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.9863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.8518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.2736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.5083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.4116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.5276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.4059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.2802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.7716], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.3629], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.9993], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.7351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.2241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.3096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.4096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.0914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.1089], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.5476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.0063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.4766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.7419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.9450], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.5392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.1940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.0493], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.6168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.4409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.7045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.2282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.9539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.7876], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.5520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.7813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.5470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.5321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.8175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.5229], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.1725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.2108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.7564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.9478], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.0292], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.4274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.3146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.1159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.9394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.0645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.4897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.9378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.9878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.9768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.0998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.3406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.2133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.5025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.9027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.0950], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.0240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.9513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.7512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.4657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.3274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.8734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.4398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.4852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.1847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.8274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.5243], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.0247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.2341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.5783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5722], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.9574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.9607], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.2617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.2208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.8524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.4235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.7628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.5988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.5408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.7885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.6694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.9747], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.2780], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.4554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.3584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.1935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.3594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.1519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.8209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.8518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.3553], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.3058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.9784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.3282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.4321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.0618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.0069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.1974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.0528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.8711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.7004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.4900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.7398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.5975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.6031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.9143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.9381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.3704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.3080], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.6302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.0246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.5041], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.7657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.9289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.2829], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.6847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.7498], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.3317], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.9909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.3337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.4703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.4596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.6347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.4423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.3295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.0734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.9461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.6823], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.9016], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.7467], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.4144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.6281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.4276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.6030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.7203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.2834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.4133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.0046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.5204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.2970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.7986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.5466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.9133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.2902], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.4732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.7001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.8661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.9190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.7977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.2953], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.8877], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.3926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.4648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.9141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.1339], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.2528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.1066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.1577], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.4920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.3833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.8358], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.3264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.3770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.1179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.2646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.8115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.8689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.9919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.6621], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8050], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.1756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.7045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.1254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.9766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.3323], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.3809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.0735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.4005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.1103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.1645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.2364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.5933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.4806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.7905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.2882], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.0099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.1070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.6688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.8043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.6946], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.6558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.7713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.2766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.6354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.8272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.0659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.8963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.6817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.4315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.0940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.4105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.7757], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.8272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.8648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.9734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.5465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.5070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.3698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.2701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.3180], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.5162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.1628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.8516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.7962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.7920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.1525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.3858], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.1913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.8914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.1644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.6868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.1488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.8771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.2330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.5154], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.9395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.0751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.0665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.6723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.3013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.9284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.9305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.4167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.5461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.7567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.9199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.1445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.5044], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.9732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.5162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.4897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.3379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.7739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.9236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5195], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.0893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.7130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.7743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.9014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.4617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.3004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.9188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.7351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.3065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.6083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.5739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.5816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.9960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.5938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.8395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.8316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.2982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.0589], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.8496], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.8547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.9406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.0491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([343.9070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.5075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.4638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.5543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.9574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.6742], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.9156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9526], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.1394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.3011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.9146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.8149], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.9740], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.7771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.1796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.1582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.7574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.3539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.8442], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.4585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.1974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.8631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.5648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.4818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([43.8008], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.2912], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.0176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.0473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.5535], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.3359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.8743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.4154], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.3176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.6206], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.2956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.2909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.0548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.3104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.3477], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.0807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.4209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.2268], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.7081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.7379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.5408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.7394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.2844], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.2115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.4288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.7244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.5202], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.9137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.2338], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.3335], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.8090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.8205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.1352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.8248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.5114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.2993], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.7313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.4323], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.8861], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.6734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.4633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.8160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.4960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.3471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.3377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.7234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.1443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.2459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.9863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.8239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.5892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.0680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.3619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.2694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.6027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.9651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.3835], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.1568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.5234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.4437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.2570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.0524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.1469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.0721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.5084], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.0743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.1582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.9088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.9443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.3806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.7325], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([4.4755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.9284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.7005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.3675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.7232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.8504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.3341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.9233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.9915], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.6637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.4601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.6187], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0307], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.4159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.4113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.7355], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.0289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.3745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.4513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.2770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.4842], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([45.5702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([345.9850], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.9818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.5558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.6601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.2551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.6916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.6684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.4483], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.3784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.1562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.1232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.7446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.5352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.7204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.9657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.6607], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.6226], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.8035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.8234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.8569], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.8872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.4215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.1961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.3853], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.8364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.7703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.4339], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.4138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.9367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.5072], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.3400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.0645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.6577], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.6875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.0358], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.4919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.0737], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.1827], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.0445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.1581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.7715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.1678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.6970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.6152], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.6416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.4503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.1612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.5683], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.0652], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.2037], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.2099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.4548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.7600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.5250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.4353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.7663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.1604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.2837], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.4209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.0645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.4079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.5821], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.0358], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.3082], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.8846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.1848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.0139], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.4964], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.6369], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.9687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.5757], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([48.6027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.4631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.6110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.9538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.2637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([36.2111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.7005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.5344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.7668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.7539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.8662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.6333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.0527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.7670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.2822], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.4510], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.9813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.7961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.4401], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.2328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.1737], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.1900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.1097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.8219], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.9749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.0684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.6328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.9236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.3913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.7136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.5895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.7114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.5290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.5284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.2667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.2780], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.2972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.7207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.2128], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.7198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.3614], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.7026], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.5597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.4495], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.9572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.4793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.3135], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.7948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.5364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.1906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.6003], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.0776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.7298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.8994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.2662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.4157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.6081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.0095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.7647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.7090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.8250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.2492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.0650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.6568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.8986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([31.7232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.8179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.0714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.9378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.0801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.8198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.4449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.1619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.4178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.8274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.7421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.5866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.5094], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.7092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.1789], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.1623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.0540], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.7013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.3345], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.7641], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.7874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.9650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([29.6830], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.8776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.7031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.5468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.7440], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.5218], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.4384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.2985], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.8715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.2091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.9006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([60.1009], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.9814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.2384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.4518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.2724], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.5960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.5701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.3253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.7627], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.5295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.0840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.5878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.1296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.9346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.7003], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.4804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.4523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.8479], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.4163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.5158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.9509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.9066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.4846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.3353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.6605], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.9379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.5351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.1360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.3372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.3329], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.6112], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.4620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.3698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.8123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.2979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.8210], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.6833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.5201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.1509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.0940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.5036], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.2561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.2889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.1761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.2806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.6428], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.6524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.0074], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.5668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.3776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.6752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.3199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.2785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.3919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.4736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.1538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.1864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([9.9813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.0027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.3440], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.2898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.6480], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.4807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.4954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.9386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.3954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.6230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.7298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6107], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.3648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.9927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.7395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6589], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.0886], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.4132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.3188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.0746], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.4053], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.1785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([27.5569], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.3441], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.8225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.2709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.2265], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.3810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([21.7784], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.6561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.2362], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.2231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.8396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.4989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.9815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.3734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.8248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.1702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.6927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.0643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.7387], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.1380], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.5794], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.0657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.5602], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.2367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.7011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.8971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.4832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.7755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.6901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([58.2828], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.0582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.3421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.5077], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.5704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.4930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.1922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.1459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9349], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.3422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.3076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.7899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.4684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.9281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.6551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.0092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.3691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.7096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.4994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.2104], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.2145], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.3666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.3875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.1484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.4184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.8013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.6001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9048], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.7592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.3377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.4773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.8252], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.7544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.4380], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.2215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.2629], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.5333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.7650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.7994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.0071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.1546], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.6163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.2979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.0479], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([8.4220], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.7647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.7168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.0703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.2990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.9447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.5472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.3910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.5608], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.5094], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.3371], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.8372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.0407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.5788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.3760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.2114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.9347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.8255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.5206], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.6076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.2420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.0144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.6753], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.4772], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.2859], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.8254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.9048], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.5326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.7234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.3837], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.8656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.9328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.3295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.3393], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.7381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.4459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.3162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.3604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.7153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.9597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.2077], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.8256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.3075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.6069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.2330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.4762], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.7446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([19.2344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.2396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.5006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.9320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.9525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.0793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.9636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.1749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.7696], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.0697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.2273], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1292], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.7717], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.0849], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.8002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.5622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.9803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.5299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.7925], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.4609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.0378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.2566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.1812], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.2556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.8251], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.0679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.4889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([23.4191], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.2697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.2308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.1425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.3651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.0216], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.7656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.7406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.2090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.4271], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.5066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.0057], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.6624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.6585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.6399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.4027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.9051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.7067], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.2294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.0379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.6106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.4503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.5305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.9185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.7470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.5277], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.9505], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.5501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.7512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.8803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.6631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.3004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.8462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.9344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.3752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.1290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.6066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.3488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.6392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.1200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.8717], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.0590], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.9002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.3763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.8648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.3043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.3126], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.3353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.4306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.8973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.7607], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.7284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.6223], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6716], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.3625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.4767], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.5661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.7302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.2422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.4628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.0826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.7537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.6785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.9695], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.9011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.5873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.5659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.0408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.0611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.7142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.5929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.3235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.6503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.7200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.0435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.1651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1603], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.8169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.7224], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.0396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([10.8834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([349.8970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.4819], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.4086], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.2138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.8306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.9319], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.9285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.1822], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.8957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.8124], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.7348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.0679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3243], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.8709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.6998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1934], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.4063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.9826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.1625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.7303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([396.2530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.8731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([445.7741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.2018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.1588], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.1920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.2189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.0289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.0173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.1552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.4700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.1921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.1978], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.4863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.6415], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.7661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.2824], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.4241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.5261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.9931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.0945], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.0539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.7306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.0241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.2590], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.5654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.6904], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.1964], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.7748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.6169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.4955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.8542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.7090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.3532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.6630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.7615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.0811], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4151], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.1469], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.6734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.3854], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.0922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.0001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.7776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.0113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.1837], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.9088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.6025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.5143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.2226], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.6079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.7270], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.8981], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.9088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.6913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.9090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.1876], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.9630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.4040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.6407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.6304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.3093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.0312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.4699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.3305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.7431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.8351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.2634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.9348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.0839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.8318], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.7982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.8000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.9787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.4012], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.5673], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.5221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.2434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0109], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.6676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.0495], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.9700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.0155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.8985], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.8999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.6081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.8436], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8429], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.7472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.3688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.0490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.4253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.1571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.0406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.4424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([29.6087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.3412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.7075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.4542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.3484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1353], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.4138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.5860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.2112], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.8364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.4618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.2645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.9456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.0179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.6759], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.6909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.7744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.0701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.7354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.7536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.7244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4249], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.1399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.6662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.4464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.4308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.3219], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.1756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.5667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.9246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.5395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.4765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.7044], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.6356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.7025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.1967], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.0061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([349.7510], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.8646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.0758], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([375.4888], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9417], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.4890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.7110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.2231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.6077], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.4879], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.0366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.3087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.8974], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.0447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.5181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.4317], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.5355], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.8840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.1630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.6103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.2958], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.2265], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.6481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.6051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.6286], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.0692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.1672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.4617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.8279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.9065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.0379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.9085], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.6045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.8474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.0392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.9293], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.3108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.5111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.3166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.8567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.3185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.8537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.4538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.9033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.5144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([385.9421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.2870], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.1520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.0459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([421.6519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.2155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.8760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([39.8862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.3087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.6496], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.4477], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.6246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.2166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.8217], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.7298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.8487], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.0894], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.2919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.6320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([94.0692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.4133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.8977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.1280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.8472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.7397], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.3481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.0000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.5774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.8367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.7424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.3600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.3312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.3889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.0850], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.6400], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.8891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.8255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.7904], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.1285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.0923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.1281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.9194], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.0470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.0686], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.7770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.2123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1319], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.1037], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.4777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.1921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.4452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.5248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.2810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.8889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.0284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.3961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([37.6021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.9143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.8311], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.8290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.0321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.8964], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.3787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.8094], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.8227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.6121], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.0284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.3301], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5228], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3273], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.1208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.1445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.7733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.5378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.4361], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.3908], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.1814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.4928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.1299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.2942], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.3122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([50.0895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.1235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.8963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.9569], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.3795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.3188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.8727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.2816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.9330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.3309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.1734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.9619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([380.4708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.2458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.8697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.2525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.0417], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.4357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.8217], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.7372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.2497], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.5567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.2277], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.2622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([341.8317], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.6347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.6711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.4885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.3874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.4496], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.5942], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.2536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.6987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.1917], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.7804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.5773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.4878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.7562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.7165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.8790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.9624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.5958], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.7302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.7734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.8663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.0088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.4532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.7638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.3889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.0528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.7324], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([409.0769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.2354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.1573], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([374.3568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.8771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.8456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.0988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.6673], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.8798], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.2451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.6738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.6462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.6625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.5779], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.4993], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.4894], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.0303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.8165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.3660], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.0491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.2399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.4751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.9560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.2643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.3931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([13.3261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.9975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.8281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.7081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.9662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.4033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.3766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([24.8916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.6450], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.2401], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.3142], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.8161], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.1959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.6058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.4153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.5441], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.8199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.6274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.7809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.8277], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.2863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.4056], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.7625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([372.7350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([382.4990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.8292], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([0.], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.8687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.3891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.6282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.8253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.7231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.9995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.3571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.6256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.3765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.2068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.2143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.2518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.7557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.0785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.7754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.4096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2413], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([435.4008], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.1598], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.1826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.8926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.4398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.4662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.1411], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.2671], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.3534], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.5405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.0585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.1255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.0711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.9449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.4452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.9330], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.5390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.7454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.4386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.4482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.0515], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.6137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.3223], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.2256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.6143], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.8614], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.7489], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.1043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.4095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.4232], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.8532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.6574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.1233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.7072], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.5342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.1007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.7693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.4912], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.1068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.6457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.6954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.5298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.0347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.8524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.3424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.2071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.1884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.2250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.9013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.2640], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.5449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.0082], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.4365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.6550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.2800], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.8056], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.1348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.1260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.0417], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.1797], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.3831], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.6898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.8980], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.5603], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([373.5711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.2733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.0844], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.6997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.3956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([392.9287], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.8152], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.2282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.4346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([66.1704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.8467], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.4623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.4665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.1697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.1109], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.4096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.0033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.9681], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.4312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.2678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.0072], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([33.2973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.6372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.8149], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.1176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.6197], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([336.5611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.6721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5622], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.5587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.6579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.8374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.0975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.2364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([107.3670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.4856], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.9561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.5584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.8872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.7346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.7077], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.3243], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.8812], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.2671], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.5007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.2166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.2301], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.9660], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.5978], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.1793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.5403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.6125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.7800], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.7884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.4364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.5141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2636], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.9572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.2308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.3434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.7963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.0078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.9649], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.2056], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.1865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.9873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.3940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.1928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.9170], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.5818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.4615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.1821], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.1978], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([436.9745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.7519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.3102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.6529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.9815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.9598], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.9214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.9983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.6512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.2828], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.2193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.6464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.7545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.6711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.2431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.4661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.4185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.9333], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.3334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.3924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.7797], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.8619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.2179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.4406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.4073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7531], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([10.7585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.5316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.8956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.1895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.9214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.8653], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.6053], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.8137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.6806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.1564], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.4205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.4103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.4801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.6863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.0088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.0890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.5983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.0921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.6229], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.3918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.4312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.2898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.2664], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.2746], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.9877], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.0153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.7971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.2642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.9557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.2559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.0918], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.9335], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.6846], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.8282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.2271], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.6099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.0756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.9581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.4847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.3451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.5922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.2874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.7943], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.2778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.4093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.3461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.3180], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.8306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.1174], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.6239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.1243], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.6435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.4637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.9507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.4766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.3238], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.9431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.0932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.9080], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.2177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.6501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.7727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.8530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.6738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.9202], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.2580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.0668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.6630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.6989], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.8528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.7435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.7945], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.7165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.5667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.5665], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.0352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.1302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.7048], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.6322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.5042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.2996], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.1382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.8091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.4700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([355.5644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.2709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.4209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.3971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.2663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.6462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.6255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.0545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.2236], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.5308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.9295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.3650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.5125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.0666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.6300], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.1426], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.7751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.0444], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.7739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.8367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.0240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.9549], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.0050], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.4150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.4960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.8705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.3035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.6871], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.5114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.6178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([324.1173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.0374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([109.7473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.9683], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.5345], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.5179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.8102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.2207], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.3491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.2803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.2414], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.3458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.0674], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.9061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.2876], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.9884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.5907], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.6792], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.6668], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.6022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.6859], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.0847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.0432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.2760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.5150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.4386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.1029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.3463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.4250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.0659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.3326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.0238], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.2369], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.3344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.0491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.7657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.0968], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.7680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.2491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([385.9137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.0218], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.9795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.0186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.7865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.6283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.2181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.0844], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.9214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.4507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.9495], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.5412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.2901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.3443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.1559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.8929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.4770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([40.9401], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.7557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.0042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.8198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.4905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.3441], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.8597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.8900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.4244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.4321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.5162], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.0776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.9425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.1774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.2950], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.6687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.2713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.8452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.5623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.2190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.0884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.9614], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.4031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.8138], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.6738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.9778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.9541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.7863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.8021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([373.0225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.4116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.0782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.2433], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([462.0904], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.8547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.8612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.0972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.9591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.4299], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.6714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.1327], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.1742], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.4301], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.9420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.2527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.1582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.6917], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.6984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.1396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.3845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([394.0621], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.6602], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([316.8567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.8656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.5175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.3474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.0216], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.4253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.3766], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.1214], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.9508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.6796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.2199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.7323], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.3570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.1065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.3254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.0976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.1634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.4030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.3787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.8865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.9611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.8864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.0930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([374.9482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.8356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.6033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.1955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.4079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.1920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.2442], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.1289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.3562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.7878], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7020], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.5042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.8289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.0258], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.8065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.8113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.8998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.9729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.8831], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.7754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.8775], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.0123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.7501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.6215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.4260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.9476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.8819], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([93.6993], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.9678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.7381], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.5694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.7437], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.6027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.0432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.8625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.0966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.4088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.7013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.4860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.6410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.3811], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.5500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.2767], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.2193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.8796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.6679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.0181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.7281], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.2895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.6471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.9680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.5891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.7221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.1040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.2012], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.2984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.5337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.5859], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.5932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.6045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.7407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.6764], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.9666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.3449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.1160], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.1632], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.4332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.8078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.4166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.7407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.0693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.5721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.9496], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([55.5961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.4621], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.6384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.2137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.5153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.1925], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([336.4105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.9159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.0617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([59.9539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([392.3721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.5889], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.1322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.9816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.9604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.1452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.8667], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([386.3570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.8481], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.5372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.1027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.2283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.1069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.2783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.7405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.2095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.6458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.1362], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.1199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.7697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.0911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.0175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.9881], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.3047], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.9528], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.7787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.3136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.2390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.3966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([376.4073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.9741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.9547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.2678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.2896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.8087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.1343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.2623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.5899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.3317], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.3457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.3868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.6010], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.6134], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.4998], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.4914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.9708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.5949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.7124], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.7371], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.4054], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.1463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.0456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([426.2839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.6418], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.6728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.8102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.0055], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.3801], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.2584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.0700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.3600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.6920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.3470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.6222], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.2001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.7558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.6707], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.7213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.8744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.5285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.9361], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.3305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.7115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.2633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.7359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([360.7226], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.9679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.2749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([469.2863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.1862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.7709], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.4567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.5467], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.5213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.0689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.7953], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.3180], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.4893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.6563], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.9246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.0732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.0925], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.3760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([373.2168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.8459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.0786], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.2670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.8639], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([399.7652], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.5009], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.6248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.8168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.0602], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.5470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.7309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.4225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.0868], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.9051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.5260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.8988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.8364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.1449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.3435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.3708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.6081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.2612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.1322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.6443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.4721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.4563], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.6366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.5019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.9307], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.6734], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.6867], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.0337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.0805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.8367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.1438], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.3971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.7845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.8174], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.6302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.4635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.8866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.5499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.4044], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.6380], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.5076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.4431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.6919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.2390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([372.2725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([436.4693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.3842], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.8672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([375.8390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.4129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.2816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([5.0079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.1997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.4803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.8314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.5961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.3298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.4996], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1640], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.0595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.1257], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.8976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.7663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.2049], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([402.4078], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.9999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.6892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.2419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.2703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.6962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([360.7815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([389.1458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([387.5173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([410.3015], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.6741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.3230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4258], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.5853], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.4713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.8357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.5550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.7530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.0365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.9714], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.0527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.5691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.3730], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9566], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.6371], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.1720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.4645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.7144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([413.0382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([471.7457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([481.3675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.3625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.8322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([405.7792], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([316.2708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.6289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.3746], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.8499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.0763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.4518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.1007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.4604], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.0046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.0717], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.7032], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.8631], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.1252], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.4933], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([348.4530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([343.4783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.6963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.3425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.1091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.4517], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([358.8872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.0184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([391.8782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.8971], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.1680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.2092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.9845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.3384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.4474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.6464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.7832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.6548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.7815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.2169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.8155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.6732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.2978], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.3120], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.9408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.3396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.8171], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.5757], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([430.1619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.6240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([391.8595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([456.1502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([369.9189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.3683], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.4027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.1670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.7783], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.5728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.1438], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.9390], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.8092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.1810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.7070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.6576], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.4962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.2108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.3699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.0536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([417.3087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.6948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.4760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.2896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.4164], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([378.8936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.1927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.6021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.2727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.8011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.2171], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.2030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.8061], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.0410], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.4297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.3689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.2522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.8789], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.9725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.6508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.8556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.4464], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.4446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.6707], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.4005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([459.3753], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.7235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([461.0970], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.0988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([488.1648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.4916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([422.0001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.2788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.5194], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.6624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.4544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.5898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.0986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.9006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.5722], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.8906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.6169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([355.8459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.5898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.2133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([355.2741], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.6555], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.3322], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.9328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.8454], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([406.9731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([444.4651], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.9676], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([426.2743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.0091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.0036], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.0484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.1943], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.7116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.4274], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2916], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.4777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.4165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.9613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9584], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.3462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.7793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.2702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.0771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.3969], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([349.0253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.0548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([414.6832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.4975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.5560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.2618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.1693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([432.8052], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.7262], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.2060], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.4361], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.9150], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.9756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.5984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.4786], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.6866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.4024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.7581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.5731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.4201], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.9507], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.1854], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([430.6204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.2099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([438.6291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.4740], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.4908], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.4976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([481.0497], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.3946], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([387.2848], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.8663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.2014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.2470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.2843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.5302], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.6303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.7574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.7391], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.6581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.5367], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7265], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.9749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.4007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.7435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([392.8064], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.2133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.5708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([411.1313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.2504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.4728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.7697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.9648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([421.3406], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.1291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.8638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.7609], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([47.3013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([91.5366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.9779], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.4279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.5511], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.5498], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.4840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.7242], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.2206], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.4699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.0506], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.2799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.2358], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.3560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([438.4501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.3578], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([345.3351], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.2827], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.0208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([475.8227], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.7107], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.9449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.4750], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.7863], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.7435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.9121], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.6432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.5130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.3535], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.3213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.3371], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.1763], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.1662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.5462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.2388], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.2347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.1695], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.3778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.9470], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.4081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.9141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.7829], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.2849], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([431.7513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.7027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.4555], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.4716], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.3513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.5427], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.1774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.5838], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.1079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.9512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.2579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.8331], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2385], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.1230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.8289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.9943], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.5728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.7554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.3685], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.0153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.4192], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.6702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.0727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.7017], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.0427], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.4314], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([28.8432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.9452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.0422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.7042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.4184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.4362], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.0456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.8554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.6544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.2851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.1369], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.9884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.9276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.9827], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.0666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([358.1076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.5110], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([450.9870], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.3185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.7705], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.9001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([396.4587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.2030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.4827], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.1141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.0167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.9628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.2364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.1346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.9790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.2294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.9262], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.1177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.7847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.8899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.7886], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.5356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([413.8167], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([437.3625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.6125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.5516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.1035], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([348.5471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([402.4731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.8937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.7376], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([70.0055], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.3526], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.3223], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.3356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.8630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.5419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.5310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.1845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.3649], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.1759], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.2937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.5672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.4383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.1781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.5529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.1382], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.4893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.5290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.9831], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.8266], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.0647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.2637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.8694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.0337], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([14.1033], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.1885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.0539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.6682], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.6995], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.0133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.2303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.4634], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6772], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.5294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.7082], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2341], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([340.8122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.4017], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.9704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([348.1762], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.6365], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.5140], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([378.3375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.1246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.7076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.8471], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.0327], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.4543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.6509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.3269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.3630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.8008], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.4375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.9791], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.1949], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.0027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.8296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([390.9135], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.8575], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.1069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.1623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([446.4242], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.8409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([456.1249], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.3097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.6359], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.5817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.3244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.3293], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.2412], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.7624], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.0944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.5379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.9965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.0155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.6130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.2884], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.6102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.5692], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.8051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.3482], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.8618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.2065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([417.6666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([407.1264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.1540], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([428.0944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.4761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([381.0182], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.8284], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([372.0246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([488.2263], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.8525], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.1901], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.5041], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.8264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.0536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.0254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.1650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.9393], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.9580], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.6648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.3781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.5955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.4793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.0836], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.8175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.6325], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.1265], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([419.8760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.0309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.5082], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.2195], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.5348], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.4805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.2244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.5694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.4911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.9772], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.1832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.8885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.8851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.3723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.3241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.5594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.9522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8560], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.1080], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.2543], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.3670], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.8972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.4946], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.5021], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([417.8625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.9735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.2688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([432.4083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.3375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([385.7907], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8981], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.1765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.0276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.9699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1517], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.4915], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.2153], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.8558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.9987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.7983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.9492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.5542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.4890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.5105], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.0474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.5326], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.7758], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.1857], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.6158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.7093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.6374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.6383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.0059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([423.7286], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.9930], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.7134], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.4190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.1685], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.1476], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.6389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.0334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.9456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.4866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.7790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.5241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.1898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.9957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.6875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.3098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([407.8177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.4432], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([493.8421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([493.4658], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.6956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.5296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.1296], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.0069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.4552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.3575], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([4.2879], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.4984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.2372], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.2140], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.9159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.8096], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.4619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.2804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.9639], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.3415], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([369.4648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.1739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.8163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([373.0579], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.2238], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.3498], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.5904], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.8010], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.7421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.1972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.9725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([56.4319], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.0209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([69.7197], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.6799], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.3502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.9111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.8043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.5693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.8392], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.0778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.1508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.5500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.5582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([390.3691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.2118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.3157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.0697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([378.5102], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.4212], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.6963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.1205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([436.1866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.5254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.8838], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.8841], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.3136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.5152], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([110.2736], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.7522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.5617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.8258], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.5420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.4000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.6177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.7937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.2036], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([378.5672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.1193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.0637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.0360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.2048], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([386.9688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.4328], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([402.3439], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.2379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.6541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.8209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.3719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.1804], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.1777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.5770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.6955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.9745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.6845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1724], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.5374], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.9523], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.7689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.7039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.6635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.2285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.1770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.2642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.2420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([434.8735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.2383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.9639], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.9773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.3083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([428.9386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.8758], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.9114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.2144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.2460], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.9006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.5689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.0956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.2823], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.9924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.4001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.5872], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.6913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.0465], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.9224], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.6600], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([410.1850], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.1364], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.1435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.5453], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.4260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.9984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.2797], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([435.9633], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.6093], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.4532], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.7586], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([63.0836], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.2028], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.3976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([226.8398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.5193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.9855], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.0768], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.2117], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.0841], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.1958], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.3177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.3821], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.6063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.8403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.8103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.5256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.6282], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.9693], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.4184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.6449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([340.7228], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.8081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.1655], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.3954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([311.9690], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.0246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2508], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.7941], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.7529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.8522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([378.7656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.0255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.0247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.9356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.6830], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.8644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.6922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([369.4632], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.5157], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([147.7230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.8547], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.3416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.8739], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.2947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.6788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([72.1458], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.9079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.8644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8608], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.8945], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.6723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.7305], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.2874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.5810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.4190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.9950], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.7334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.0630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.8336], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.9834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([391.5778], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.4173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.9796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([392.3583], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.0972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([380.5630], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.8645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([404.3280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.1098], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.1264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.9514], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.3845], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([125.2726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.4926], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.1290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.3472], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.7198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([387.7898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.6964], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.0249], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.4368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.1092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.7199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.0585], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.2483], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([339.5663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.2292], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.1423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.0362], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([422.5211], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.3130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.6991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.2654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.7161], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.2574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.2951], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.5608], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.9500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.6204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.1983], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.5468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.7751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.2722], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.0136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.6277], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([386.4575], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([371.1642], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.7182], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([335.5659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([477.3687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.4355], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.7654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([354.0190], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([384.8011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.1099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.4899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([96.9310], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.7666], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.7370], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.3957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.1176], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.2922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.9006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.8246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.5087], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.6672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.7911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([341.0448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.9462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.7259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([339.2338], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.3637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.1060], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.7137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([340.5663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([433.8172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.1320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.7384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1417], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([73.7354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.8913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.5237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.8948], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.4595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.6686], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1540], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.4403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.2139], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.0225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.4422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.9905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.3099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([403.6161], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.9727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([252.7701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([412.6550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([400.8704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.5213], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([417.9723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([306.3553], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.7534], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.3728], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.6522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.6999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.1931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.3625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.8316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.4537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.4188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.9847], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.5151], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.2244], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.0370], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.4111], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.7957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.2908], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([411.7737], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.7874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.3883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.3474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.9689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.5135], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.8885], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.7818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.8062], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.3550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.5592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.3276], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4057], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([106.6711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.5653], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.3905], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.7940], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.6552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.2155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.2876], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.0686], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.9449], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.8490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.9869], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.8903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.2510], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.0965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.9723], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([369.2083], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([473.4790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([394.9288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.0404], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.1168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([108.4597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.4815], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.3563], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.9209], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.0754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.9304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.1520], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.4569], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.3340], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.1745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.3959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.5147], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.0856], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.8691], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.7004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.3103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.2927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.9466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([321.7419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.2906], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([355.9408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.5357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.8703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.4518], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.2678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.6315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.4474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([148.4711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.3542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.1647], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.8014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.6308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.5452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.8883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.1059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.8541], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.7891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.1298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([376.7027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([393.7699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.1927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.5247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.5040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.5977], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([441.9415], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.8860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.4427], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.1185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.4688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.6587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.1596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.4645], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.8027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.6034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.7042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.9360], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.1283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.3130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.5794], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([271.5363], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.2826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.9984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.8965], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.2445], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.5572], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.0473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.7720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.8130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.8829], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.5039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.9220], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.2771], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([74.3041], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.5710], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.5345], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.7646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([229.2656], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.3272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.4761], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.4298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.7188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.2726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.3247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.0126], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.4538], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.4588], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.9342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.8984], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.7193], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([382.3599], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.4285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.8816], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.8363], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.6946], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.7290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.9301], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.8402], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3225], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.8556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.1882], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.1148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.0699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.9542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.6754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.3486], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.1920], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.4189], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.7548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([376.4874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([388.5519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([434.7807], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([370.5053], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([524.6653], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([403.3478], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([410.4802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.7267], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.2765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.7928], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.4247], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.5755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.3703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.3294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.8076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9657], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.4204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.1217], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.3352], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.5001], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.6810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.3773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.7960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([389.9115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([410.9169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.5787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([479.5536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.5826], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.6931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.1638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.0198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.6764], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.5407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.2168], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.4399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.9073], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.0527], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.2548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([221.2832], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.6264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.9744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.8131], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.7030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.5172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.9596], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([340.5060], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.0448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.4173], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.9902], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.0069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.2208], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.6617], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([456.7924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([430.7260], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([437.6529], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.8434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.0499], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([20.9347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.4664], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.2786], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.3428], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.6025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.5025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.0011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.9852], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.5840], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.7269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.5030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.4809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([381.6158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.2046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.4440], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([334.2090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.1198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([314.5591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([376.0126], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.4721], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.4551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.7199], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([87.1979], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.2632], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.7203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.5228], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.0688], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.5081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.6063], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([197.2060], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.4810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.8306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.2156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.5929], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.6070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.0732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.5909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.4517], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.9749], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.1123], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.2002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.2172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.5986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.5434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.8742], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.8648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.8913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.0188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.2354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.3166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.4492], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.0315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.9346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([84.4238], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([265.2638], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.2368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([270.9156], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([318.8311], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.5501], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.9745], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.8460], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([339.9309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.8511], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.0076], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.6309], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.9680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([308.7241], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.7169], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([397.4680], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.5068], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.9203], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.4973], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.9233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.0819], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.8459], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.0650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.2720], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.1375], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.4502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2576], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.7982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.9044], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.1865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.2849], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([319.5245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([377.9559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.6533], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.5259], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.8280], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.1283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([423.1582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([440.5825], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.9782], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.8266], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.6776], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([150.7321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([157.9435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.0177], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.1700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.3279], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.9819], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.4137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.8184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([246.4349], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([242.6456], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.4865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([333.3483], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.0650], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.0558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.4103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([397.1230], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([367.3654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.9293], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.5205], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.9303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.0748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.5045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.7589], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.8750], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([68.5181], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.9025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([124.0307], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.2706], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.2935], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([304.7790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.9048], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.8384], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.9663], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.0234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.4623], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.1366], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.4141], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.3075], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.1985], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([485.3335], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.8252], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.4590], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.4239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([316.8070], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.8555], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([198.2014], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.0702], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.0121], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.5079], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.0106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.4378], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.9233], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.4246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.3932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.0873], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.9137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.1130], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.4628], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.6586], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.1900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([413.8620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([440.6446], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([380.2254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.4992], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([326.6917], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.8966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([382.4195], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([340.8561], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.8344], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.3051], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.9474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.9964], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.7013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.2616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.6646], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.8398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.4103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.0582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.6612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.0438], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.7779], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.3643], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.1509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.0574], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.2548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([361.3086], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([269.2938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.4577], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.4038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([292.5024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([382.5395], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.6306], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5335], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([4.4769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.3158], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([49.7803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.2231], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.2240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.1245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.7040], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.1269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.8729], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.2421], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.3810], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.6802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.6681], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.8711], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([278.4081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.8694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.9715], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([294.3777], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.1559], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.3509], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.9295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([366.1955], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([146.6139], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([119.5644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.2805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.6155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.2947], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.0430], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.7611], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.5993], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.6092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.1890], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.1689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.5017], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.8416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([342.4903], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.0954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.9018], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.2090], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.0500], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.3936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.8896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.6393], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([301.1954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.0325], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.2332], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.2558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.3963], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.4931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.8448], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.0898], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.0485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.3987], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.2300], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.9687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.0866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([285.5954], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.4793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([234.3253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.5065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.7910], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.6002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.3215], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.7976], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([52.9071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.7291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([444.2582], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([254.1357], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([253.5118], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([309.0921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.0037], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.0505], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([228.6397], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.5661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([339.7257], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4738], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([255.6923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([416.2043], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.2960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0593], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.3175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([41.1891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.6809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.6466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.3698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.0092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([34.4494], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.0704], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.2114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.1146], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.2052], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.6250], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.1116], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.3434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.3308], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.5462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.5129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([379.0066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([215.8862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([418.8931], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([357.2196], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.3272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([406.0285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.1869], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([158.6962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.4447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.6927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.6513], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.1708], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.3866], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.2860], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([235.7494], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([240.7304], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([195.4731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.0781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.2813], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.2435], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([259.1058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.1126], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.6394], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.1321], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([276.8752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([353.2420], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([355.7755], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.0246], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.5859], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.0095], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.5159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([26.9635], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.1581], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([65.6982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.0433], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.1530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4271], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.1356], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([80.9257], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([88.2222], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([312.9283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.9618], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.6312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.1059], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([280.5113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.9895], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([341.9129], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.6530], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([425.4911], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.6512], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([351.1019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.0864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.5191], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.0531], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.2091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.2982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.6790], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([115.5024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([151.7814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([86.2022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.6719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.1744], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.8086], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.2347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.7649], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.4034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.8606], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.7914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.9431], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.4320], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([381.4460], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.4599], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.4975], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.1594], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.8788], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.2355], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.7684], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.1519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([78.8969], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.8452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.0239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.5959], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.1503], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1849], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5900], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.4990], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.8726], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.4626], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.5347], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.4568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.5403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([200.5519], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.4834], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.4303], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.0398], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([327.3697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([313.1488], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([330.1195], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.5175], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.0567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([392.7803], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([382.0698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.9385], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.2007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.8204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.9354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.1577], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.7787], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.3030], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3504], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.6424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.1796], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.5000], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.1874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.5961], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.9411], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.3896], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.4316], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.3874], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.8468], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([396.4396], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([262.7921], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([364.3124], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.5255], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([346.1423], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.3055], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.4703], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.2648], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.2055], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.9844], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.0653], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([85.2814], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.0165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.2902], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4234], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.1536], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.1426], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.3735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([258.5875], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.9672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.2186], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.8899], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([329.5913], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([383.8515], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.7802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.2614], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([401.0769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.6386], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.1748], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([267.7108], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([207.3743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.3389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.3285], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.5088], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.2473], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.1851], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.0751], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.4843], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.0354], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.2342], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([284.2039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.7407], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.2795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([272.1793], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([305.3219], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.8524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.0952], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([344.1544], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.3144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([105.3318], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([341.2058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([249.8770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.6127], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([298.2839], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.0659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.2113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.5298], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([76.3022], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([190.4686], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.9773], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.4433], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.0937], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([154.8597], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.4981], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.8571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.1012], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.3567], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.5106], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.4502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([183.6071], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.5113], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([239.6924], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([399.7239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([245.0957], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.2724], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.9932], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.8054], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.6922], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([168.2498], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([46.7701], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.3350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([53.9184], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.0066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.2240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([71.1451], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.8049], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.7122], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.9545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.1592], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.4615], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.9293], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.8148], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.2522], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([331.7735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.7452], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.3133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([232.1626], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.7966], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.0919], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([420.0269], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([332.6893], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.4713], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.9422], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.0770], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.5539], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.1109], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([103.1593], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0502], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.0081], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.8625], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.6936], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.8545], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.2125], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([261.9662], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.6112], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([193.9681], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([348.4325], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.0200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([363.2644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.6253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.1757], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.7694], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.6447], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.4002], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([79.3272], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.8409], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([162.9103], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([67.5029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([182.8425], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([57.1521], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([144.4058], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([62.0315], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.3587], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.0350], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.5163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.2586], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.3756], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([204.0732], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.9969], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.8300], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([328.9204], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.5006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([352.9133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.3038], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([299.1601], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([478.8424], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([282.3859], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([398.2137], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.1197], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([260.6253], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.9387], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.5383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.3433], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.0485], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.5727], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.7159], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.4408], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.4327], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.0865], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.0463], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([256.3151], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.1997], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.6066], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.8312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.2758], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.5956], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.9599], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.8133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([279.3914], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([291.7178], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([244.7334], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([422.1892], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.7254], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.4019], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([130.5556], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([131.2443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([145.2698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.0185], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([75.8144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([166.8089], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.4654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.8462], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.6752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.0047], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([201.5733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([295.4661], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.4289], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([257.5672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.2183], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.9731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.0743], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([315.3524], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([293.8466], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.7654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([275.2833], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([432.8461], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.5620], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([206.6809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([268.4551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.9127], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([222.1312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.0960], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3754], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([177.8548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([220.0725], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.2136], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.7144], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.3962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([322.9785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([231.9323], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([227.3163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([139.4595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.0641], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.9419], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([233.1897], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([410.0251], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.2179], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.8343], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([338.0313], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([203.3132], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.3938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.3972], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.5764], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.0025], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([112.0687], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.8266], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.3092], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.4099], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([179.5505], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.1034], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.2379], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.5297], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.9403], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([297.9319], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([359.9237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([236.2434], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.8938], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([247.7923], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.1802], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.3166], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([287.9612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.5909], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([281.8264], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.8474], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.7383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([38.9537], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([83.9817], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([95.8750], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.3042], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.1188], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([165.9497], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.1256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([32.5654], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([212.0557], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.5261], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.4312], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([213.4346], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.4006], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.9769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([117.3707], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.5904], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([347.7240], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([153.4765], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([286.2655], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.9591], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([317.5045], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([216.1155], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.5165], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.9283], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([10.4516], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([97.1383], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([189.6542], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.6733], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([64.9377], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.5570], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.6065], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.9319], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([274.6986], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.5644], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.7576], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.7698], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([320.4161], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.3114], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([126.5578], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([225.4091], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([316.4750], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.2719], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([277.8552], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([289.1221], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([266.0551], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([202.6944], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([136.3968], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([122.7413], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([167.5612], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.4031], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.5864], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([192.3010], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([140.1659], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.8781], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.5700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([173.2237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([185.0595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([188.4235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([224.6029], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([302.5548], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.6368], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([205.7007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.8681], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.1013], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.3491], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.5235], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.2115], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.9027], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([19.9443], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.7278], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([81.3675], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([121.9678], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([54.9323], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([98.1550], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.5418], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.5457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([90.6005], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.9818], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.6774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([209.4222], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([248.2891], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.2245], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([307.2880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([160.0007], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([251.7605], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([174.2405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([273.5290], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([365.4619], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.9376], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([163.7202], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([325.1369], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([324.5511], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([199.7907], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([180.7047], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([132.4752], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.2805], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([89.1490], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([102.8295], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([127.3994], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.8198], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.8291], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([175.6798], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([238.6735], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([218.8202], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([217.0248], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.3154], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([208.6927], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([264.9568], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([237.4968], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([243.0558], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([219.8613], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([135.8712], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([99.6697], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([303.1256], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([300.1237], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.9389], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([290.7679], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([77.4318], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([100.7672], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([35.2440], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([82.3172], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([114.7097], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([116.2883], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([156.7133], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.5595], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.1399], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([142.3163], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([129.7862], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([137.1842], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([176.2652], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([184.2200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([152.8101], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([161.5988], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([178.4239], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([172.8999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3760], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([211.8731], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.7024], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([283.6706], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([310.6039], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([296.4700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([61.5880], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([104.6011], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([42.5506], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([118.1769], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([181.3962], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([101.7982], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([149.2699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.6991], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.3689], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.4700], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([169.9455], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([111.0288], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([250.7785], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([356.0127], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([164.1571], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([288.3046], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([133.9795], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([170.8069], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([134.8484], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([336.9004], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([323.3809], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([138.3349], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([350.5294], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([187.5200], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([191.8637], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([113.9554], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([123.9786], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([159.8275], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([120.1871], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([128.8140], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([141.7405], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.0455], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([143.6416], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.5806], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([51.1457], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([155.3683], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([186.5774], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([92.1074], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([194.1699], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([241.8789], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([210.3999], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([196.3562], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([214.4603], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([230.4820], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([223.8119], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([337.9716], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([171.9616], grad_fn=<UnbindBackward0>)\n",
      "OUTPUT tensor([263.3965], grad_fn=<UnbindBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_output = []\n",
    "for output in test_outputs:\n",
    "    print('OUTPUT', output)\n",
    "    list_output.append(output.item())\n",
    "\n",
    "len(list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2df9f6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.890083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.202118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.364738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.930027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.578465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>230.481964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>223.811874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>337.971558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>171.961578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>263.396515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      90.890083\n",
       "1      27.202118\n",
       "2      43.364738\n",
       "3      43.930027\n",
       "4      32.578465\n",
       "...          ...\n",
       "6488  230.481964\n",
       "6489  223.811874\n",
       "6490  337.971558\n",
       "6491  171.961578\n",
       "6492  263.396515\n",
       "\n",
       "[6493 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame(list_output)\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a3cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('muchomorki.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979d00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c89dac2000cd39b6c6afdbb40384525553e908a214fa5e3caa43ad6708c415f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
