{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"3a7aaad0630ad3230b7b955ab34166b9352cf35c53f01b298fd4177c5371ed1f"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports, setting up device and seeds","metadata":{"id":"5_Aw62xaLFLv","jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n \n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\n\nimport torch.optim as optim\n\nfrom torch.utils.data import DataLoader, random_split","metadata":{"id":"-kQDdETmLHWI","execution":{"iopub.status.busy":"2023-01-10T20:48:28.499957Z","iopub.execute_input":"2023-01-10T20:48:28.501075Z","iopub.status.idle":"2023-01-10T20:48:28.510086Z","shell.execute_reply.started":"2023-01-10T20:48:28.501033Z","shell.execute_reply":"2023-01-10T20:48:28.508528Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\n\ndef set_all_seeds(seed):\n    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_all_seeds(42)","metadata":{"id":"b2OuFOjAHMLP","execution":{"iopub.status.busy":"2023-01-10T20:48:28.512692Z","iopub.execute_input":"2023-01-10T20:48:28.513689Z","iopub.status.idle":"2023-01-10T20:48:28.523991Z","shell.execute_reply.started":"2023-01-10T20:48:28.513524Z","shell.execute_reply":"2023-01-10T20:48:28.522865Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\")\ndevice = torch.device('cpu')\n# device = torch.device('mps')","metadata":{"id":"lkXBboDtLI6G","execution":{"iopub.status.busy":"2023-01-10T20:48:28.526191Z","iopub.execute_input":"2023-01-10T20:48:28.526995Z","iopub.status.idle":"2023-01-10T20:48:28.533951Z","shell.execute_reply.started":"2023-01-10T20:48:28.526953Z","shell.execute_reply":"2023-01-10T20:48:28.532914Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Constants","metadata":{"id":"dXiojnk_HvZA","jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"VALIDATION_PERCENTAGE = 0.025504348 # we want only 1000 images in validation dataset for FID score\nTRAIN_PATH = \"/kaggle/input/traffic/trafic_32\"\n# TRAIN_PATH = \"./trafic_32\"","metadata":{"id":"xAKB2OBkHve9","execution":{"iopub.status.busy":"2023-01-10T20:48:28.537081Z","iopub.execute_input":"2023-01-10T20:48:28.537578Z","iopub.status.idle":"2023-01-10T20:48:28.545805Z","shell.execute_reply.started":"2023-01-10T20:48:28.537536Z","shell.execute_reply":"2023-01-10T20:48:28.544671Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{"id":"sejxvF56H7N7","jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"%%time\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\nbatch_size = 256\n\ntrainFolder = torchvision.datasets.ImageFolder(root=TRAIN_PATH,\n                                               transform=transform)\n\nn_val = int(np.floor(VALIDATION_PERCENTAGE * len(trainFolder)))\nn_train = len(trainFolder) - n_val\n\ntrain_ds, val_ds = random_split(trainFolder, [n_train, n_val])\n\ntrainloader = DataLoader(train_ds, batch_size=batch_size, drop_last=True, shuffle=True)\nvalidloader = DataLoader(val_ds , batch_size=batch_size, drop_last=True, shuffle=True)","metadata":{"id":"V77_sxtXPa7v","execution":{"iopub.status.busy":"2023-01-10T20:48:28.547590Z","iopub.execute_input":"2023-01-10T20:48:28.548062Z","iopub.status.idle":"2023-01-10T20:48:52.848970Z","shell.execute_reply.started":"2023-01-10T20:48:28.548023Z","shell.execute_reply":"2023-01-10T20:48:52.847849Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CPU times: user 988 ms, sys: 1.54 s, total: 2.53 s\nWall time: 24.3 s\n","output_type":"stream"}]},{"cell_type":"code","source":"next(iter(trainloader))[0].max()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:52.850537Z","iopub.execute_input":"2023-01-10T20:48:52.851096Z","iopub.status.idle":"2023-01-10T20:48:53.098027Z","shell.execute_reply.started":"2023-01-10T20:48:52.851053Z","shell.execute_reply":"2023-01-10T20:48:53.096934Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor(1.)"},"metadata":{}}]},{"cell_type":"code","source":"# takes images from valid dataset\ndef get_train_images(num):\n    return torch.stack([val_ds[i][0] for i in range(10,10+num)], dim=0)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:53.099820Z","iopub.execute_input":"2023-01-10T20:48:53.100527Z","iopub.status.idle":"2023-01-10T20:48:53.107092Z","shell.execute_reply.started":"2023-01-10T20:48:53.100483Z","shell.execute_reply":"2023-01-10T20:48:53.105805Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation - Frechet Inception distance","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom scipy import linalg\n\n\ndef calculate_frechet_distance(distribution_1, distribution_2, eps=1e-6):\n    mu1 = np.mean(distribution_1, axis=0)\n    sigma1 = np.cov(distribution_1, rowvar=False)\n\n    mu2 = np.mean(distribution_2, axis=0)\n    sigma2 = np.cov(distribution_2, rowvar=False)\n\n    \"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n    Stable version by Dougal J. Sutherland.\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an\n               representative data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an\n               representative data set.\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"\n\n    mu1 = np.atleast_1d(mu1)\n    mu2 = np.atleast_1d(mu2)\n\n    sigma1 = np.atleast_2d(sigma1)\n    sigma2 = np.atleast_2d(sigma2)\n\n    assert mu1.shape == mu2.shape, \\\n        'Training and test mean vectors have different lengths'\n    assert sigma1.shape == sigma2.shape, \\\n        'Training and test covariances have different dimensions'\n\n    diff = mu1 - mu2\n\n    # Product might be almost singular\n    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n    if not np.isfinite(covmean).all():\n        msg = ('fid calculation produces singular product; '\n               'adding %s to diagonal of cov estimates') % eps\n        print(msg)\n        offset = np.eye(sigma1.shape[0]) * eps\n        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n\n    # Numerical error might give slight imaginary component\n    if np.iscomplexobj(covmean):\n        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n            m = np.max(np.abs(covmean.imag))\n            raise ValueError('Imaginary component {}'.format(m))\n        covmean = covmean.real\n\n    tr_covmean = np.trace(covmean)\n\n    return (diff.dot(diff) + np.trace(sigma1) +\n            np.trace(sigma2) - 2 * tr_covmean)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:53.109096Z","iopub.execute_input":"2023-01-10T20:48:53.109919Z","iopub.status.idle":"2023-01-10T20:48:53.124163Z","shell.execute_reply.started":"2023-01-10T20:48:53.109878Z","shell.execute_reply":"2023-01-10T20:48:53.123076Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Evaluator","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"class Evaluator(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(Evaluator, self).__init__()\n\n        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n        self.fc_2 = nn.Linear(hidden_dim, 50)\n        self.fc_out  = nn.Linear(50, 43)\n        \n        self.LeakyReLU = nn.LeakyReLU(0.2)\n        \n    def get_features(self, x):\n        x = torch.flatten(x, 1)\n        x = self.LeakyReLU(self.fc_1(x))\n        x = self.LeakyReLU(self.fc_2(x))\n        return x\n    \n\n    def forward(self, x):\n        x = self.get_features(x)\n        x = self.fc_out(x)\n        return x\n\nevaluator = Evaluator(32*32*3, 256).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:53.128361Z","iopub.execute_input":"2023-01-10T20:48:53.129049Z","iopub.status.idle":"2023-01-10T20:48:53.148936Z","shell.execute_reply.started":"2023-01-10T20:48:53.129006Z","shell.execute_reply":"2023-01-10T20:48:53.148099Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Optimizers\noptimizer = torch.optim.Adam(evaluator.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97)\n\n# loss\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:53.150550Z","iopub.execute_input":"2023-01-10T20:48:53.151336Z","iopub.status.idle":"2023-01-10T20:48:53.157067Z","shell.execute_reply.started":"2023-01-10T20:48:53.151234Z","shell.execute_reply":"2023-01-10T20:48:53.156126Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_epochs = 2\nfor epoch in range(num_epochs):\n    for data, targets in iter(trainloader):\n        data = data.to(device)\n        targets = targets.to(device)\n\n        results = evaluator(data)\n        loss = criterion(results, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:48:53.158424Z","iopub.execute_input":"2023-01-10T20:48:53.158923Z","iopub.status.idle":"2023-01-10T20:49:42.895705Z","shell.execute_reply.started":"2023-01-10T20:48:53.158889Z","shell.execute_reply":"2023-01-10T20:49:42.891742Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3240204468.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[1;32m    229\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3075\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3077\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"num_correct = 0\ntotal_guesses = 0\n\nevaluator.eval()\nwith torch.no_grad():\n    for data, targets in iter(validloader):\n        # Sends data and targets to device\n        data = data.to(device)\n        targets = targets.to(device)\n\n        # Acquires the network's best guesses at each class\n        results = evaluator(data)\n        best_guesses = torch.argmax(results, 1)\n\n        # Updates number of correct and total guesses\n        num_correct += torch.eq(targets, best_guesses).sum().item()\n        total_guesses += len(targets)\n\nprint(\"Correctly guessed \", num_correct/total_guesses*100, \"% of the dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:49:51.476138Z","iopub.execute_input":"2023-01-10T20:49:51.476549Z","iopub.status.idle":"2023-01-10T20:49:55.826523Z","shell.execute_reply.started":"2023-01-10T20:49:51.476515Z","shell.execute_reply":"2023-01-10T20:49:55.825366Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Correctly guessed  60.546875 % of the dataset\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"CP3xKDyuSc5X","jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, latent_dim):\n        super(Encoder, self).__init__()\n\n        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc_mean  = nn.Linear(hidden_dim, latent_dim)\n        self.fc_var   = nn.Linear(hidden_dim, latent_dim)\n        \n        self.LeakyReLU = nn.LeakyReLU(0.2)\n        \n        self.training = True\n        \n    def forward(self, x):\n        x = torch.flatten(x, 1)\n        x       = self.LeakyReLU(self.fc_1(x))\n        x       = self.LeakyReLU(self.fc_2(x))\n        mean     = self.fc_mean(x)\n        log_var  = self.fc_var(x)                      # encoder produces mean and log of variance \n                                                       #             (i.e., parateters of simple tractable normal distribution \"q\"\n        \n        return mean, log_var","metadata":{"id":"5psxvca0PG8p","execution":{"iopub.status.busy":"2023-01-10T20:49:58.538073Z","iopub.execute_input":"2023-01-10T20:49:58.538453Z","iopub.status.idle":"2023-01-10T20:49:58.547380Z","shell.execute_reply.started":"2023-01-10T20:49:58.538408Z","shell.execute_reply":"2023-01-10T20:49:58.546078Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, latent_dim, hidden_dim, output_dim):\n        super(Decoder, self).__init__()\n        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n        \n        self.LeakyReLU = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        h     = self.LeakyReLU(self.fc_1(x))\n        h     = self.LeakyReLU(self.fc_2(h))\n        \n        x_hat = torch.sigmoid(self.fc_3(h))\n        x_hat = x_hat.view([-1, 3, 32, 32])\n        return x_hat","metadata":{"id":"EnKbjbvKT-fI","execution":{"iopub.status.busy":"2023-01-10T20:49:58.713669Z","iopub.execute_input":"2023-01-10T20:49:58.714408Z","iopub.status.idle":"2023-01-10T20:49:58.721988Z","shell.execute_reply.started":"2023-01-10T20:49:58.714371Z","shell.execute_reply":"2023-01-10T20:49:58.720834Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, x_dim, hidden_dim, latent_dim):\n        super(VAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n        self.decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n\n        \n    def reparameterization(self, mean, var):\n        eps = torch.randn_like(mean)\n        z = eps * var + mean\n        # z = np.random.normal(mean, var)\n        # z = mean # Change to proper sampling\n        return z\n        \n                \n    def forward(self, x):\n        mean, log_var = self.encoder(x)\n#         print(\"mean log_var\", mean.shape, log_var.shape)\n        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n#         print(\"z\", z.shape)\n        x_hat = self.decoder(z)\n        return x_hat, mean, log_var","metadata":{"id":"tliw15bbUA96","execution":{"iopub.status.busy":"2023-01-10T20:49:58.889620Z","iopub.execute_input":"2023-01-10T20:49:58.890353Z","iopub.status.idle":"2023-01-10T20:49:58.898485Z","shell.execute_reply.started":"2023-01-10T20:49:58.890314Z","shell.execute_reply":"2023-01-10T20:49:58.897214Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"vae = VAE(latent_dim=64, hidden_dim=1024, x_dim=32*32*3).to(device)","metadata":{"id":"GyTykpGOSBlk","execution":{"iopub.status.busy":"2023-01-10T20:49:59.077968Z","iopub.execute_input":"2023-01-10T20:49:59.078823Z","iopub.status.idle":"2023-01-10T20:49:59.170229Z","shell.execute_reply.started":"2023-01-10T20:49:59.078759Z","shell.execute_reply":"2023-01-10T20:49:59.169236Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Training loop","metadata":{"id":"F7JiRfSSUI-l","tags":[]}},{"cell_type":"code","source":"# criterion = nn.MSELoss(reduction=\"sum\")\noptimizer = optim.Adam(vae.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)","metadata":{"id":"J7mdh9rkSbrJ","execution":{"iopub.status.busy":"2023-01-10T20:49:59.455695Z","iopub.execute_input":"2023-01-10T20:49:59.456353Z","iopub.status.idle":"2023-01-10T20:49:59.462741Z","shell.execute_reply.started":"2023-01-10T20:49:59.456318Z","shell.execute_reply":"2023-01-10T20:49:59.461263Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def vae_loss_function(x, x_hat, mean, log_var):\n    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n\n    return reproduction_loss+ KLD","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:49:59.647434Z","iopub.execute_input":"2023-01-10T20:49:59.648544Z","iopub.status.idle":"2023-01-10T20:49:59.654563Z","shell.execute_reply.started":"2023-01-10T20:49:59.648499Z","shell.execute_reply":"2023-01-10T20:49:59.653460Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"%%time\nnum_epochs = 2\nfor n in range(num_epochs):\n    losses_epoch = []\n    for x, _ in iter(trainloader):\n        x = x.to(device)\n#         print(\"X SHAPE: \", x.shape, x.shape[0])\n        out, means, log_var = vae(x)\n        out = out.cpu()\n        x = x.cpu()\n#         out = x.view (x.shape[0],3,32,32)\n#         print(\"OUT SHAPE: \", out.shape)\n#         print(\"X SHAPE: \", x.shape)\n        loss = vae_loss_function(x, out, means, log_var)\n        losses_epoch.append(loss.item())\n        loss.backward()               \n        optimizer.step()             \n        optimizer.zero_grad()  \n        \n    L1_list = []\n    FID_list = []\n    for x, _ in iter(validloader):\n        x  = x.to(device)\n        out, _, _ = vae(x)\n        L1_list.append(torch.mean(torch.abs(out-x)).item())\n        \n        # FID\n        with torch.no_grad():\n            latent_dim=64\n            fixed_noise = torch.randn(1000, latent_dim, device=device)\n            generations_vae = vae.decoder(fixed_noise)\n            dist_orig_data = evaluator.get_features(x.to(device)).cpu()\n            dist_vae = evaluator.get_features(generations_vae.to(device)).cpu()\n            FID_score = calculate_frechet_distance(dist_orig_data.numpy(), dist_vae.numpy())\n            FID_list.append(FID_score)\n        \n    print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}, FID = {np.mean(FID_list)}\")\n    scheduler.step()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"h7WZQS5QUKiE","outputId":"4a35eeaa-7ac1-4299-8bdc-47112c1f926b","execution":{"iopub.status.busy":"2023-01-10T20:54:49.329220Z","iopub.execute_input":"2023-01-10T20:54:49.329578Z","iopub.status.idle":"2023-01-10T20:57:44.881584Z","shell.execute_reply.started":"2023-01-10T20:54:49.329547Z","shell.execute_reply":"2023-01-10T20:57:44.880597Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 0 loss 19496.46847472735, test L1 = 0.09812033673127492, FID = 287.1614984517286\nEpoch 1 loss 17701.213021707215, test L1 = 0.09208404272794724, FID = 206.11861397101856\nCPU times: user 1min 25s, sys: 6.79 s, total: 1min 32s\nWall time: 2min 55s\n","output_type":"stream"}]},{"cell_type":"code","source":"# saving model to file\nfrom datetime import datetime\n\ndef get_current_datetime_formatted():\n    return f'{datetime.now()}'.replace('-', '_').replace(' ', '_').replace(':', '_')[:-4]\ncurrent_datetime_formatted = get_current_datetime_formatted()\nstate_dict = vae.state_dict()\ntorch.save(state_dict, f\"generated_models/vae_{current_datetime_formatted}.tar\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.061820Z","iopub.execute_input":"2023-01-10T20:52:52.062595Z","iopub.status.idle":"2023-01-10T20:52:52.084818Z","shell.execute_reply.started":"2023-01-10T20:52:52.062558Z","shell.execute_reply":"2023-01-10T20:52:52.081734Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3944637874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcurrent_datetime_formatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_datetime_formatted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"generated_models/vae_{current_datetime_formatted}.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generated_models/vae_2023_01_10_20_52_52.06.tar'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'generated_models/vae_2023_01_10_20_52_52.06.tar'","output_type":"error"}]},{"cell_type":"markdown","source":"# Reconstructions","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"def visualize_reconstructions(model, input_imgs, device):\n    # Reconstruct images\n    model.eval()\n    with torch.no_grad():\n        reconst_imgs, means, log_var = model(input_imgs.to(device))\n    reconst_imgs = reconst_imgs.cpu()\n    \n    # Plotting\n    imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=False, range=(-1,1))\n    grid = grid.permute(1, 2, 0)\n    if len(input_imgs) == 4:\n        plt.figure(figsize=(10,10))\n    else:\n        plt.figure(figsize=(15,10))\n    plt.title(f\"Reconstructions\")\n    plt.imshow(grid)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.085483Z","iopub.status.idle":"2023-01-10T20:52:52.085830Z","shell.execute_reply.started":"2023-01-10T20:52:52.085647Z","shell.execute_reply":"2023-01-10T20:52:52.085663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_imgs = get_train_images(16)\nvisualize_reconstructions(vae, input_imgs, device)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.087208Z","iopub.status.idle":"2023-01-10T20:52:52.087966Z","shell.execute_reply.started":"2023-01-10T20:52:52.087675Z","shell.execute_reply":"2023-01-10T20:52:52.087701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating new images","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"def generate_images(model, n_imgs, device):\n    # Generate images\n    model.eval()\n    with torch.no_grad():\n        generated_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n    generated_imgs = generated_imgs.cpu()\n    print(generated_imgs[1].min())\n    # generated_imgs =  torch.nn.functional.normalize(generated_imgs, p=2.0, dim = 2)\n    \n    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=False, range=(-1,1))\n    grid = grid.permute(1, 2, 0)\n    if len(input_imgs) == 4:\n        plt.figure(figsize=(10,10))\n    else:\n        plt.figure(figsize=(15,10))\n    plt.title(f\"Generations\")\n    plt.imshow(grid)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.090237Z","iopub.status.idle":"2023-01-10T20:52:52.090710Z","shell.execute_reply.started":"2023-01-10T20:52:52.090470Z","shell.execute_reply":"2023-01-10T20:52:52.090492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_images(vae, 32 , device)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.092320Z","iopub.status.idle":"2023-01-10T20:52:52.092837Z","shell.execute_reply.started":"2023-01-10T20:52:52.092539Z","shell.execute_reply":"2023-01-10T20:52:52.092560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hidden layer VAE","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"def embed_imgs(model, data_loader):\n    # Encode all images in the data_laoder using model, and return both images and encodings\n    img_list, embed_list = [], []\n    model.eval()\n    labels = []\n    for imgs, label in data_loader:\n        with torch.no_grad():\n            mean, var_log = model.encoder(imgs.to(device))\n        img_list.append(imgs)\n        embed_list.append(mean)\n        labels.append(label)\n    return (torch.cat(img_list, dim=0), torch.cat(embed_list, dim=0), torch.cat(labels, dim=0))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.094622Z","iopub.status.idle":"2023-01-10T20:52:52.095127Z","shell.execute_reply.started":"2023-01-10T20:52:52.094875Z","shell.execute_reply":"2023-01-10T20:52:52.094899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import umap\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.097425Z","iopub.status.idle":"2023-01-10T20:52:52.098490Z","shell.execute_reply.started":"2023-01-10T20:52:52.098238Z","shell.execute_reply":"2023-01-10T20:52:52.098260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"umap_object = umap.UMAP(metric=\"cosine\", n_neighbors=100)\ntrain_img_embeds = embed_imgs(vae, trainloader)\ntest_img_embeds = embed_imgs(vae, validloader)\ntrain_embedded = umap_object.fit_transform(train_img_embeds[1][:5000].cpu())","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.099685Z","iopub.status.idle":"2023-01-10T20:52:52.100505Z","shell.execute_reply.started":"2023-01-10T20:52:52.100264Z","shell.execute_reply":"2023-01-10T20:52:52.100286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_latent(train_embedded, train_img_embeds, n_data=5000):\n    data = pd.DataFrame(train_embedded[:n_data])\n    data[\"label\"] = train_img_embeds[2][:n_data].cpu().numpy()\n    examples = []\n    examples_locations = []\n    for i in np.random.randint(0,n_data,40):\n        examples.append(train_img_embeds[0][i].squeeze(0).cpu().numpy())\n        examples_locations.append(data.iloc[i])\n    fig, ax = plt.subplots(figsize=(12, 10))\n    # ax.scatter(noises_to_plot_tsne[0],noises_to_plot_tsne[1],c=noises_to_plot_tsne[\"batch\"],s=3,alpha=0.8)\n    sns.scatterplot(\n        x=0, y=1,\n        hue=\"label\",\n        palette=sns.color_palette(\"hls\", 43),\n        data=data,\n        legend=\"full\",\n        alpha=0.1\n    )\n    for location, example in zip(examples_locations, examples):\n        x, y = location[0], location[1]\n        label = int(location[\"label\"])\n        print(example.shape)\n        ab = AnnotationBbox(OffsetImage(example,cmap=plt.cm.gray_r, zoom=1), (x, y), frameon=True,\n                            bboxprops=dict(facecolor=sns.color_palette(\"hls\", 43)[label], boxstyle=\"round\"))\n        ax.add_artist(ab)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.102064Z","iopub.status.idle":"2023-01-10T20:52:52.102957Z","shell.execute_reply.started":"2023-01-10T20:52:52.102621Z","shell.execute_reply":"2023-01-10T20:52:52.102645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_latent(train_embedded, train_img_embeds)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.104666Z","iopub.status.idle":"2023-01-10T20:52:52.105610Z","shell.execute_reply.started":"2023-01-10T20:52:52.105338Z","shell.execute_reply":"2023-01-10T20:52:52.105364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(train_embedded[:5000])\ndata[\"label\"] = train_img_embeds[2][:5000].cpu().numpy()\nfig, ax = plt.subplots(figsize=(16, 13))\n# ax.scatter(noises_to_plot_tsne[0],noises_to_plot_tsne[1],c=noises_to_plot_tsne[\"batch\"],s=3,alpha=0.8)\nsns.scatterplot(\n    x=0, y=1,\n    hue=\"label\",\n    palette=sns.color_palette(\"hls\", 43),\n    data=data,\n    legend=\"full\",\n    alpha=0.9\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.107103Z","iopub.status.idle":"2023-01-10T20:52:52.107928Z","shell.execute_reply.started":"2023-01-10T20:52:52.107652Z","shell.execute_reply":"2023-01-10T20:52:52.107676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculating FID","metadata":{"tags":[]}},{"cell_type":"code","source":"orig_data = [x[0] for x in list(val_ds)]\norig_data = torch.stack(orig_data)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.109420Z","iopub.status.idle":"2023-01-10T20:52:52.110244Z","shell.execute_reply.started":"2023-01-10T20:52:52.109995Z","shell.execute_reply":"2023-01-10T20:52:52.110019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    latent_dim=64\n    fixed_noise = torch.randn(1000, latent_dim, device=device)\n    generations_vae = vae.decoder(fixed_noise)\n    torch.nn.functional.normalize(generations_vae, p=2.0, dim = 2)\n    \n    dist_orig_data = evaluator.get_features(orig_data.to(device)).cpu()\n    dist_vae = evaluator.get_features(generations_vae.to(device)).cpu()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.111726Z","iopub.status.idle":"2023-01-10T20:52:52.112550Z","shell.execute_reply.started":"2023-01-10T20:52:52.112303Z","shell.execute_reply":"2023-01-10T20:52:52.112327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orig_data_2 = [x[0] for x in list(val_ds)]\norig_data_2 = torch.stack(orig_data_2)\nwith torch.no_grad():\n    dist_orig_data_2 = evaluator.get_features(orig_data_2.to(device)).cpu()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.115272Z","iopub.status.idle":"2023-01-10T20:52:52.115971Z","shell.execute_reply.started":"2023-01-10T20:52:52.115711Z","shell.execute_reply":"2023-01-10T20:52:52.115735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, obj in zip(['orig','vae'],[dist_orig_data_2.numpy(), dist_vae.numpy()]):\n    print(f\"FD {name}: {calculate_frechet_distance(dist_orig_data.numpy(),obj)}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.117196Z","iopub.status.idle":"2023-01-10T20:52:52.117900Z","shell.execute_reply.started":"2023-01-10T20:52:52.117640Z","shell.execute_reply":"2023-01-10T20:52:52.117663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving generated images to file","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"torch.save(generations_vae.cpu().detach(), \"poniedzialek_Lopatto_Sakowski.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.119123Z","iopub.status.idle":"2023-01-10T20:52:52.119827Z","shell.execute_reply.started":"2023-01-10T20:52:52.119562Z","shell.execute_reply":"2023-01-10T20:52:52.119585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generations_vae[7].max()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.121063Z","iopub.status.idle":"2023-01-10T20:52:52.121752Z","shell.execute_reply.started":"2023-01-10T20:52:52.121504Z","shell.execute_reply":"2023-01-10T20:52:52.121527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generations_vae[0].min()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T20:52:52.123077Z","iopub.status.idle":"2023-01-10T20:52:52.123918Z","shell.execute_reply.started":"2023-01-10T20:52:52.123591Z","shell.execute_reply":"2023-01-10T20:52:52.123617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}