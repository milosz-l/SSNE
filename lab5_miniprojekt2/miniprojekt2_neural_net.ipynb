{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd98f3b-a7a0-4072-9577-4fdfad76e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105a0caf-58f1-456c-bd73-deeaede46b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a904f74e-14f9-4e67-9d89-126ebfe67bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['class'] = pd.cut(x=train_data['SalePrice'], bins=[train_data['SalePrice'].min() - 1, 100000, 350000, train_data['SalePrice'].max() + 1], labels=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab393789-fa84-463f-9e13-4dd6f895fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['YearBuilt', 'Size(sqf)', 'Floor', 'N_Parkinglot(Ground)',\n",
    "       'N_Parkinglot(Basement)',  'N_manager',\n",
    "       'N_elevators', 'N_FacilitiesInApt',\n",
    "       'N_FacilitiesNearBy(Total)', 'N_SchoolNearBy(Total)']\n",
    "to_predict = ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e82af22-367d-40d7-8961-2bc7f17e83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[features + to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2565a941-53f8-4e0e-8400-fa1bc1698e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data[:3800]\n",
    "df_val = train_data[3800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acead9a4-f085-4fa5-bbd4-a848473b275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(torch.from_numpy(df_train.values[:,:-1]).float(), torch.from_numpy(df_train.values[:,-1].astype(np.dtype('int64'))))\n",
    "val_dataset = data.TensorDataset(torch.from_numpy(df_val.values[:,:-1]).float(), torch.from_numpy(df_val.values[:,-1].astype(np.dtype('int64'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f3b41f-468e-48fd-9555-612c636871ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2006.,  814.,    3.,  111.,  184.,    3.,    0.,    5.,    6.,    9.]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f636304e-7368-49a8-8f0e-ba32a2355999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e29f3a-eade-4bac-bb0e-ccae22f993bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd724d14-bd08-478d-8b20-f290ce4f28b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884f6696-0b05-4db6-913e-c79fa325099c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (15,20))\n",
    "# ax = fig.gca()\n",
    "# train_data.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90cec52-318a-4e52-8370-9aca500a64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ff510a-c6c0-44ef-a614-f61d29a8524f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b915b216-cc7b-4688-b35e-75be4463a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 1000)\n",
    "        self.act_1 =  nn.ReLU()\n",
    "        self.layer2 = nn.Linear(1000, 1000)\n",
    "        self.act_2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(1000, 1000)\n",
    "        self.act_3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(1000, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act_1(self.layer1(x))\n",
    "        x = self.act_2(self.layer2(x))\n",
    "        x = self.act_3(self.layer3(x))\n",
    "        x = self.layer4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f68080e-9a7c-4174-b789-6ce1b4cb814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() #*********#\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n",
    "        # imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7740c4-4898-4cac-99c4-ca391e190798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train, valid, batch_size=1, num_epochs=1, learning_rate=0.001, weight_decay=0):\n",
    "    train_loader = torch.utils.data.DataLoader(train,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True) # shuffle after every epoch\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay )\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    # n = 0 # the number of iterations\n",
    "    idx = 0\n",
    "    for n in range(num_epochs):\n",
    "        for imgs, labels in iter(train_loader):\n",
    "            # imgs, labels = imgs.to(device), labels.to(device)\n",
    "            model.train() \n",
    "            out = model(imgs)             # forward pass\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         \n",
    "\n",
    "            # save the current training information\n",
    "            if idx % 10 == 9:\n",
    "                iters.append(idx)\n",
    "                losses.append(float(loss)/batch_size)        # compute *average* loss\n",
    "                train_acc.append(get_accuracy(model, train)) # compute training accuracy \n",
    "                val_acc.append(get_accuracy(model, valid))   # compute validation accuracy\n",
    "            idx+=1\n",
    "        print(f\"Epoch {n}\")\n",
    "\n",
    "            \n",
    "    # plotting\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9c07eb-d252-44ac-96db-2b287ef988f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc_loader = torch.utils.data.DataLoader(df_train, batch_size=100)\n",
    "# val_acc_loader = torch.utils.data.DataLoader(df_val, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ffceb-4d7e-49e0-bdd7-87e611ff2a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "train(model, train_dataset, val_dataset, num_epochs=30, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11503a3-681f-4745-96eb-ec3dfa815634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172db5b-1c48-488d-8fc5-61403a89f935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
